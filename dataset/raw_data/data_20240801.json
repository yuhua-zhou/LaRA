[
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      12,
      2,
      14,
      4,
      4,
      4,
      6,
      2,
      4,
      12,
      16,
      4,
      10,
      8,
      4,
      16,
      8,
      10,
      14,
      4,
      12,
      2,
      4,
      14,
      14,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4537037037037037,
      "openbookqa": 0.214,
      "hellaswag": 0.37094204341764586,
      "winogrande": 0.5130228887134964,
      "piqa": 0.6877040261153428,
      "boolq": 0.4308868501529052,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      10,
      14,
      12,
      4,
      12,
      10,
      4,
      2,
      4,
      8,
      10,
      8,
      6,
      8,
      10,
      6,
      2,
      2,
      2,
      16,
      4,
      10,
      8,
      14,
      2,
      16,
      2,
      4,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24829351535836178,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.36875124477195775,
      "openbookqa": 0.222,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.4620795107033639
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      12,
      8,
      12,
      4,
      10,
      8,
      2,
      2,
      2,
      16,
      2,
      12,
      12,
      4,
      2,
      8,
      16,
      12,
      14,
      2,
      8,
      14,
      6,
      4,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5483180428134556,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3593905596494722,
      "arc_easy": 0.48653198653198654,
      "openbookqa": 0.232,
      "winogrande": 0.5059194948697711,
      "piqa": 0.6702937976060935
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      2,
      10,
      12,
      2,
      14,
      10,
      4,
      4,
      2,
      12,
      8,
      10,
      12,
      4,
      10,
      16,
      16,
      2,
      16,
      6,
      6,
      2,
      14,
      14,
      10,
      12,
      12,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.44991582491582494,
      "boolq": 0.41529051987767585,
      "openbookqa": 0.226,
      "hellaswag": 0.3719378609838678,
      "piqa": 0.6920565832426551,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      16,
      2,
      12,
      16,
      10,
      4,
      8,
      16,
      4,
      10,
      10,
      6,
      10,
      8,
      14,
      14,
      4,
      14,
      2,
      8,
      2,
      6,
      4,
      2,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5153906866614049,
      "boolq": 0.41865443425076454,
      "arc_easy": 0.4478114478114478,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.25853242320819114,
      "openbookqa": 0.218,
      "hellaswag": 0.36964748058155744
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      2,
      4,
      6,
      16,
      16,
      10,
      8,
      12,
      8,
      10,
      6,
      14,
      8,
      4,
      4,
      2,
      6,
      12,
      10,
      2,
      6,
      12,
      10,
      14,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6692056583242655,
      "boolq": 0.544954128440367,
      "arc_easy": 0.48358585858585856,
      "openbookqa": 0.228,
      "winogrande": 0.5177584846093133,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.3588926508663613
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      2,
      2,
      6,
      4,
      14,
      14,
      16,
      10,
      4,
      4,
      12,
      12,
      14,
      8,
      6,
      8,
      6,
      12,
      6,
      8,
      16,
      4,
      4,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5773700305810398,
      "arc_easy": 0.4861111111111111,
      "arc_challenge": 0.24829351535836178,
      "piqa": 0.6741022850924918,
      "winogrande": 0.5256511444356748,
      "openbookqa": 0.23,
      "hellaswag": 0.35929097789285
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      2,
      10,
      14,
      2,
      6,
      14,
      4,
      2,
      14,
      8,
      6,
      6,
      4,
      10,
      4,
      6,
      8,
      4,
      14,
      12,
      2,
      12,
      10,
      2,
      12,
      14,
      12,
      6,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44612794612794615,
      "winogrande": 0.5185477505919495,
      "boolq": 0.427217125382263,
      "hellaswag": 0.3695478988249353,
      "arc_challenge": 0.2551194539249147,
      "openbookqa": 0.226,
      "piqa": 0.6877040261153428
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      8,
      16,
      8,
      4,
      6,
      2,
      6,
      10,
      2,
      6,
      6,
      2,
      6,
      16,
      8,
      8,
      8,
      16,
      16,
      2,
      6,
      14,
      4,
      16,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5248618784530387,
      "boolq": 0.5871559633027523,
      "openbookqa": 0.218,
      "arc_challenge": 0.2508532423208191,
      "piqa": 0.6681175190424374,
      "hellaswag": 0.36058554072893845,
      "arc_easy": 0.47853535353535354
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      10,
      12,
      4,
      6,
      14,
      12,
      12,
      2,
      14,
      12,
      10,
      4,
      10,
      4,
      8,
      14,
      6,
      8,
      8,
      4,
      8,
      6,
      4,
      10,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5240726124704025,
      "hellaswag": 0.35839474208325034,
      "arc_easy": 0.48148148148148145,
      "boolq": 0.5837920489296636,
      "arc_challenge": 0.24573378839590443,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.226
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      8,
      2,
      14,
      16,
      2,
      4,
      8,
      16,
      4,
      16,
      6,
      6,
      14,
      16,
      12,
      8,
      6,
      8,
      2,
      8,
      12,
      4,
      6,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35789683330013944,
      "arc_challenge": 0.25,
      "openbookqa": 0.226,
      "winogrande": 0.5146014206787688,
      "piqa": 0.6724700761697497,
      "boolq": 0.5648318042813456,
      "arc_easy": 0.4739057239057239
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      16,
      2,
      8,
      6,
      12,
      4,
      14,
      2,
      10,
      2,
      16,
      8,
      6,
      10,
      6,
      10,
      4,
      16,
      2,
      16,
      4,
      6,
      8,
      4,
      2,
      14,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4831649831649832,
      "arc_challenge": 0.24744027303754265,
      "hellaswag": 0.35879306910973907,
      "openbookqa": 0.234,
      "boolq": 0.5480122324159021,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      16,
      4,
      6,
      16,
      2,
      10,
      4,
      16,
      8,
      6,
      16,
      10,
      10,
      2,
      12,
      4,
      12,
      2,
      2,
      6,
      8,
      8,
      8,
      8,
      4,
      2,
      12,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44654882154882153,
      "openbookqa": 0.22,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.369946225851424,
      "boolq": 0.4703363914373089,
      "arc_challenge": 0.25597269624573377,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      8,
      10,
      6,
      8,
      8,
      14,
      8,
      6,
      6,
      4,
      2,
      6,
      4,
      12,
      4,
      8,
      6,
      4,
      12,
      16,
      10,
      16,
      8,
      4,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.47186544342507647,
      "winogrande": 0.5209155485398579,
      "hellaswag": 0.36964748058155744,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.2525597269624573,
      "openbookqa": 0.216,
      "arc_easy": 0.4473905723905724
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      10,
      6,
      10,
      8,
      8,
      16,
      14,
      12,
      2,
      8,
      6,
      2,
      16,
      4,
      2,
      12,
      12,
      16,
      12,
      8,
      2,
      6,
      6,
      6,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6838955386289445,
      "arc_easy": 0.4444444444444444,
      "hellaswag": 0.3721370244971121,
      "arc_challenge": 0.24829351535836178,
      "boolq": 0.40856269113149846,
      "openbookqa": 0.222,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      6,
      4,
      6,
      6,
      8,
      10,
      12,
      12,
      12,
      12,
      6,
      2,
      14,
      2,
      14,
      4,
      12,
      10,
      8,
      2,
      16,
      8,
      14,
      8,
      2,
      8,
      8,
      2,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "hellaswag": 0.37094204341764586,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.25,
      "boolq": 0.44648318042813456,
      "arc_easy": 0.4457070707070707,
      "piqa": 0.6953210010881393
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      16,
      12,
      4,
      16,
      6,
      6,
      2,
      2,
      8,
      6,
      4,
      12,
      16,
      2,
      8,
      6,
      2,
      10,
      12,
      4,
      14,
      4,
      8,
      16,
      2,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6686615886833515,
      "boolq": 0.5896024464831804,
      "arc_challenge": 0.25170648464163825,
      "openbookqa": 0.238,
      "hellaswag": 0.3573989245170285,
      "arc_easy": 0.4793771043771044,
      "winogrande": 0.5240726124704025
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      4,
      4,
      12,
      14,
      2,
      14,
      12,
      8,
      12,
      4,
      6,
      8,
      8,
      12,
      4,
      8,
      4,
      12,
      4,
      14,
      8,
      10,
      2,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2431740614334471,
      "arc_easy": 0.48148148148148145,
      "openbookqa": 0.232,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.3594901414060944,
      "boolq": 0.5850152905198777,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      8,
      2,
      16,
      14,
      6,
      14,
      10,
      4,
      6,
      12,
      4,
      16,
      4,
      4,
      4,
      2,
      8,
      10,
      8,
      4,
      14,
      10,
      16,
      4,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.4793771043771044,
      "hellaswag": 0.35919139613622786,
      "piqa": 0.6730141458106638,
      "openbookqa": 0.236,
      "arc_challenge": 0.2431740614334471,
      "boolq": 0.5856269113149847
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      10,
      4,
      12,
      8,
      6,
      6,
      6,
      14,
      14,
      6,
      12,
      12,
      2,
      8,
      2,
      12,
      10,
      2,
      2,
      4,
      14,
      10,
      12,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676278563656148,
      "arc_easy": 0.48737373737373735,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.5801223241590214,
      "hellaswag": 0.3599880501892053,
      "winogrande": 0.5122336227308603,
      "openbookqa": 0.222
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      2,
      14,
      8,
      2,
      16,
      6,
      4,
      6,
      2,
      16,
      16,
      6,
      10,
      4,
      4,
      6,
      6,
      4,
      16,
      8,
      16,
      8,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.226,
      "piqa": 0.6947769314472253,
      "hellaswag": 0.3723361880103565,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.4553872053872054,
      "arc_challenge": 0.25853242320819114,
      "boolq": 0.4602446483180428
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      14,
      6,
      2,
      14,
      4,
      6,
      4,
      6,
      12,
      12,
      14,
      12,
      4,
      14,
      10,
      12,
      2,
      14,
      12,
      8,
      6,
      4,
      4,
      2,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5217048145224941,
      "arc_easy": 0.44107744107744107,
      "hellaswag": 0.369946225851424,
      "piqa": 0.6871599564744287,
      "openbookqa": 0.218,
      "boolq": 0.41712538226299695,
      "arc_challenge": 0.24914675767918087
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      6,
      2,
      8,
      12,
      2,
      4,
      4,
      10,
      10,
      16,
      6,
      4,
      8,
      16,
      14,
      14,
      6,
      14,
      4,
      2,
      14,
      2,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24488054607508533,
      "piqa": 0.675734494015234,
      "hellaswag": 0.36078470424218284,
      "openbookqa": 0.234,
      "boolq": 0.5951070336391437,
      "arc_easy": 0.4852693602693603,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      10,
      14,
      6,
      8,
      8,
      2,
      2,
      16,
      10,
      2,
      4,
      12,
      4,
      4,
      4,
      2,
      2,
      16,
      4,
      16,
      14,
      10,
      4,
      16,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3593905596494722,
      "arc_challenge": 0.24573378839590443,
      "winogrande": 0.526440410418311,
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.228,
      "piqa": 0.6735582154515778,
      "boolq": 0.5345565749235474
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      10,
      16,
      14,
      6,
      6,
      10,
      10,
      4,
      2,
      4,
      6,
      2,
      14,
      8,
      8,
      16,
      12,
      6,
      10,
      2,
      10,
      10,
      4,
      2,
      2,
      14,
      14,
      8,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "openbookqa": 0.218,
      "arc_easy": 0.44486531986531985,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6877040261153428,
      "boolq": 0.4547400611620795,
      "hellaswag": 0.371539533957379
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      10,
      4,
      6,
      2,
      14,
      6,
      2,
      16,
      4,
      4,
      14,
      2,
      10,
      4,
      12,
      4,
      14,
      4,
      2,
      6,
      2,
      16,
      4,
      6,
      14,
      16,
      14,
      8,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "hellaswag": 0.37054371639115713,
      "boolq": 0.41804281345565747,
      "openbookqa": 0.222,
      "arc_easy": 0.43897306397306396,
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      6,
      2,
      8,
      6,
      8,
      16,
      2,
      8,
      10,
      8,
      4,
      16,
      14,
      6,
      16,
      8,
      14,
      2,
      4,
      2,
      8,
      4,
      10,
      6,
      16,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3579964150567616,
      "openbookqa": 0.228,
      "winogrande": 0.5193370165745856,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5966360856269113,
      "piqa": 0.6773667029379761,
      "arc_challenge": 0.24744027303754265
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      12,
      4,
      2,
      14,
      8,
      14,
      10,
      6,
      10,
      2,
      8,
      2,
      6,
      2,
      8,
      14,
      12,
      10,
      10,
      6,
      2,
      12,
      2,
      14,
      12,
      14,
      4,
      12,
      2,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44654882154882153,
      "openbookqa": 0.224,
      "hellaswag": 0.36974706233817967,
      "arc_challenge": 0.24573378839590443,
      "piqa": 0.6882480957562568,
      "boolq": 0.45688073394495415,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      16,
      2,
      16,
      8,
      2,
      2,
      14,
      2,
      4,
      6,
      8,
      14,
      2,
      8,
      6,
      4,
      16,
      4,
      6,
      10,
      14,
      12,
      12,
      12,
      6,
      10,
      4,
      10,
      2,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3710416251742681,
      "boolq": 0.481039755351682,
      "winogrande": 0.5272296764009471,
      "openbookqa": 0.224,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.257679180887372,
      "arc_easy": 0.44865319865319864
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      10,
      16,
      6,
      4,
      6,
      6,
      2,
      10,
      4,
      4,
      8,
      2,
      12,
      4,
      6,
      6,
      12,
      16,
      16,
      8,
      10,
      4,
      10,
      8,
      14,
      8,
      4,
      14,
      4,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.212,
      "hellaswag": 0.3701453893646684,
      "arc_easy": 0.44276094276094274,
      "winogrande": 0.5098658247829518,
      "arc_challenge": 0.2525597269624573,
      "boolq": 0.43547400611620796,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      2,
      14,
      4,
      10,
      10,
      12,
      4,
      2,
      2,
      8,
      16,
      8,
      4,
      12,
      4,
      12,
      14,
      6,
      12,
      14,
      16,
      12,
      4,
      2,
      4,
      2,
      4,
      16,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "piqa": 0.6893362350380848,
      "boolq": 0.42171253822629967,
      "arc_challenge": 0.2525597269624573,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.3712407886875124,
      "winogrande": 0.5146014206787688
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      2,
      8,
      4,
      14,
      12,
      12,
      2,
      10,
      2,
      2,
      4,
      6,
      12,
      14,
      6,
      8,
      6,
      14,
      8,
      8,
      12,
      6,
      8,
      6,
      10,
      4,
      4,
      12,
      14,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.43602693602693604,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.37134037044413465,
      "piqa": 0.6882480957562568,
      "openbookqa": 0.218,
      "boolq": 0.43180428134556575
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      2,
      10,
      6,
      4,
      10,
      14,
      6,
      4,
      12,
      14,
      16,
      6,
      2,
      8,
      14,
      16,
      6,
      16,
      2,
      6,
      6,
      8,
      6,
      8,
      4,
      4,
      12,
      8,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3708424616610237,
      "openbookqa": 0.214,
      "arc_challenge": 0.24658703071672355,
      "boolq": 0.5107033639143731,
      "arc_easy": 0.4532828282828283,
      "piqa": 0.6838955386289445,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      12,
      14,
      16,
      4,
      6,
      2,
      2,
      2,
      6,
      12,
      2,
      4,
      6,
      14,
      12,
      2,
      8,
      6,
      10,
      16,
      4,
      6,
      10,
      16,
      10,
      6,
      12,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44654882154882153,
      "winogrande": 0.5209155485398579,
      "boolq": 0.4951070336391437,
      "piqa": 0.6898803046789989,
      "openbookqa": 0.224,
      "hellaswag": 0.369946225851424,
      "arc_challenge": 0.25341296928327645
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      6,
      2,
      6,
      2,
      10,
      2,
      6,
      10,
      2,
      12,
      12,
      2,
      16,
      16,
      10,
      4,
      4,
      10,
      14,
      12,
      10,
      10,
      14,
      10,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "boolq": 0.5847094801223242,
      "piqa": 0.6708378672470077,
      "arc_easy": 0.4877946127946128,
      "hellaswag": 0.3584943238398725,
      "arc_challenge": 0.24232081911262798,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      16,
      4,
      10,
      4,
      10,
      2,
      12,
      2,
      4,
      6,
      2,
      2,
      16,
      10,
      16,
      6,
      8,
      2,
      8,
      4,
      10,
      14,
      10,
      12,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "openbookqa": 0.228,
      "arc_easy": 0.4797979797979798,
      "hellaswag": 0.3593905596494722,
      "boolq": 0.5648318042813456,
      "piqa": 0.6686615886833515,
      "arc_challenge": 0.24488054607508533
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      16,
      4,
      2,
      2,
      2,
      6,
      10,
      16,
      8,
      6,
      16,
      14,
      8,
      14,
      6,
      12,
      14,
      4,
      6,
      10,
      4,
      6,
      2,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6741022850924918,
      "openbookqa": 0.23,
      "boolq": 0.5715596330275229,
      "hellaswag": 0.3603863772156941,
      "arc_easy": 0.4810606060606061,
      "winogrande": 0.5169692186266772,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      8,
      4,
      2,
      10,
      16,
      8,
      8,
      4,
      14,
      2,
      10,
      2,
      4,
      2,
      14,
      6,
      8,
      6,
      2,
      2,
      14,
      16,
      14,
      14,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "piqa": 0.675734494015234,
      "boolq": 0.5779816513761468,
      "arc_challenge": 0.2440273037542662,
      "arc_easy": 0.484006734006734,
      "hellaswag": 0.3579964150567616,
      "winogrande": 0.526440410418311
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      16,
      10,
      4,
      6,
      12,
      4,
      10,
      12,
      8,
      2,
      2,
      6,
      4,
      8,
      10,
      10,
      6,
      10,
      14,
      2,
      14,
      10,
      14,
      4,
      2,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25426621160409557,
      "arc_easy": 0.44823232323232326,
      "hellaswag": 0.36914957179844654,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6866158868335147,
      "openbookqa": 0.218,
      "boolq": 0.4776758409785933
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      8,
      10,
      4,
      2,
      6,
      14,
      2,
      8,
      10,
      2,
      2,
      8,
      10,
      10,
      8,
      16,
      16,
      16,
      4,
      8,
      8,
      12,
      4,
      10,
      16,
      12,
      10,
      4,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6860718171926007,
      "boolq": 0.42446483180428135,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.3714399522007568,
      "winogrande": 0.5169692186266772,
      "arc_challenge": 0.2508532423208191,
      "openbookqa": 0.22
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      14,
      6,
      12,
      10,
      16,
      6,
      2,
      14,
      6,
      8,
      2,
      10,
      14,
      2,
      2,
      6,
      16,
      14,
      10,
      14,
      2,
      4,
      4,
      6,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.228,
      "arc_challenge": 0.24146757679180889,
      "boolq": 0.5859327217125382,
      "arc_easy": 0.4819023569023569,
      "hellaswag": 0.3588926508663613,
      "piqa": 0.6713819368879217,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      14,
      4,
      6,
      6,
      12,
      14,
      12,
      6,
      2,
      4,
      6,
      2,
      4,
      16,
      14,
      4,
      14,
      8,
      14,
      2,
      8,
      8,
      4,
      14,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3586934873531169,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.25341296928327645,
      "openbookqa": 0.24,
      "boolq": 0.5984709480122324,
      "arc_easy": 0.48653198653198654,
      "winogrande": 0.5130228887134964
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      8,
      10,
      6,
      12,
      16,
      2,
      16,
      14,
      12,
      12,
      10,
      12,
      12,
      10,
      2,
      6,
      8,
      8,
      4,
      12,
      4,
      4,
      2,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "boolq": 0.5785932721712538,
      "piqa": 0.6730141458106638,
      "arc_challenge": 0.2440273037542662,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.3584943238398725,
      "arc_easy": 0.49242424242424243
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      6,
      14,
      8,
      12,
      12,
      2,
      14,
      10,
      16,
      6,
      2,
      8,
      4,
      4,
      2,
      8,
      16,
      6,
      8,
      2,
      12,
      2,
      10,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3575980880302729,
      "openbookqa": 0.224,
      "winogrande": 0.5272296764009471,
      "boolq": 0.5889908256880734,
      "arc_easy": 0.4823232323232323,
      "arc_challenge": 0.2508532423208191,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      2,
      16,
      16,
      2,
      14,
      6,
      6,
      8,
      4,
      14,
      2,
      16,
      16,
      4,
      12,
      16,
      10,
      4,
      8,
      10,
      6,
      10,
      4,
      6,
      2,
      4,
      2,
      2,
      8,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6882480957562568,
      "boolq": 0.44648318042813456,
      "hellaswag": 0.3723361880103565,
      "arc_challenge": 0.24573378839590443,
      "openbookqa": 0.218,
      "arc_easy": 0.44907407407407407,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      12,
      16,
      12,
      6,
      12,
      2,
      4,
      10,
      4,
      8,
      12,
      4,
      12,
      2,
      4,
      10,
      16,
      2,
      6,
      4,
      12,
      16,
      12,
      4,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.226,
      "piqa": 0.6871599564744287,
      "arc_easy": 0.4457070707070707,
      "boolq": 0.4418960244648318,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.2568259385665529,
      "hellaswag": 0.3707428799044015
    }
  }
]