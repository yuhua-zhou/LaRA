[
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      14,
      14,
      6,
      10,
      6,
      14,
      10,
      10,
      6,
      12,
      4,
      6,
      12,
      8,
      6,
      4,
      12,
      14,
      8,
      8,
      16,
      6,
      2,
      8,
      10,
      4,
      10,
      16,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.484006734006734,
      "arc_challenge": 0.27303754266211605,
      "winogrande": 0.516179952644041,
      "boolq": 0.5425076452599389,
      "openbookqa": 0.346,
      "hellaswag": 0.4325831507667795,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      6,
      14,
      6,
      6,
      10,
      14,
      16,
      8,
      6,
      6,
      12,
      2,
      6,
      10,
      6,
      6,
      6,
      6,
      14,
      8,
      6,
      6,
      2,
      10,
      10,
      4,
      6,
      14,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4504587155963303,
      "piqa": 0.6860718171926007,
      "arc_challenge": 0.2883959044368601,
      "arc_easy": 0.44234006734006737,
      "hellaswag": 0.4480183230432185,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.356
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      16,
      12,
      2,
      12,
      2,
      8,
      2,
      14,
      6,
      10,
      16,
      12,
      12,
      16,
      6,
      6,
      16,
      6,
      4,
      2,
      4,
      8,
      10,
      8,
      14,
      8,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "piqa": 0.676822633297062,
      "arc_easy": 0.48863636363636365,
      "hellaswag": 0.43218482374029077,
      "boolq": 0.5388379204892967,
      "arc_challenge": 0.2627986348122867,
      "winogrande": 0.5248618784530387
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      2,
      10,
      14,
      12,
      12,
      8,
      8,
      4,
      14,
      16,
      8,
      16,
      4,
      2,
      12,
      14,
      12,
      12,
      10,
      6,
      2,
      8,
      8,
      8,
      6,
      16,
      10,
      10,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6708378672470077,
      "hellaswag": 0.43158733320055764,
      "arc_easy": 0.4852693602693603,
      "openbookqa": 0.352,
      "winogrande": 0.5201262825572218,
      "boolq": 0.590519877675841,
      "arc_challenge": 0.2721843003412969
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      2,
      6,
      10,
      4,
      16,
      14,
      4,
      16,
      16,
      10,
      10,
      12,
      4,
      14,
      10,
      2,
      12,
      6,
      4,
      6,
      2,
      10,
      8,
      10,
      10,
      12,
      10,
      6,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.41345565749235474,
      "hellaswag": 0.4502091216889066,
      "openbookqa": 0.35,
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.27303754266211605
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      16,
      10,
      14,
      12,
      16,
      16,
      2,
      12,
      2,
      10,
      12,
      16,
      8,
      16,
      12,
      6,
      6,
      2,
      4,
      8,
      16,
      6,
      8,
      14,
      16,
      6,
      6,
      2,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.42939653455486954,
      "arc_challenge": 0.26535836177474403,
      "openbookqa": 0.35,
      "piqa": 0.6719260065288357,
      "boolq": 0.5920489296636086,
      "winogrande": 0.5232833464877664,
      "arc_easy": 0.4819023569023569
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      16,
      6,
      6,
      14,
      2,
      8,
      2,
      4,
      14,
      8,
      6,
      10,
      6,
      12,
      6,
      14,
      12,
      8,
      2,
      12,
      4,
      2,
      8,
      16,
      16,
      8,
      10,
      8,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4831649831649832,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5694189602446483,
      "hellaswag": 0.43009360685122483,
      "arc_challenge": 0.2721843003412969,
      "openbookqa": 0.35,
      "piqa": 0.6692056583242655
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      2,
      16,
      16,
      12,
      6,
      4,
      2,
      8,
      8,
      2,
      8,
      4,
      4,
      4,
      10,
      6,
      10,
      4,
      14,
      4,
      2,
      10,
      4,
      6,
      6,
      8,
      6,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5837920489296636,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.358,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.4326827325234017,
      "piqa": 0.6686615886833515,
      "arc_challenge": 0.2721843003412969
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      6,
      12,
      8,
      6,
      2,
      16,
      10,
      16,
      16,
      4,
      8,
      4,
      8,
      2,
      10,
      8,
      4,
      8,
      16,
      8,
      16,
      4,
      4,
      8,
      4,
      2,
      12,
      10,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6784548422198041,
      "openbookqa": 0.352,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5825688073394495,
      "arc_challenge": 0.2687713310580205,
      "arc_easy": 0.4819023569023569,
      "hellaswag": 0.4311890061740689
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      8,
      2,
      2,
      2,
      10,
      4,
      4,
      2,
      2,
      12,
      10,
      10,
      2,
      12,
      2,
      6,
      8,
      2,
      8,
      4,
      12,
      6,
      12,
      12,
      14,
      2,
      12,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4473905723905724,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6860718171926007,
      "arc_challenge": 0.28242320819112626,
      "openbookqa": 0.352,
      "boolq": 0.4669724770642202,
      "hellaswag": 0.4477195777733519
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      10,
      12,
      14,
      12,
      14,
      2,
      14,
      2,
      14,
      8,
      6,
      12,
      4,
      6,
      6,
      10,
      16,
      16,
      14,
      12,
      10,
      6,
      12,
      4,
      6,
      6,
      2,
      12,
      4,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4480183230432185,
      "openbookqa": 0.35,
      "arc_challenge": 0.2832764505119454,
      "arc_easy": 0.4444444444444444,
      "piqa": 0.6898803046789989,
      "winogrande": 0.5209155485398579,
      "boolq": 0.4801223241590214
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      12,
      16,
      12,
      6,
      8,
      10,
      12,
      14,
      4,
      16,
      4,
      16,
      2,
      4,
      10,
      16,
      8,
      8,
      14,
      10,
      14,
      16,
      6,
      10,
      16,
      8,
      14,
      2,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45580808080808083,
      "arc_challenge": 0.2858361774744027,
      "piqa": 0.691512513601741,
      "hellaswag": 0.45379406492730534,
      "boolq": 0.4685015290519878,
      "winogrande": 0.5138121546961326,
      "openbookqa": 0.354
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      16,
      16,
      16,
      4,
      10,
      14,
      14,
      10,
      16,
      8,
      8,
      8,
      8,
      10,
      14,
      14,
      10,
      6,
      6,
      8,
      8,
      2,
      8,
      14,
      14,
      10,
      16,
      12,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.356,
      "piqa": 0.6675734494015234,
      "arc_easy": 0.48484848484848486,
      "arc_challenge": 0.2636518771331058,
      "hellaswag": 0.4302927703644692,
      "winogrande": 0.5122336227308603,
      "boolq": 0.5996941896024465
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      16,
      2,
      16,
      14,
      14,
      10,
      12,
      2,
      16,
      8,
      8,
      2,
      4,
      4,
      4,
      8,
      4,
      14,
      16,
      16,
      4,
      6,
      14,
      4,
      12,
      8,
      4,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4477195777733519,
      "arc_challenge": 0.28071672354948807,
      "openbookqa": 0.346,
      "arc_easy": 0.4436026936026936,
      "piqa": 0.6931447225244831,
      "winogrande": 0.5146014206787688,
      "boolq": 0.4840978593272171
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      10,
      8,
      6,
      4,
      2,
      14,
      8,
      8,
      12,
      14,
      6,
      12,
      4,
      4,
      14,
      4,
      4,
      4,
      6,
      4,
      4,
      14,
      2,
      2,
      4,
      8,
      2,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44865319865319864,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.28668941979522183,
      "boolq": 0.46055045871559636,
      "openbookqa": 0.348,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.44961163114917346
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      14,
      10,
      2,
      2,
      12,
      10,
      10,
      10,
      2,
      12,
      8,
      12,
      14,
      10,
      10,
      10,
      12,
      14,
      4,
      12,
      4,
      6,
      6,
      8,
      8,
      6,
      4,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48653198653198654,
      "piqa": 0.6751904243743199,
      "hellaswag": 0.43019318860784705,
      "winogrande": 0.5138121546961326,
      "arc_challenge": 0.2721843003412969,
      "boolq": 0.591743119266055,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      4,
      12,
      14,
      14,
      10,
      14,
      12,
      12,
      6,
      8,
      4,
      4,
      4,
      8,
      12,
      14,
      2,
      4,
      10,
      4,
      2,
      12,
      10,
      4,
      14,
      14,
      8,
      2,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4524410774410774,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.28242320819112626,
      "boolq": 0.4562691131498471,
      "hellaswag": 0.448814977096196,
      "openbookqa": 0.342
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      6,
      16,
      2,
      16,
      6,
      10,
      10,
      2,
      4,
      2,
      4,
      14,
      2,
      16,
      12,
      14,
      12,
      12,
      4,
      10,
      2,
      14,
      8,
      14,
      8,
      16,
      4,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.43507269468233417,
      "arc_challenge": 0.2721843003412969,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.47895622895622897,
      "boolq": 0.5785932721712538
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      16,
      10,
      2,
      6,
      6,
      4,
      14,
      14,
      2,
      6,
      10,
      12,
      16,
      12,
      12,
      2,
      10,
      2,
      14,
      2,
      16,
      2,
      10,
      4,
      8,
      4,
      8,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.344,
      "arc_challenge": 0.26621160409556316,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.47853535353535354,
      "boolq": 0.5902140672782875,
      "hellaswag": 0.43238398725353516
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      2,
      6,
      12,
      14,
      2,
      16,
      16,
      16,
      8,
      2,
      4,
      12,
      2,
      2,
      4,
      14,
      6,
      6,
      6,
      16,
      10,
      2,
      6,
      14,
      4,
      8,
      8,
      6,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45075757575757575,
      "hellaswag": 0.44851623182632944,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.348,
      "arc_challenge": 0.2738907849829352,
      "piqa": 0.6877040261153428,
      "boolq": 0.43700305810397555
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      6,
      12,
      2,
      6,
      4,
      4,
      2,
      4,
      2,
      12,
      6,
      4,
      16,
      8,
      14,
      16,
      10,
      8,
      16,
      16,
      10,
      16,
      8,
      14,
      16,
      8,
      12,
      6,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44811790479984065,
      "boolq": 0.43333333333333335,
      "openbookqa": 0.342,
      "arc_easy": 0.43813131313131315,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5272296764009471
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      12,
      6,
      4,
      10,
      8,
      14,
      6,
      6,
      8,
      8,
      4,
      6,
      8,
      10,
      8,
      8,
      8,
      10,
      16,
      14,
      16,
      6,
      2,
      10,
      14,
      6,
      4,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "hellaswag": 0.43178649671380204,
      "winogrande": 0.526440410418311,
      "piqa": 0.6659412404787813,
      "arc_challenge": 0.26706484641638223,
      "boolq": 0.6036697247706422,
      "arc_easy": 0.48863636363636365
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      10,
      6,
      16,
      16,
      16,
      12,
      14,
      16,
      16,
      4,
      14,
      10,
      10,
      8,
      8,
      14,
      16,
      4,
      4,
      8,
      12,
      2,
      12,
      14,
      4,
      16,
      8,
      2,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.358,
      "boolq": 0.6030581039755352,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6708378672470077,
      "hellaswag": 0.43089026090420235,
      "arc_challenge": 0.26621160409556316
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      10,
      16,
      6,
      16,
      6,
      16,
      16,
      8,
      12,
      2,
      10,
      12,
      12,
      6,
      8,
      4,
      12,
      8,
      16,
      14,
      2,
      16,
      16,
      2,
      10,
      14,
      8,
      14,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.358,
      "arc_challenge": 0.27303754266211605,
      "boolq": 0.5504587155963303,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.48274410774410775,
      "hellaswag": 0.4312885879306911
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      16,
      14,
      16,
      4,
      2,
      14,
      8,
      14,
      2,
      4,
      8,
      12,
      2,
      2,
      12,
      10,
      4,
      10,
      8,
      14,
      14,
      10,
      12,
      14,
      6,
      8,
      14,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.591131498470948,
      "hellaswag": 0.43178649671380204,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6692056583242655,
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.342
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      10,
      10,
      16,
      2,
      14,
      14,
      8,
      12,
      6,
      4,
      12,
      16,
      12,
      10,
      6,
      12,
      4,
      12,
      16,
      14,
      16,
      12,
      4,
      14,
      8,
      6,
      4,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5944954128440367,
      "openbookqa": 0.354,
      "arc_challenge": 0.27047781569965873,
      "piqa": 0.6686615886833515,
      "arc_easy": 0.48358585858585856,
      "hellaswag": 0.43009360685122483,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      6,
      8,
      2,
      10,
      12,
      10,
      8,
      8,
      4,
      16,
      8,
      2,
      14,
      16,
      10,
      14,
      2,
      12,
      10,
      12,
      16,
      12,
      16,
      8,
      14,
      4,
      2,
      8,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5984709480122324,
      "piqa": 0.676822633297062,
      "arc_challenge": 0.2773037542662116,
      "hellaswag": 0.43168691495717987,
      "arc_easy": 0.48148148148148145,
      "openbookqa": 0.346,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      12,
      14,
      10,
      2,
      2,
      2,
      10,
      12,
      8,
      16,
      16,
      8,
      14,
      4,
      12,
      14,
      12,
      12,
      8,
      14,
      2,
      16,
      16,
      4,
      8,
      2,
      14,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.354,
      "arc_easy": 0.44612794612794615,
      "boolq": 0.4529051987767584,
      "arc_challenge": 0.27986348122866894,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.4486158135829516
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      16,
      14,
      14,
      12,
      10,
      16,
      14,
      8,
      2,
      14,
      10,
      12,
      6,
      6,
      14,
      16,
      8,
      12,
      8,
      16,
      4,
      12,
      6,
      12,
      10,
      10,
      16,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27303754266211605,
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.34,
      "piqa": 0.6708378672470077,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5761467889908257,
      "hellaswag": 0.43158733320055764
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      8,
      14,
      2,
      14,
      10,
      2,
      8,
      8,
      6,
      2,
      6,
      10,
      6,
      6,
      4,
      6,
      2,
      8,
      10,
      2,
      16,
      8,
      12,
      14,
      10,
      6,
      4,
      10,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.27303754266211605,
      "hellaswag": 0.4344752041426011,
      "piqa": 0.6741022850924918,
      "boolq": 0.5883792048929664,
      "openbookqa": 0.358,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      12,
      4,
      16,
      2,
      6,
      12,
      12,
      10,
      4,
      12,
      8,
      8,
      8,
      16,
      2,
      8,
      12,
      12,
      10,
      4,
      14,
      12,
      6,
      2,
      4,
      14,
      10,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4305915156343358,
      "boolq": 0.5874617737003058,
      "openbookqa": 0.348,
      "arc_challenge": 0.2619453924914676,
      "piqa": 0.6653971708378672,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.48358585858585856
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      12,
      10,
      16,
      10,
      2,
      6,
      16,
      12,
      4,
      10,
      8,
      4,
      4,
      14,
      10,
      2,
      12,
      2,
      16,
      16,
      12,
      10,
      2,
      10,
      16,
      16,
      4,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2858361774744027,
      "piqa": 0.690424374319913,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4457070707070707,
      "boolq": 0.44311926605504587,
      "openbookqa": 0.354,
      "hellaswag": 0.44901414060944034
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      12,
      4,
      14,
      16,
      12,
      4,
      12,
      14,
      4,
      14,
      16,
      4,
      10,
      14,
      12,
      6,
      12,
      12,
      12,
      10,
      8,
      4,
      12,
      14,
      6,
      14,
      2,
      4,
      14,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "boolq": 0.6110091743119266,
      "openbookqa": 0.352,
      "arc_challenge": 0.2696245733788396,
      "piqa": 0.6746463547334058,
      "arc_easy": 0.4793771043771044,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      16,
      12,
      6,
      10,
      10,
      10,
      12,
      16,
      8,
      8,
      8,
      16,
      2,
      2,
      16,
      14,
      14,
      6,
      12,
      12,
      14,
      14,
      4,
      2,
      12,
      2,
      14,
      8,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5098658247829518,
      "hellaswag": 0.44971121290579563,
      "arc_easy": 0.44486531986531985,
      "arc_challenge": 0.2790102389078498,
      "piqa": 0.6855277475516867,
      "boolq": 0.43547400611620796,
      "openbookqa": 0.348
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      6,
      8,
      6,
      6,
      10,
      16,
      8,
      4,
      2,
      12,
      14,
      2,
      6,
      14,
      12,
      12,
      16,
      2,
      16,
      6,
      4,
      16,
      10,
      12,
      6,
      12,
      2,
      14,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27559726962457337,
      "openbookqa": 0.342,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6860718171926007,
      "winogrande": 0.5090765588003157,
      "hellaswag": 0.45140410276837284,
      "boolq": 0.4055045871559633
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      4,
      2,
      16,
      10,
      12,
      8,
      6,
      6,
      10,
      8,
      12,
      6,
      8,
      4,
      6,
      8,
      4,
      6,
      16,
      8,
      6,
      16,
      12,
      6,
      4,
      4,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2832764505119454,
      "hellaswag": 0.4495120493925513,
      "arc_easy": 0.45075757575757575,
      "boolq": 0.42415902140672784,
      "openbookqa": 0.348,
      "winogrande": 0.5193370165745856,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      10,
      4,
      8,
      10,
      2,
      6,
      16,
      4,
      10,
      12,
      4,
      6,
      8,
      12,
      16,
      10,
      4,
      10,
      4,
      6,
      4,
      4,
      14,
      8,
      16,
      8,
      2,
      2,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2738907849829352,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.4739057239057239,
      "openbookqa": 0.354,
      "boolq": 0.6064220183486239,
      "hellaswag": 0.43178649671380204,
      "piqa": 0.6713819368879217
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      8,
      8,
      6,
      16,
      6,
      16,
      6,
      2,
      16,
      16,
      12,
      14,
      14,
      10,
      10,
      10,
      6,
      4,
      14,
      10,
      2,
      14,
      16,
      16,
      10,
      14,
      4,
      10,
      16,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2841296928327645,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.348,
      "piqa": 0.6871599564744287,
      "boolq": 0.43363914373088686,
      "arc_easy": 0.45580808080808083,
      "hellaswag": 0.4506074487153953
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      14,
      10,
      16,
      14,
      14,
      6,
      14,
      2,
      16,
      8,
      12,
      16,
      16,
      12,
      10,
      16,
      16,
      12,
      4,
      16,
      4,
      6,
      8,
      16,
      2,
      10,
      2,
      8,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "boolq": 0.4504587155963303,
      "winogrande": 0.516179952644041,
      "arc_easy": 0.4444444444444444,
      "arc_challenge": 0.28242320819112626,
      "hellaswag": 0.4494124676359291,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      8,
      12,
      8,
      10,
      10,
      14,
      12,
      10,
      6,
      12,
      6,
      4,
      2,
      6,
      2,
      4,
      14,
      14,
      10,
      12,
      2,
      10,
      6,
      4,
      2,
      6,
      6,
      14,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.346,
      "hellaswag": 0.4494124676359291,
      "boolq": 0.42752293577981654,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.2841296928327645
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      6,
      14,
      8,
      16,
      16,
      10,
      12,
      10,
      4,
      14,
      16,
      6,
      8,
      8,
      8,
      4,
      4,
      14,
      6,
      16,
      10,
      10,
      8,
      12,
      2,
      6,
      10,
      4,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.48256880733944957,
      "arc_easy": 0.4377104377104377,
      "piqa": 0.6855277475516867,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.4477195777733519,
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.35
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      12,
      8,
      4,
      2,
      16,
      4,
      6,
      12,
      6,
      10,
      8,
      6,
      16,
      4,
      10,
      14,
      6,
      10,
      2,
      8,
      12,
      14,
      2,
      4,
      16,
      12,
      10,
      12,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "winogrande": 0.5240726124704025,
      "arc_challenge": 0.2721843003412969,
      "arc_easy": 0.49284511784511786,
      "piqa": 0.6730141458106638,
      "boolq": 0.5804281345565749,
      "hellaswag": 0.43218482374029077
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      4,
      14,
      12,
      4,
      8,
      2,
      10,
      12,
      16,
      10,
      6,
      2,
      2,
      14,
      14,
      16,
      2,
      8,
      8,
      16,
      16,
      14,
      2,
      16,
      6,
      10,
      12,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.2713310580204778,
      "hellaswag": 0.43228440549691294,
      "winogrande": 0.5177584846093133,
      "boolq": 0.6076452599388379,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      10,
      4,
      10,
      14,
      16,
      6,
      16,
      12,
      14,
      6,
      2,
      14,
      2,
      2,
      10,
      10,
      8,
      12,
      16,
      2,
      10,
      4,
      12,
      6,
      10,
      12,
      4,
      16,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27986348122866894,
      "hellaswag": 0.4506074487153953,
      "boolq": 0.44036697247706424,
      "winogrande": 0.5303867403314917,
      "openbookqa": 0.352,
      "arc_easy": 0.45496632996632996,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      6,
      6,
      6,
      12,
      12,
      6,
      16,
      16,
      6,
      12,
      10,
      6,
      12,
      6,
      4,
      6,
      8,
      6,
      8,
      14,
      12,
      8,
      4,
      10,
      4,
      6,
      14,
      10,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2815699658703072,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.4495120493925513,
      "openbookqa": 0.348,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.46116207951070337
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      10,
      16,
      10,
      6,
      2,
      2,
      14,
      12,
      10,
      4,
      4,
      4,
      4,
      14,
      12,
      6,
      6,
      4,
      8,
      10,
      8,
      14,
      14,
      16,
      16,
      4,
      6,
      2,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6926006528835691,
      "arc_challenge": 0.28071672354948807,
      "hellaswag": 0.44971121290579563,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.40886850152905196,
      "openbookqa": 0.346,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      14,
      6,
      12,
      12,
      4,
      2,
      12,
      12,
      12,
      8,
      8,
      6,
      16,
      14,
      8,
      14,
      2,
      2,
      14,
      14,
      6,
      12,
      4,
      8,
      12,
      14,
      4,
      6,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44961163114917346,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.44486531986531985,
      "arc_challenge": 0.28754266211604096,
      "boolq": 0.4779816513761468,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.348
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      12,
      2,
      14,
      4,
      10,
      6,
      8,
      8,
      8,
      6,
      4,
      12,
      2,
      14,
      16,
      14,
      6,
      10,
      6,
      10,
      6,
      6,
      4,
      10,
      10,
      2,
      14,
      8,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4473212507468632,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.348,
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.27986348122866894,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4917431192660551
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      6,
      4,
      10,
      12,
      8,
      6,
      14,
      6,
      16,
      10,
      14,
      2,
      16,
      6,
      6,
      10,
      12,
      14,
      12,
      6,
      2,
      6,
      8,
      10,
      2,
      8,
      16,
      8,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2815699658703072,
      "arc_easy": 0.4452861952861953,
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.4519020115514838,
      "openbookqa": 0.348,
      "piqa": 0.6931447225244831,
      "boolq": 0.4792048929663609
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      16,
      16,
      4,
      6,
      12,
      2,
      8,
      8,
      6,
      14,
      10,
      2,
      8,
      10,
      6,
      16,
      10,
      10,
      2,
      12,
      16,
      16,
      2,
      12,
      12,
      12,
      4,
      10,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.27047781569965873,
      "piqa": 0.6708378672470077,
      "boolq": 0.5697247706422018,
      "hellaswag": 0.4313881696873133,
      "openbookqa": 0.358,
      "arc_easy": 0.4903198653198653
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      12,
      2,
      8,
      8,
      4,
      4,
      14,
      2,
      16,
      2,
      8,
      2,
      4,
      2,
      8,
      6,
      10,
      6,
      8,
      4,
      2,
      14,
      16,
      10,
      12,
      12,
      12,
      16,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4890572390572391,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.354,
      "boolq": 0.6027522935779817,
      "arc_challenge": 0.26706484641638223,
      "hellaswag": 0.4336785500896236,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      16,
      2,
      6,
      12,
      14,
      12,
      12,
      14,
      6,
      16,
      10,
      16,
      16,
      2,
      2,
      10,
      2,
      8,
      4,
      6,
      12,
      4,
      6,
      10,
      16,
      12,
      12,
      16,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43108942441744674,
      "openbookqa": 0.35,
      "arc_challenge": 0.27047781569965873,
      "boolq": 0.5844036697247706,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6719260065288357,
      "arc_easy": 0.48863636363636365
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      16,
      14,
      14,
      2,
      16,
      2,
      16,
      12,
      16,
      6,
      2,
      14,
      4,
      2,
      14,
      6,
      12,
      12,
      12,
      12,
      4,
      8,
      14,
      4,
      10,
      10,
      10,
      4,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6692056583242655,
      "hellaswag": 0.433877713602868,
      "arc_easy": 0.47853535353535354,
      "arc_challenge": 0.2738907849829352,
      "boolq": 0.5865443425076453
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      8,
      16,
      6,
      6,
      16,
      8,
      10,
      2,
      4,
      2,
      8,
      16,
      16,
      4,
      2,
      8,
      14,
      8,
      12,
      14,
      2,
      14,
      14,
      10,
      8,
      4,
      6,
      16,
      4,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4253822629969419,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.344,
      "arc_easy": 0.44234006734006737,
      "hellaswag": 0.44991037641904,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.27474402730375425
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      14,
      14,
      8,
      12,
      8,
      4,
      14,
      2,
      6,
      10,
      10,
      12,
      10,
      16,
      8,
      8,
      4,
      8,
      6,
      4,
      8,
      4,
      8,
      4,
      10,
      12,
      12,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27047781569965873,
      "piqa": 0.6741022850924918,
      "openbookqa": 0.354,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5932721712538226,
      "hellaswag": 0.43019318860784705
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      10,
      10,
      12,
      16,
      2,
      6,
      2,
      16,
      6,
      10,
      10,
      2,
      12,
      12,
      2,
      6,
      10,
      12,
      14,
      16,
      2,
      12,
      10,
      16,
      4,
      8,
      16,
      12,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.460016835016835,
      "openbookqa": 0.346,
      "piqa": 0.6893362350380848,
      "winogrande": 0.5295974743488555,
      "hellaswag": 0.45130452101175067,
      "arc_challenge": 0.2832764505119454,
      "boolq": 0.44801223241590216
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      14,
      14,
      8,
      12,
      2,
      12,
      12,
      4,
      16,
      14,
      14,
      4,
      2,
      8,
      2,
      4,
      14,
      10,
      12,
      2,
      2,
      12,
      4,
      2,
      8,
      12,
      12,
      10,
      2,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.352,
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4773700305810398,
      "arc_challenge": 0.28498293515358364,
      "hellaswag": 0.4494124676359291
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      10,
      2,
      14,
      4,
      16,
      6,
      6,
      8,
      8,
      10,
      6,
      4,
      10,
      4,
      4,
      10,
      2,
      14,
      16,
      2,
      14,
      10,
      4,
      12,
      6,
      6,
      8,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.4504587155963303,
      "winogrande": 0.526440410418311,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.45120493925512845,
      "arc_challenge": 0.28071672354948807,
      "openbookqa": 0.344
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      10,
      4,
      2,
      2,
      10,
      2,
      16,
      12,
      4,
      2,
      14,
      12,
      6,
      8,
      4,
      12,
      10,
      6,
      8,
      14,
      4,
      2,
      12,
      2,
      4,
      14,
      10,
      12,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.45198776758409787,
      "arc_challenge": 0.28754266211604096,
      "piqa": 0.6882480957562568,
      "openbookqa": 0.35,
      "arc_easy": 0.44486531986531985,
      "winogrande": 0.5138121546961326,
      "hellaswag": 0.44851623182632944
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      2,
      10,
      8,
      2,
      10,
      14,
      10,
      4,
      2,
      12,
      2,
      12,
      16,
      12,
      12,
      8,
      4,
      14,
      14,
      14,
      4,
      12,
      14,
      2,
      10,
      8,
      2,
      8,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6697497279651795,
      "arc_challenge": 0.27559726962457337,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.35,
      "boolq": 0.581651376146789,
      "arc_easy": 0.48653198653198654,
      "hellaswag": 0.43198566022704643
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      16,
      2,
      6,
      12,
      2,
      10,
      12,
      16,
      2,
      6,
      16,
      10,
      6,
      6,
      8,
      2,
      12,
      8,
      2,
      8,
      12,
      6,
      8,
      12,
      8,
      14,
      14,
      12,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "hellaswag": 0.4304919338777136,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.2790102389078498,
      "boolq": 0.6015290519877676,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6702937976060935
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      16,
      10,
      2,
      14,
      6,
      8,
      14,
      8,
      4,
      12,
      6,
      10,
      4,
      8,
      16,
      6,
      10,
      2,
      2,
      6,
      16,
      2,
      10,
      8,
      2,
      4,
      12,
      8,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28242320819112626,
      "winogrande": 0.5130228887134964,
      "boolq": 0.47217125382263,
      "arc_easy": 0.4457070707070707,
      "hellaswag": 0.4494124676359291,
      "openbookqa": 0.35,
      "piqa": 0.6855277475516867
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      14,
      6,
      16,
      2,
      14,
      6,
      8,
      2,
      8,
      8,
      12,
      4,
      4,
      4,
      2,
      12,
      10,
      8,
      12,
      6,
      14,
      6,
      8,
      12,
      10,
      8,
      12,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4781144781144781,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5209155485398579,
      "boolq": 0.5519877675840978,
      "openbookqa": 0.362,
      "hellaswag": 0.4307906791475802,
      "arc_challenge": 0.27303754266211605
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      14,
      6,
      16,
      8,
      10,
      4,
      12,
      16,
      6,
      2,
      10,
      12,
      8,
      8,
      2,
      16,
      12,
      16,
      2,
      10,
      14,
      4,
      14,
      14,
      8,
      10,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.342,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6719260065288357,
      "boolq": 0.5752293577981651,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.27474402730375425,
      "hellaswag": 0.4307906791475802
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      10,
      6,
      14,
      12,
      8,
      4,
      8,
      6,
      10,
      8,
      16,
      2,
      16,
      10,
      2,
      10,
      16,
      8,
      2,
      16,
      10,
      16,
      10,
      8,
      10,
      8,
      8,
      10,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "boolq": 0.5599388379204893,
      "hellaswag": 0.4343756223859789,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5138121546961326,
      "arc_challenge": 0.2696245733788396,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      12,
      6,
      2,
      8,
      8,
      16,
      6,
      16,
      12,
      8,
      12,
      16,
      8,
      12,
      10,
      16,
      14,
      4,
      12,
      10,
      14,
      14,
      6,
      12,
      12,
      8,
      12,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6,
      "hellaswag": 0.43108942441744674,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6697497279651795,
      "arc_challenge": 0.2645051194539249,
      "openbookqa": 0.354,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      4,
      6,
      2,
      2,
      6,
      6,
      8,
      10,
      8,
      10,
      16,
      16,
      8,
      8,
      4,
      16,
      8,
      6,
      6,
      8,
      2,
      2,
      10,
      16,
      2,
      6,
      14,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.44276094276094274,
      "hellaswag": 0.448814977096196,
      "piqa": 0.6866158868335147,
      "boolq": 0.4577981651376147,
      "openbookqa": 0.346,
      "arc_challenge": 0.28242320819112626
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      14,
      2,
      14,
      10,
      2,
      14,
      8,
      16,
      10,
      4,
      16,
      12,
      8,
      4,
      6,
      10,
      8,
      14,
      8,
      8,
      12,
      8,
      14,
      8,
      2,
      4,
      8,
      2,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "piqa": 0.676278563656148,
      "boolq": 0.5960244648318043,
      "openbookqa": 0.35,
      "arc_easy": 0.47853535353535354,
      "hellaswag": 0.43377813184624575,
      "arc_challenge": 0.2713310580204778
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      12,
      2,
      8,
      4,
      2,
      6,
      4,
      4,
      2,
      10,
      8,
      12,
      10,
      12,
      4,
      2,
      14,
      10,
      16,
      10,
      10,
      8,
      4,
      4,
      14,
      14,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44823232323232326,
      "winogrande": 0.5130228887134964,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.27986348122866894,
      "boolq": 0.44036697247706424,
      "openbookqa": 0.35,
      "hellaswag": 0.44921330412268473
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      12,
      10,
      2,
      6,
      8,
      6,
      14,
      16,
      12,
      14,
      2,
      10,
      14,
      6,
      14,
      10,
      16,
      2,
      10,
      4,
      6,
      12,
      14,
      8,
      14,
      12,
      2,
      8,
      12,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.47769360269360267,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.4334793865763792,
      "arc_challenge": 0.2619453924914676,
      "boolq": 0.5868501529051988,
      "openbookqa": 0.346,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      16,
      6,
      4,
      12,
      8,
      14,
      10,
      8,
      4,
      4,
      6,
      4,
      8,
      16,
      14,
      14,
      10,
      8,
      2,
      2,
      14,
      12,
      16,
      16,
      2,
      6,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "boolq": 0.46238532110091746,
      "arc_challenge": 0.2773037542662116,
      "hellaswag": 0.44831706831308504,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.44907407407407407,
      "piqa": 0.6936887921653971
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      4,
      10,
      8,
      8,
      14,
      16,
      2,
      16,
      4,
      6,
      12,
      10,
      12,
      4,
      6,
      2,
      4,
      12,
      16,
      2,
      12,
      6,
      8,
      8,
      6,
      12,
      10,
      12,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "arc_easy": 0.43602693602693604,
      "arc_challenge": 0.28754266211604096,
      "winogrande": 0.5240726124704025,
      "boolq": 0.43180428134556575,
      "hellaswag": 0.44961163114917346,
      "piqa": 0.6931447225244831
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      10,
      4,
      10,
      16,
      12,
      8,
      6,
      4,
      4,
      14,
      14,
      10,
      10,
      8,
      16,
      10,
      4,
      16,
      10,
      14,
      14,
      4,
      4,
      4,
      14,
      2,
      10,
      16,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6789989118607181,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.2790102389078498,
      "boolq": 0.5672782874617737,
      "hellaswag": 0.4320852419836686,
      "arc_easy": 0.48484848484848486,
      "openbookqa": 0.352
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      12,
      12,
      12,
      2,
      16,
      6,
      2,
      12,
      16,
      2,
      12,
      2,
      14,
      12,
      6,
      14,
      4,
      8,
      4,
      4,
      6,
      6,
      16,
      4,
      4,
      6,
      10,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4515993265993266,
      "hellaswag": 0.4502091216889066,
      "boolq": 0.42201834862385323,
      "arc_challenge": 0.2858361774744027,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      4,
      2,
      12,
      6,
      8,
      16,
      16,
      8,
      4,
      12,
      10,
      16,
      8,
      6,
      2,
      10,
      16,
      16,
      14,
      8,
      14,
      10,
      4,
      14,
      14,
      14,
      2,
      2,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.346,
      "arc_challenge": 0.28754266211604096,
      "arc_easy": 0.4444444444444444,
      "hellaswag": 0.45160326628161723,
      "boolq": 0.4415902140672783,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      16,
      6,
      8,
      10,
      16,
      12,
      6,
      12,
      6,
      6,
      10,
      16,
      16,
      16,
      6,
      6,
      10,
      10,
      14,
      16,
      12,
      6,
      8,
      10,
      2,
      10,
      16,
      8,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.427217125382263,
      "arc_challenge": 0.2815699658703072,
      "hellaswag": 0.4487153953395738,
      "winogrande": 0.5146014206787688,
      "piqa": 0.6936887921653971,
      "openbookqa": 0.352,
      "arc_easy": 0.44612794612794615
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      6,
      12,
      8,
      8,
      4,
      2,
      14,
      14,
      14,
      16,
      16,
      12,
      16,
      6,
      16,
      12,
      6,
      16,
      14,
      8,
      12,
      8,
      10,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "piqa": 0.6887921653971708,
      "boolq": 0.4666666666666667,
      "arc_easy": 0.4532828282828283,
      "hellaswag": 0.45030870344552876,
      "arc_challenge": 0.2773037542662116,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      2,
      16,
      16,
      12,
      12,
      10,
      6,
      6,
      14,
      10,
      4,
      14,
      8,
      16,
      10,
      4,
      10,
      2,
      14,
      16,
      8,
      2,
      12,
      10,
      12,
      4,
      8,
      12,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_easy": 0.4414983164983165,
      "boolq": 0.47553516819571867,
      "arc_challenge": 0.27986348122866894,
      "winogrande": 0.5098658247829518,
      "hellaswag": 0.45050786695877315,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      10,
      2,
      16,
      4,
      14,
      2,
      2,
      16,
      10,
      4,
      16,
      8,
      14,
      4,
      14,
      2,
      16,
      8,
      10,
      16,
      8,
      12,
      14,
      16,
      6,
      8,
      14,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.36,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.27303754266211605,
      "arc_easy": 0.4877946127946128,
      "boolq": 0.5899082568807339,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.4325831507667795
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      16,
      8,
      12,
      10,
      6,
      16,
      14,
      14,
      10,
      12,
      2,
      4,
      10,
      6,
      10,
      4,
      4,
      12,
      8,
      4,
      14,
      4,
      8,
      16,
      10,
      4,
      16,
      2,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_easy": 0.44654882154882153,
      "arc_challenge": 0.28242320819112626,
      "hellaswag": 0.4486158135829516,
      "openbookqa": 0.352,
      "boolq": 0.4529051987767584,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      4,
      2,
      12,
      4,
      16,
      12,
      6,
      16,
      4,
      14,
      2,
      16,
      6,
      6,
      8,
      10,
      16,
      10,
      6,
      8,
      16,
      2,
      10,
      6,
      8,
      12,
      6,
      8,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "arc_challenge": 0.26791808873720135,
      "piqa": 0.6724700761697497,
      "hellaswag": 0.4325831507667795,
      "boolq": 0.5825688073394495,
      "arc_easy": 0.48653198653198654,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      4,
      2,
      12,
      4,
      4,
      8,
      16,
      2,
      6,
      8,
      4,
      6,
      14,
      12,
      6,
      10,
      4,
      8,
      4,
      8,
      2,
      10,
      4,
      4,
      2,
      16,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6855277475516867,
      "boolq": 0.4685015290519878,
      "arc_easy": 0.45202020202020204,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5090765588003157,
      "openbookqa": 0.35,
      "hellaswag": 0.4486158135829516
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      10,
      8,
      8,
      12,
      10,
      6,
      8,
      12,
      4,
      12,
      6,
      8,
      6,
      4,
      10,
      16,
      2,
      6,
      2,
      2,
      4,
      4,
      6,
      10,
      14,
      10,
      10,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "winogrande": 0.5240726124704025,
      "hellaswag": 0.43288189603664606,
      "arc_challenge": 0.2764505119453925,
      "arc_easy": 0.4810606060606061,
      "piqa": 0.6686615886833515,
      "boolq": 0.5605504587155963
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      4,
      4,
      14,
      8,
      6,
      2,
      14,
      10,
      10,
      10,
      6,
      10,
      14,
      10,
      12,
      8,
      10,
      16,
      2,
      4,
      16,
      8,
      2,
      10,
      14,
      16,
      16,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44971121290579563,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.348,
      "arc_easy": 0.4414983164983165,
      "arc_challenge": 0.2781569965870307,
      "boolq": 0.4492354740061162,
      "piqa": 0.6898803046789989
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      6,
      4,
      14,
      8,
      8,
      8,
      16,
      12,
      12,
      12,
      10,
      8,
      4,
      6,
      12,
      6,
      2,
      10,
      14,
      16,
      8,
      4,
      16,
      4,
      16,
      14,
      10,
      14,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "arc_challenge": 0.2841296928327645,
      "boolq": 0.43486238532110094,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.4473905723905724,
      "hellaswag": 0.448814977096196,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      16,
      8,
      4,
      4,
      6,
      8,
      8,
      16,
      16,
      12,
      8,
      12,
      10,
      14,
      8,
      12,
      16,
      2,
      8,
      16,
      2,
      6,
      6,
      6,
      8,
      2,
      10,
      14,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.450408285202151,
      "arc_challenge": 0.28498293515358364,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.44654882154882153,
      "boolq": 0.4510703363914373,
      "piqa": 0.690968443960827,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      8,
      4,
      4,
      2,
      6,
      2,
      10,
      4,
      2,
      8,
      12,
      2,
      14,
      6,
      6,
      10,
      6,
      8,
      16,
      14,
      8,
      4,
      16,
      14,
      12,
      4,
      4,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.2645051194539249,
      "arc_easy": 0.48358585858585856,
      "hellaswag": 0.4318860784704242,
      "boolq": 0.5608562691131499,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      6,
      4,
      2,
      16,
      8,
      4,
      6,
      16,
      6,
      10,
      2,
      4,
      4,
      2,
      16,
      2,
      10,
      2,
      6,
      8,
      10,
      16,
      4,
      14,
      16,
      4,
      6,
      12,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4494124676359291,
      "openbookqa": 0.346,
      "arc_challenge": 0.28242320819112626,
      "piqa": 0.6882480957562568,
      "arc_easy": 0.4452861952861953,
      "winogrande": 0.5217048145224941,
      "boolq": 0.463914373088685
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      6,
      2,
      2,
      4,
      2,
      6,
      2,
      4,
      14,
      16,
      16,
      12,
      14,
      14,
      12,
      4,
      12,
      12,
      14,
      14,
      8,
      4,
      2,
      8,
      8,
      4,
      10,
      2,
      6,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5244648318042814,
      "arc_easy": 0.44865319865319864,
      "openbookqa": 0.356,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6953210010881393,
      "arc_challenge": 0.2841296928327645,
      "hellaswag": 0.4487153953395738
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      2,
      2,
      2,
      10,
      8,
      10,
      2,
      8,
      14,
      16,
      6,
      6,
      8,
      12,
      8,
      10,
      16,
      12,
      10,
      4,
      6,
      4,
      16,
      12,
      10,
      2,
      10,
      12,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6942328618063112,
      "arc_challenge": 0.28924914675767915,
      "openbookqa": 0.352,
      "hellaswag": 0.45120493925512845,
      "boolq": 0.45535168195718656,
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      12,
      16,
      16,
      14,
      6,
      4,
      2,
      6,
      10,
      8,
      6,
      14,
      14,
      12,
      10,
      12,
      6,
      2,
      4,
      14,
      16,
      10,
      16,
      4,
      4,
      6,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "piqa": 0.6719260065288357,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.4852693602693603,
      "hellaswag": 0.4312885879306911,
      "openbookqa": 0.35,
      "boolq": 0.6067278287461774
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      2,
      14,
      2,
      10,
      16,
      10,
      16,
      6,
      16,
      4,
      2,
      16,
      16,
      12,
      12,
      6,
      2,
      16,
      8,
      4,
      12,
      12,
      12,
      4,
      4,
      8,
      2,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "openbookqa": 0.352,
      "piqa": 0.6713819368879217,
      "arc_easy": 0.4970538720538721,
      "boolq": 0.6024464831804281,
      "hellaswag": 0.43397729535949015,
      "arc_challenge": 0.27986348122866894
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      4,
      2,
      14,
      4,
      8,
      2,
      4,
      16,
      10,
      10,
      8,
      14,
      8,
      4,
      6,
      16,
      14,
      8,
      8,
      16,
      16,
      8,
      14,
      6,
      4,
      8,
      6,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4363914373088685,
      "openbookqa": 0.348,
      "arc_easy": 0.4414983164983165,
      "piqa": 0.6887921653971708,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.45269866560446126,
      "arc_challenge": 0.28498293515358364
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      16,
      10,
      6,
      4,
      14,
      16,
      2,
      16,
      12,
      12,
      4,
      12,
      12,
      14,
      6,
      16,
      8,
      6,
      2,
      14,
      4,
      12,
      6,
      4,
      14,
      14,
      8,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4477195777733519,
      "boolq": 0.45351681957186546,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4393939393939394,
      "openbookqa": 0.35,
      "arc_challenge": 0.2773037542662116
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      16,
      16,
      2,
      2,
      6,
      10,
      10,
      2,
      12,
      6,
      14,
      16,
      6,
      4,
      4,
      8,
      6,
      14,
      14,
      4,
      2,
      12,
      8,
      16,
      6,
      16,
      2,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4397553516819572,
      "piqa": 0.6898803046789989,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.35,
      "hellaswag": 0.4493128858793069,
      "arc_challenge": 0.28498293515358364,
      "arc_easy": 0.4444444444444444
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      2,
      8,
      2,
      10,
      6,
      4,
      16,
      2,
      12,
      8,
      8,
      12,
      2,
      6,
      6,
      4,
      2,
      14,
      6,
      2,
      2,
      8,
      4,
      4,
      10,
      10,
      14,
      6,
      10,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4351851851851852,
      "boolq": 0.4892966360856269,
      "openbookqa": 0.342,
      "winogrande": 0.5335438042620363,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.2738907849829352,
      "hellaswag": 0.45180242979486157
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      16,
      12,
      10,
      2,
      2,
      8,
      6,
      4,
      6,
      14,
      4,
      12,
      16,
      4,
      10,
      12,
      14,
      6,
      4,
      14,
      12,
      14,
      4,
      2,
      2,
      4,
      10,
      2,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.47853535353535354,
      "hellaswag": 0.4314877514439355,
      "arc_challenge": 0.27303754266211605,
      "openbookqa": 0.352,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6692056583242655,
      "boolq": 0.5844036697247706
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      8,
      4,
      12,
      16,
      2,
      16,
      10,
      2,
      8,
      4,
      4,
      8,
      8,
      2,
      6,
      10,
      14,
      14,
      8,
      6,
      4,
      12,
      6,
      16,
      4,
      6,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44612794612794615,
      "piqa": 0.6849836779107725,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.4500099581756622,
      "openbookqa": 0.344,
      "boolq": 0.42660550458715596,
      "arc_challenge": 0.2790102389078498
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      4,
      14,
      14,
      2,
      10,
      14,
      6,
      4,
      10,
      14,
      6,
      6,
      14,
      2,
      16,
      4,
      10,
      16,
      6,
      10,
      2,
      10,
      10,
      16,
      10,
      8,
      2,
      12,
      6,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43537143995220073,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.2687713310580205,
      "arc_easy": 0.4890572390572391,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.354,
      "boolq": 0.5758409785932722
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      2,
      16,
      12,
      2,
      6,
      2,
      14,
      4,
      14,
      4,
      16,
      14,
      6,
      8,
      2,
      12,
      8,
      16,
      14,
      14,
      10,
      12,
      4,
      8,
      16,
      16,
      8,
      8,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "arc_challenge": 0.2721843003412969,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.433379804819757,
      "winogrande": 0.5082872928176796,
      "arc_easy": 0.48695286195286197,
      "boolq": 0.5724770642201835
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      6,
      6,
      16,
      4,
      12,
      2,
      16,
      2,
      12,
      6,
      12,
      6,
      8,
      14,
      16,
      2,
      10,
      10,
      6,
      12,
      2,
      16,
      2,
      10,
      12,
      6,
      6,
      16,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4501095399322844,
      "piqa": 0.6860718171926007,
      "boolq": 0.4892966360856269,
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.2832764505119454,
      "openbookqa": 0.354,
      "arc_easy": 0.4398148148148148
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      6,
      4,
      6,
      14,
      16,
      4,
      14,
      10,
      8,
      8,
      4,
      4,
      10,
      12,
      2,
      16,
      16,
      6,
      8,
      10,
      14,
      8,
      8,
      4,
      12,
      16,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4464250149372635,
      "openbookqa": 0.344,
      "winogrande": 0.5201262825572218,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.27559726962457337,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4648318042813456
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      14,
      12,
      6,
      2,
      12,
      2,
      16,
      10,
      16,
      14,
      4,
      4,
      14,
      10,
      14,
      12,
      12,
      16,
      16,
      10,
      4,
      6,
      2,
      16,
      16,
      10,
      8,
      14,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.354,
      "boolq": 0.5773700305810398,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6702937976060935,
      "hellaswag": 0.43308105954989046
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      2,
      12,
      8,
      10,
      4,
      14,
      14,
      10,
      6,
      4,
      16,
      8,
      2,
      14,
      12,
      16,
      6,
      12,
      10,
      10,
      16,
      2,
      16,
      16,
      12,
      4,
      14,
      16,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27986348122866894,
      "hellaswag": 0.4501095399322844,
      "boolq": 0.4837920489296636,
      "openbookqa": 0.342,
      "piqa": 0.691512513601741,
      "arc_easy": 0.4532828282828283,
      "winogrande": 0.5248618784530387
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      8,
      6,
      4,
      4,
      2,
      12,
      4,
      6,
      14,
      2,
      10,
      8,
      10,
      12,
      2,
      12,
      10,
      16,
      4,
      6,
      16,
      8,
      6,
      2,
      12,
      2,
      2,
      16,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4802188552188552,
      "arc_challenge": 0.2696245733788396,
      "hellaswag": 0.4325831507667795,
      "openbookqa": 0.344,
      "piqa": 0.6702937976060935,
      "boolq": 0.5972477064220183,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      2,
      12,
      6,
      4,
      12,
      14,
      14,
      6,
      12,
      10,
      16,
      12,
      4,
      14,
      10,
      4,
      14,
      4,
      12,
      8,
      10,
      2,
      8,
      12,
      6,
      6,
      6,
      6,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.45120493925512845,
      "arc_easy": 0.44276094276094274,
      "boolq": 0.41834862385321103,
      "openbookqa": 0.348,
      "arc_challenge": 0.28242320819112626,
      "winogrande": 0.5240726124704025,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      2,
      12,
      6,
      12,
      6,
      4,
      4,
      10,
      12,
      4,
      2,
      14,
      10,
      6,
      8,
      6,
      2,
      6,
      14,
      6,
      12,
      10,
      12,
      16,
      14,
      16,
      14,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "boolq": 0.4819571865443425,
      "arc_challenge": 0.28242320819112626,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.6860718171926007,
      "openbookqa": 0.342,
      "hellaswag": 0.4493128858793069
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      8,
      8,
      4,
      12,
      2,
      16,
      12,
      4,
      16,
      8,
      8,
      12,
      8,
      10,
      4,
      4,
      14,
      2,
      4,
      6,
      12,
      2,
      2,
      12,
      8,
      2,
      14,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "openbookqa": 0.342,
      "boolq": 0.5920489296636086,
      "arc_easy": 0.48569023569023567,
      "hellaswag": 0.4313881696873133,
      "arc_challenge": 0.26791808873720135,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      12,
      4,
      2,
      10,
      14,
      14,
      14,
      8,
      6,
      8,
      10,
      2,
      6,
      2,
      12,
      16,
      12,
      4,
      2,
      2,
      4,
      14,
      10,
      14,
      16,
      16,
      10,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.55565749235474,
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.26621160409556316,
      "piqa": 0.6735582154515778,
      "openbookqa": 0.352,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.4325831507667795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      16,
      8,
      8,
      6,
      12,
      14,
      16,
      2,
      16,
      10,
      14,
      8,
      10,
      10,
      4,
      16,
      4,
      6,
      4,
      6,
      6,
      2,
      14,
      14,
      10,
      10,
      14,
      16,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43158733320055764,
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.2696245733788396,
      "winogrande": 0.5098658247829518,
      "boolq": 0.5715596330275229,
      "arc_easy": 0.48695286195286197,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      4,
      14,
      4,
      12,
      6,
      2,
      2,
      16,
      2,
      12,
      14,
      10,
      8,
      6,
      8,
      10,
      10,
      2,
      4,
      2,
      10,
      4,
      14,
      12,
      6,
      12,
      6,
      8,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.4508066122286397,
      "arc_challenge": 0.2815699658703072,
      "boolq": 0.5061162079510704,
      "arc_easy": 0.44823232323232326,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      8,
      4,
      12,
      16,
      8,
      6,
      2,
      16,
      14,
      14,
      4,
      12,
      2,
      6,
      6,
      8,
      6,
      10,
      2,
      6,
      14,
      14,
      10,
      8,
      12,
      6,
      12,
      6,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4312885879306911,
      "arc_easy": 0.4802188552188552,
      "boolq": 0.5571865443425077,
      "piqa": 0.676278563656148,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.344,
      "arc_challenge": 0.27986348122866894
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      16,
      16,
      4,
      2,
      8,
      4,
      14,
      10,
      6,
      4,
      4,
      12,
      6,
      4,
      16,
      14,
      2,
      4,
      16,
      8,
      2,
      8,
      14,
      12,
      12,
      16,
      16,
      2,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28498293515358364,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.346,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.4672782874617737,
      "piqa": 0.690424374319913,
      "hellaswag": 0.44991037641904
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      10,
      6,
      8,
      10,
      10,
      4,
      14,
      8,
      2,
      8,
      16,
      10,
      12,
      16,
      16,
      6,
      8,
      4,
      12,
      4,
      8,
      2,
      10,
      8,
      14,
      12,
      2,
      10,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.348,
      "hellaswag": 0.4493128858793069,
      "boolq": 0.48073394495412847,
      "arc_challenge": 0.28242320819112626,
      "arc_easy": 0.44402356902356904,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      14,
      16,
      16,
      16,
      8,
      14,
      10,
      10,
      14,
      16,
      16,
      8,
      14,
      6,
      2,
      14,
      12,
      12,
      8,
      12,
      16,
      12,
      12,
      16,
      10,
      8,
      16,
      2,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "arc_challenge": 0.27986348122866894,
      "winogrande": 0.5177584846093133,
      "boolq": 0.45504587155963305,
      "hellaswag": 0.4486158135829516,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4377104377104377
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      10,
      16,
      10,
      16,
      8,
      2,
      4,
      10,
      16,
      2,
      2,
      10,
      14,
      10,
      10,
      12,
      12,
      16,
      6,
      2,
      10,
      10,
      12,
      10,
      6,
      16,
      12,
      14,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "openbookqa": 0.35,
      "arc_challenge": 0.27047781569965873,
      "boolq": 0.5984709480122324,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.4327823142800239,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      8,
      8,
      10,
      14,
      2,
      12,
      10,
      2,
      4,
      6,
      14,
      16,
      2,
      10,
      6,
      10,
      10,
      16,
      16,
      12,
      2,
      6,
      2,
      12,
      2,
      10,
      6,
      14,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4510057757418841,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.28242320819112626,
      "openbookqa": 0.348,
      "arc_easy": 0.45454545454545453,
      "piqa": 0.6893362350380848,
      "boolq": 0.42079510703363915
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      6,
      16,
      4,
      8,
      14,
      2,
      10,
      14,
      4,
      10,
      12,
      12,
      12,
      8,
      12,
      8,
      4,
      14,
      4,
      4,
      10,
      4,
      4,
      8,
      10,
      12,
      4,
      10,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4503367003367003,
      "boolq": 0.5266055045871559,
      "hellaswag": 0.44961163114917346,
      "winogrande": 0.5240726124704025,
      "openbookqa": 0.346,
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.27986348122866894
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      16,
      8,
      12,
      6,
      8,
      8,
      6,
      4,
      14,
      8,
      8,
      4,
      16,
      6,
      14,
      16,
      2,
      4,
      12,
      2,
      10,
      4,
      2,
      16,
      14,
      12,
      6,
      12,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5935779816513761,
      "piqa": 0.6751904243743199,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.4823232323232323,
      "arc_challenge": 0.27559726962457337,
      "openbookqa": 0.356,
      "hellaswag": 0.433877713602868
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      8,
      6,
      6,
      6,
      2,
      8,
      2,
      14,
      12,
      6,
      12,
      4,
      6,
      10,
      14,
      4,
      16,
      12,
      2,
      14,
      14,
      12,
      8,
      14,
      6,
      6,
      4,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "arc_easy": 0.48484848484848486,
      "hellaswag": 0.43178649671380204,
      "arc_challenge": 0.27559726962457337,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6730141458106638,
      "boolq": 0.5675840978593272
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      4,
      8,
      10,
      8,
      8,
      8,
      14,
      6,
      8,
      12,
      12,
      14,
      6,
      12,
      10,
      10,
      4,
      16,
      14,
      10,
      16,
      16,
      12,
      4,
      10,
      16,
      6,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "winogrande": 0.516179952644041,
      "boolq": 0.43547400611620796,
      "piqa": 0.6844396082698585,
      "arc_easy": 0.45454545454545453,
      "hellaswag": 0.45050786695877315,
      "arc_challenge": 0.2883959044368601
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      6,
      10,
      10,
      16,
      14,
      8,
      6,
      4,
      8,
      2,
      8,
      6,
      14,
      16,
      8,
      14,
      4,
      4,
      16,
      8,
      4,
      2,
      10,
      12,
      16,
      2,
      6,
      8,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4506074487153953,
      "boolq": 0.47889908256880737,
      "openbookqa": 0.344,
      "winogrande": 0.516179952644041,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4574915824915825,
      "arc_challenge": 0.28071672354948807
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      2,
      8,
      12,
      6,
      10,
      6,
      2,
      14,
      10,
      8,
      16,
      6,
      16,
      16,
      16,
      6,
      12,
      8,
      10,
      16,
      14,
      4,
      2,
      8,
      10,
      12,
      12,
      12,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2773037542662116,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5232415902140672,
      "openbookqa": 0.346,
      "winogrande": 0.5122336227308603,
      "hellaswag": 0.4506074487153953,
      "piqa": 0.6866158868335147
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      4,
      14,
      6,
      6,
      12,
      10,
      16,
      12,
      2,
      6,
      2,
      14,
      4,
      4,
      10,
      12,
      2,
      14,
      4,
      10,
      12,
      6,
      14,
      4,
      10,
      8,
      4,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_challenge": 0.26706484641638223,
      "boolq": 0.6137614678899083,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.43069109739095796,
      "arc_easy": 0.4802188552188552,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      2,
      2,
      8,
      10,
      2,
      2,
      6,
      10,
      14,
      16,
      14,
      12,
      8,
      6,
      12,
      8,
      10,
      12,
      10,
      2,
      12,
      10,
      16,
      16,
      12,
      16,
      4,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.572782874617737,
      "openbookqa": 0.344,
      "hellaswag": 0.4303923521210914,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5146014206787688,
      "arc_challenge": 0.26706484641638223,
      "arc_easy": 0.48148148148148145
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      8,
      10,
      2,
      14,
      14,
      16,
      10,
      16,
      8,
      4,
      14,
      8,
      12,
      6,
      12,
      14,
      10,
      2,
      4,
      10,
      2,
      4,
      16,
      2,
      2,
      2,
      16,
      12,
      4,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4311890061740689,
      "openbookqa": 0.356,
      "winogrande": 0.5082872928176796,
      "boolq": 0.5697247706422018,
      "arc_challenge": 0.2687713310580205,
      "arc_easy": 0.48484848484848486,
      "piqa": 0.6779107725788901
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      2,
      8,
      6,
      14,
      4,
      14,
      4,
      8,
      14,
      2,
      14,
      16,
      12,
      6,
      2,
      6,
      2,
      14,
      10,
      4,
      2,
      6,
      2,
      6,
      12,
      6,
      8,
      12,
      6,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "piqa": 0.6866158868335147,
      "winogrande": 0.5217048145224941,
      "boolq": 0.41437308868501527,
      "hellaswag": 0.4484166500697072,
      "arc_challenge": 0.2815699658703072,
      "arc_easy": 0.44023569023569026
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      10,
      10,
      4,
      2,
      12,
      10,
      16,
      4,
      14,
      16,
      6,
      10,
      12,
      14,
      12,
      8,
      2,
      8,
      10,
      8,
      4,
      2,
      6,
      6,
      2,
      16,
      12,
      10,
      4,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.358,
      "arc_challenge": 0.26706484641638223,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.43198566022704643,
      "boolq": 0.5654434250764526,
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      6,
      2,
      12,
      8,
      16,
      12,
      10,
      4,
      2,
      16,
      10,
      16,
      12,
      14,
      8,
      8,
      12,
      12,
      8,
      2,
      4,
      6,
      14,
      8,
      16,
      4,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.45130452101175067,
      "boolq": 0.43149847094801225,
      "openbookqa": 0.344,
      "arc_easy": 0.44065656565656564,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.2858361774744027,
      "piqa": 0.6926006528835691
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      4,
      10,
      6,
      8,
      16,
      14,
      14,
      12,
      14,
      10,
      8,
      12,
      6,
      4,
      10,
      2,
      6,
      8,
      14,
      14,
      4,
      12,
      4,
      10,
      6,
      2,
      14,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "boolq": 0.4559633027522936,
      "openbookqa": 0.35,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.4431818181818182,
      "arc_challenge": 0.2832764505119454,
      "hellaswag": 0.4500099581756622
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      4,
      16,
      16,
      14,
      10,
      10,
      2,
      2,
      8,
      6,
      14,
      8,
      14,
      4,
      10,
      14,
      16,
      12,
      12,
      16,
      14,
      12,
      14,
      14,
      16,
      6,
      10,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4819571865443425,
      "arc_easy": 0.4473905723905724,
      "hellaswag": 0.4471220872336188,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6877040261153428,
      "openbookqa": 0.348,
      "arc_challenge": 0.2858361774744027
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      6,
      6,
      14,
      8,
      8,
      12,
      16,
      6,
      12,
      14,
      8,
      14,
      10,
      4,
      16,
      16,
      6,
      16,
      6,
      2,
      16,
      6,
      12,
      14,
      10,
      8,
      8,
      2,
      16,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.27474402730375425,
      "boolq": 0.5886850152905199,
      "openbookqa": 0.348,
      "hellaswag": 0.43069109739095796,
      "arc_easy": 0.47769360269360267,
      "piqa": 0.6773667029379761
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      4,
      16,
      2,
      12,
      10,
      8,
      10,
      14,
      12,
      14,
      8,
      14,
      10,
      2,
      8,
      16,
      8,
      8,
      10,
      10,
      8,
      10,
      10,
      8,
      2,
      6,
      4,
      14,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5193370165745856,
      "boolq": 0.45504587155963305,
      "openbookqa": 0.35,
      "piqa": 0.6871599564744287,
      "arc_easy": 0.44065656565656564,
      "arc_challenge": 0.2841296928327645,
      "hellaswag": 0.4493128858793069
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      2,
      8,
      14,
      8,
      6,
      6,
      8,
      8,
      8,
      16,
      8,
      14,
      6,
      8,
      6,
      12,
      8,
      8,
      8,
      12,
      10,
      4,
      6,
      6,
      8,
      16,
      16,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676822633297062,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.2738907849829352,
      "hellaswag": 0.43089026090420235,
      "arc_easy": 0.492003367003367,
      "boolq": 0.582262996941896,
      "openbookqa": 0.342
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      6,
      4,
      4,
      10,
      12,
      16,
      14,
      14,
      6,
      10,
      8,
      4,
      16,
      2,
      16,
      4,
      10,
      16,
      10,
      6,
      16,
      4,
      8,
      10,
      8,
      4,
      2,
      10,
      4,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.2636518771331058,
      "openbookqa": 0.346,
      "boolq": 0.5840978593272171,
      "hellaswag": 0.43238398725353516
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      10,
      4,
      12,
      8,
      14,
      4,
      8,
      2,
      12,
      12,
      10,
      14,
      2,
      2,
      8,
      10,
      12,
      6,
      12,
      10,
      6,
      6,
      6,
      6,
      8,
      16,
      8,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.450408285202151,
      "openbookqa": 0.344,
      "piqa": 0.690968443960827,
      "arc_challenge": 0.27986348122866894,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.41987767584097857,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      14,
      4,
      16,
      8,
      4,
      8,
      14,
      12,
      16,
      12,
      8,
      14,
      10,
      2,
      12,
      2,
      4,
      8,
      8,
      4,
      14,
      16,
      2,
      6,
      2,
      2,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4831649831649832,
      "boolq": 0.5617737003058104,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.4331806413065126,
      "openbookqa": 0.354,
      "winogrande": 0.5224940805051302,
      "arc_challenge": 0.26791808873720135
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      8,
      10,
      2,
      4,
      10,
      14,
      8,
      16,
      4,
      12,
      4,
      6,
      12,
      10,
      6,
      12,
      8,
      8,
      14,
      2,
      16,
      2,
      6,
      4,
      2,
      6,
      16,
      12,
      6,
      2,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "piqa": 0.6719260065288357,
      "arc_challenge": 0.26706484641638223,
      "boolq": 0.5626911314984709,
      "winogrande": 0.510655090765588,
      "arc_easy": 0.48569023569023567,
      "hellaswag": 0.427504481179048
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      2,
      4,
      8,
      12,
      10,
      6,
      14,
      6,
      14,
      14,
      10,
      4,
      4,
      6,
      6,
      2,
      14,
      12,
      2,
      4,
      2,
      4,
      12,
      12,
      16,
      12,
      2,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4596330275229358,
      "arc_easy": 0.4574915824915825,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.4494124676359291,
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.346,
      "piqa": 0.6931447225244831
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      14,
      10,
      16,
      4,
      8,
      14,
      6,
      10,
      14,
      2,
      16,
      14,
      2,
      2,
      6,
      6,
      8,
      16,
      4,
      12,
      8,
      10,
      6,
      8,
      4,
      14,
      14,
      6,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5009174311926605,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6866158868335147,
      "hellaswag": 0.44811790479984065,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.4478114478114478,
      "openbookqa": 0.348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      12,
      16,
      8,
      8,
      14,
      10,
      8,
      8,
      16,
      14,
      6,
      16,
      2,
      12,
      4,
      10,
      10,
      6,
      16,
      4,
      16,
      4,
      12,
      12,
      4,
      6,
      2,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27474402730375425,
      "boolq": 0.5541284403669725,
      "openbookqa": 0.346,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.48653198653198654,
      "hellaswag": 0.43527185819557856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      12,
      2,
      12,
      12,
      16,
      12,
      2,
      2,
      14,
      16,
      8,
      4,
      16,
      8,
      12,
      2,
      4,
      12,
      16,
      10,
      12,
      4,
      14,
      10,
      10,
      2,
      2,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43168691495717987,
      "winogrande": 0.5153906866614049,
      "arc_challenge": 0.2696245733788396,
      "piqa": 0.6730141458106638,
      "openbookqa": 0.35,
      "arc_easy": 0.4819023569023569,
      "boolq": 0.6018348623853211
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      8,
      2,
      4,
      6,
      2,
      2,
      12,
      10,
      8,
      16,
      14,
      6,
      2,
      16,
      2,
      12,
      10,
      2,
      10,
      4,
      16,
      10,
      12,
      8,
      8,
      16,
      8,
      10,
      12,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6849836779107725,
      "openbookqa": 0.342,
      "boolq": 0.43363914373088686,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.45130452101175067,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.28242320819112626
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      6,
      4,
      4,
      2,
      6,
      16,
      12,
      6,
      10,
      16,
      6,
      10,
      4,
      10,
      8,
      16,
      4,
      4,
      16,
      16,
      14,
      14,
      16,
      8,
      16,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2713310580204778,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.35,
      "winogrande": 0.5082872928176796,
      "boolq": 0.5847094801223242,
      "piqa": 0.676822633297062,
      "hellaswag": 0.4297948615813583
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      16,
      8,
      6,
      10,
      6,
      14,
      8,
      12,
      4,
      4,
      14,
      6,
      14,
      16,
      16,
      14,
      2,
      12,
      14,
      12,
      4,
      10,
      16,
      6,
      10,
      8,
      8,
      6,
      14,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "hellaswag": 0.44981079466241786,
      "boolq": 0.4363914373088685,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.2781569965870307,
      "openbookqa": 0.344,
      "arc_easy": 0.4515993265993266
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      4,
      10,
      6,
      8,
      16,
      4,
      2,
      6,
      16,
      4,
      6,
      2,
      4,
      8,
      16,
      4,
      6,
      8,
      16,
      2,
      16,
      14,
      14,
      8,
      10,
      6,
      12,
      4,
      4,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "boolq": 0.4672782874617737,
      "winogrande": 0.5232833464877664,
      "piqa": 0.690424374319913,
      "openbookqa": 0.348,
      "hellaswag": 0.45070703047201754,
      "arc_challenge": 0.2815699658703072
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      12,
      10,
      14,
      2,
      10,
      4,
      12,
      12,
      4,
      8,
      2,
      8,
      10,
      10,
      10,
      16,
      4,
      8,
      8,
      8,
      12,
      8,
      6,
      8,
      12,
      12,
      16,
      2,
      16,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4305915156343358,
      "arc_easy": 0.48358585858585856,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.354,
      "boolq": 0.5828746177370031,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.26023890784982934
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      4,
      10,
      14,
      4,
      12,
      12,
      6,
      2,
      6,
      10,
      16,
      14,
      2,
      12,
      4,
      16,
      4,
      4,
      10,
      8,
      14,
      8,
      4,
      4,
      2,
      4,
      2,
      6,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4902140672782875,
      "winogrande": 0.5240726124704025,
      "openbookqa": 0.346,
      "piqa": 0.6936887921653971,
      "arc_challenge": 0.28924914675767915,
      "hellaswag": 0.4493128858793069
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      8,
      16,
      14,
      2,
      4,
      14,
      4,
      8,
      16,
      6,
      8,
      6,
      2,
      14,
      4,
      2,
      10,
      8,
      16,
      4,
      10,
      10,
      4,
      2,
      14,
      6,
      10,
      14,
      6,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4484166500697072,
      "arc_easy": 0.4494949494949495,
      "openbookqa": 0.342,
      "winogrande": 0.516179952644041,
      "piqa": 0.691512513601741,
      "arc_challenge": 0.28754266211604096,
      "boolq": 0.42813455657492355
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      12,
      6,
      16,
      6,
      12,
      6,
      16,
      4,
      14,
      4,
      4,
      6,
      2,
      10,
      16,
      14,
      14,
      4,
      6,
      6,
      10,
      14,
      16,
      14,
      6,
      16,
      2,
      8,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.40489296636085625,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.4501095399322844,
      "openbookqa": 0.35,
      "piqa": 0.6855277475516867,
      "arc_challenge": 0.28071672354948807,
      "arc_easy": 0.44107744107744107
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      4,
      4,
      12,
      6,
      16,
      12,
      6,
      14,
      4,
      12,
      2,
      10,
      8,
      16,
      14,
      10,
      6,
      6,
      4,
      2,
      8,
      2,
      10,
      10,
      4,
      4,
      10,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6882480957562568,
      "hellaswag": 0.44851623182632944,
      "openbookqa": 0.346,
      "arc_challenge": 0.2815699658703072,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.5244648318042814,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      12,
      6,
      12,
      10,
      14,
      4,
      2,
      6,
      2,
      16,
      16,
      4,
      4,
      16,
      2,
      2,
      2,
      4,
      10,
      12,
      8,
      14,
      4,
      2,
      4,
      2,
      2,
      4,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.36,
      "hellaswag": 0.4331806413065126,
      "winogrande": 0.5153906866614049,
      "arc_challenge": 0.26706484641638223,
      "boolq": 0.5694189602446483,
      "piqa": 0.676822633297062,
      "arc_easy": 0.48442760942760943
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      2,
      12,
      4,
      10,
      2,
      16,
      16,
      10,
      10,
      4,
      6,
      14,
      10,
      14,
      8,
      4,
      6,
      16,
      2,
      8,
      10,
      6,
      2,
      8,
      8,
      4,
      2,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28498293515358364,
      "arc_easy": 0.4511784511784512,
      "openbookqa": 0.348,
      "winogrande": 0.5209155485398579,
      "boolq": 0.42782874617737005,
      "hellaswag": 0.44991037641904,
      "piqa": 0.6844396082698585
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      12,
      12,
      6,
      12,
      16,
      12,
      2,
      4,
      16,
      2,
      14,
      8,
      10,
      14,
      4,
      4,
      8,
      8,
      6,
      10,
      14,
      16,
      8,
      4,
      8,
      4,
      2,
      12,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6681175190424374,
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.35,
      "hellaswag": 0.4314877514439355,
      "arc_easy": 0.49284511784511786,
      "boolq": 0.5807339449541284,
      "arc_challenge": 0.2764505119453925
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      6,
      2,
      14,
      16,
      4,
      2,
      14,
      16,
      4,
      16,
      6,
      14,
      12,
      10,
      2,
      10,
      8,
      12,
      8,
      10,
      10,
      2,
      14,
      4,
      2,
      2,
      2,
      4,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.28498293515358364,
      "boolq": 0.45382262996941897,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.4493128858793069
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      14,
      8,
      12,
      16,
      10,
      16,
      2,
      12,
      4,
      12,
      10,
      10,
      8,
      6,
      12,
      4,
      12,
      8,
      6,
      14,
      12,
      8,
      4,
      10,
      6,
      14,
      14,
      12,
      4,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "piqa": 0.6887921653971708,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.28668941979522183,
      "hellaswag": 0.4482174865564629,
      "boolq": 0.4902140672782875,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      6,
      6,
      12,
      4,
      8,
      12,
      4,
      2,
      16,
      12,
      12,
      2,
      8,
      8,
      16,
      14,
      4,
      8,
      6,
      16,
      12,
      12,
      6,
      6,
      8,
      14,
      14,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4312885879306911,
      "arc_challenge": 0.2721843003412969,
      "openbookqa": 0.354,
      "piqa": 0.6719260065288357,
      "winogrande": 0.516179952644041,
      "boolq": 0.5770642201834862,
      "arc_easy": 0.4819023569023569
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      16,
      10,
      14,
      8,
      10,
      10,
      4,
      8,
      4,
      2,
      12,
      6,
      4,
      8,
      16,
      6,
      16,
      8,
      12,
      10,
      4,
      12,
      14,
      6,
      14,
      16,
      8,
      2,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.348,
      "arc_easy": 0.4385521885521885,
      "arc_challenge": 0.2841296928327645,
      "boolq": 0.4724770642201835,
      "hellaswag": 0.44851623182632944,
      "piqa": 0.690424374319913
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      12,
      10,
      14,
      14,
      8,
      16,
      16,
      4,
      6,
      4,
      2,
      2,
      2,
      16,
      14,
      6,
      10,
      16,
      10,
      8,
      2,
      14,
      4,
      10,
      12,
      14,
      12,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4537037037037037,
      "hellaswag": 0.4508066122286397,
      "boolq": 0.45137614678899085,
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.354,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      14,
      10,
      10,
      12,
      4,
      6,
      4,
      14,
      10,
      4,
      14,
      14,
      2,
      12,
      8,
      10,
      2,
      14,
      10,
      4,
      2,
      10,
      16,
      14,
      4,
      10,
      8,
      4,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4308868501529052,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6936887921653971,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5074980268350434,
      "hellaswag": 0.44971121290579563,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      10,
      2,
      12,
      4,
      6,
      12,
      2,
      8,
      12,
      16,
      8,
      8,
      10,
      14,
      14,
      16,
      16,
      4,
      16,
      6,
      12,
      6,
      8,
      2,
      8,
      14,
      2,
      14,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6730141458106638,
      "boolq": 0.5749235474006116,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.4298944433379805,
      "arc_challenge": 0.2713310580204778
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      6,
      6,
      14,
      10,
      6,
      14,
      12,
      12,
      4,
      6,
      12,
      6,
      4,
      16,
      16,
      8,
      10,
      6,
      14,
      14,
      14,
      12,
      16,
      12,
      14,
      4,
      8,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5003058103975535,
      "arc_challenge": 0.2841296928327645,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.4523003385779725,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      6,
      8,
      2,
      8,
      10,
      8,
      16,
      6,
      8,
      4,
      8,
      12,
      2,
      16,
      12,
      8,
      14,
      16,
      14,
      12,
      8,
      6,
      8,
      10,
      8,
      6,
      6,
      8,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "boolq": 0.5850152905198777,
      "arc_easy": 0.4877946127946128,
      "hellaswag": 0.4312885879306911,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.2738907849829352,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      8,
      16,
      16,
      14,
      12,
      8,
      14,
      16,
      12,
      16,
      4,
      4,
      10,
      6,
      4,
      2,
      12,
      2,
      14,
      12,
      2,
      6,
      10,
      10,
      14,
      14,
      10,
      12,
      16,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "winogrande": 0.5059194948697711,
      "arc_challenge": 0.2781569965870307,
      "hellaswag": 0.4336785500896236,
      "boolq": 0.590519877675841,
      "openbookqa": 0.356,
      "arc_easy": 0.48484848484848486
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      8,
      10,
      14,
      2,
      4,
      6,
      14,
      6,
      12,
      8,
      12,
      4,
      10,
      14,
      12,
      2,
      14,
      10,
      6,
      4,
      10,
      12,
      12,
      16,
      16,
      6,
      6,
      12,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.4503367003367003,
      "boolq": 0.4363914373088685,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.28924914675767915,
      "hellaswag": 0.4509061939852619,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      14,
      6,
      12,
      2,
      8,
      16,
      4,
      10,
      12,
      10,
      6,
      4,
      4,
      8,
      2,
      2,
      10,
      2,
      8,
      8,
      12,
      12,
      2,
      8,
      14,
      6,
      4,
      10,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4436026936026936,
      "openbookqa": 0.348,
      "boolq": 0.45137614678899085,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5067087608524072,
      "hellaswag": 0.44761999601672975,
      "arc_challenge": 0.28071672354948807
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      4,
      6,
      2,
      4,
      12,
      10,
      2,
      10,
      2,
      2,
      14,
      12,
      4,
      4,
      10,
      6,
      12,
      6,
      10,
      16,
      8,
      8,
      4,
      4,
      12,
      14,
      16,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "winogrande": 0.5217048145224941,
      "piqa": 0.6887921653971708,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.4506074487153953,
      "arc_challenge": 0.28498293515358364,
      "boolq": 0.47186544342507647
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      8,
      2,
      6,
      12,
      10,
      14,
      12,
      10,
      12,
      16,
      12,
      8,
      12,
      2,
      2,
      10,
      2,
      16,
      6,
      2,
      12,
      10,
      4,
      2,
      16,
      12,
      14,
      14,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2832764505119454,
      "piqa": 0.6855277475516867,
      "openbookqa": 0.348,
      "arc_easy": 0.44234006734006737,
      "boolq": 0.4706422018348624,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.44981079466241786
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      14,
      10,
      8,
      6,
      8,
      2,
      2,
      6,
      12,
      12,
      6,
      14,
      8,
      6,
      8,
      12,
      14,
      2,
      2,
      8,
      8,
      2,
      12,
      16,
      8,
      16,
      14,
      8,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44981079466241786,
      "winogrande": 0.5090765588003157,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.44865319865319864,
      "openbookqa": 0.352,
      "boolq": 0.46452599388379207,
      "arc_challenge": 0.27986348122866894
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      8,
      2,
      16,
      8,
      12,
      16,
      14,
      4,
      8,
      4,
      14,
      6,
      2,
      14,
      14,
      8,
      2,
      14,
      2,
      6,
      2,
      2,
      14,
      4,
      8,
      4,
      16,
      2,
      10,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "winogrande": 0.5177584846093133,
      "boolq": 0.555045871559633,
      "arc_challenge": 0.26535836177474403,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.43009360685122483,
      "arc_easy": 0.4911616161616162
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      4,
      2,
      16,
      2,
      2,
      6,
      12,
      8,
      10,
      6,
      2,
      14,
      14,
      10,
      10,
      10,
      8,
      8,
      14,
      8,
      14,
      10,
      8,
      8,
      6,
      2,
      16,
      14,
      16,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44107744107744107,
      "boolq": 0.41804281345565747,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6871599564744287,
      "openbookqa": 0.35,
      "hellaswag": 0.45130452101175067,
      "arc_challenge": 0.27559726962457337
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      12,
      6,
      8,
      4,
      16,
      14,
      16,
      8,
      8,
      16,
      6,
      4,
      6,
      14,
      4,
      2,
      16,
      4,
      2,
      12,
      12,
      14,
      6,
      2,
      4,
      12,
      6,
      4,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "arc_challenge": 0.2841296928327645,
      "piqa": 0.6855277475516867,
      "hellaswag": 0.4487153953395738,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5100917431192661,
      "winogrande": 0.5224940805051302
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      6,
      8,
      16,
      6,
      2,
      12,
      4,
      4,
      4,
      8,
      16,
      14,
      2,
      12,
      8,
      8,
      8,
      16,
      2,
      14,
      14,
      6,
      12,
      8,
      12,
      2,
      10,
      6,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4325831507667795,
      "arc_challenge": 0.2781569965870307,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.5749235474006116,
      "openbookqa": 0.344,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      4,
      16,
      14,
      8,
      4,
      16,
      2,
      10,
      8,
      4,
      10,
      6,
      14,
      2,
      12,
      6,
      12,
      16,
      16,
      12,
      8,
      4,
      16,
      4,
      8,
      14,
      4,
      10,
      12,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2781569965870307,
      "openbookqa": 0.348,
      "piqa": 0.6936887921653971,
      "hellaswag": 0.44921330412268473,
      "boolq": 0.4620795107033639,
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      16,
      6,
      14,
      10,
      12,
      8,
      4,
      4,
      6,
      6,
      10,
      4,
      8,
      14,
      14,
      10,
      8,
      4,
      14,
      8,
      6,
      6,
      4,
      2,
      8,
      6,
      14,
      6,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2696245733788396,
      "hellaswag": 0.43069109739095796,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5908256880733945,
      "openbookqa": 0.348,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      6,
      16,
      12,
      14,
      2,
      12,
      4,
      14,
      6,
      2,
      8,
      2,
      8,
      6,
      2,
      16,
      10,
      10,
      8,
      6,
      16,
      2,
      2,
      12,
      16,
      8,
      16,
      16,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.346,
      "boolq": 0.5862385321100917,
      "hellaswag": 0.43238398725353516,
      "arc_challenge": 0.2721843003412969,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6708378672470077
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      4,
      6,
      14,
      8,
      4,
      14,
      4,
      10,
      4,
      14,
      2,
      14,
      14,
      6,
      6,
      16,
      10,
      12,
      12,
      2,
      8,
      4,
      10,
      12,
      12,
      2,
      16,
      8,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28071672354948807,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.348,
      "piqa": 0.6926006528835691,
      "hellaswag": 0.450408285202151,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.46605504587155966
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      10,
      2,
      6,
      10,
      14,
      12,
      10,
      4,
      8,
      6,
      8,
      10,
      14,
      14,
      16,
      8,
      14,
      10,
      10,
      2,
      2,
      14,
      12,
      2,
      16,
      14,
      16,
      8,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4776758409785933,
      "arc_easy": 0.44191919191919193,
      "hellaswag": 0.4475204142601075,
      "winogrande": 0.5098658247829518,
      "arc_challenge": 0.28071672354948807,
      "piqa": 0.690424374319913,
      "openbookqa": 0.342
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      12,
      16,
      2,
      16,
      8,
      10,
      12,
      14,
      14,
      10,
      2,
      8,
      12,
      10,
      4,
      2,
      2,
      6,
      10,
      8,
      16,
      2,
      14,
      16,
      6,
      12,
      14,
      14,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2781569965870307,
      "boolq": 0.48256880733944957,
      "piqa": 0.6887921653971708,
      "winogrande": 0.510655090765588,
      "hellaswag": 0.44851623182632944,
      "openbookqa": 0.35,
      "arc_easy": 0.4377104377104377
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      16,
      16,
      8,
      10,
      8,
      16,
      16,
      2,
      10,
      12,
      4,
      12,
      8,
      8,
      8,
      16,
      8,
      10,
      14,
      6,
      6,
      12,
      8,
      6,
      10,
      4,
      12,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "boolq": 0.5966360856269113,
      "piqa": 0.6713819368879217,
      "hellaswag": 0.4309898426608245,
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.48653198653198654,
      "arc_challenge": 0.2738907849829352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      4,
      2,
      12,
      2,
      2,
      4,
      4,
      4,
      16,
      14,
      6,
      2,
      2,
      16,
      6,
      4,
      16,
      2,
      12,
      12,
      8,
      16,
      6,
      6,
      4,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5593272171253822,
      "openbookqa": 0.352,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.492003367003367,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.43328022306313485,
      "arc_challenge": 0.27474402730375425
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      12,
      6,
      8,
      6,
      8,
      12,
      12,
      6,
      6,
      16,
      14,
      12,
      8,
      2,
      2,
      16,
      14,
      14,
      16,
      8,
      8,
      16,
      12,
      14,
      16,
      14,
      10,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4511784511784512,
      "arc_challenge": 0.2781569965870307,
      "winogrande": 0.5209155485398579,
      "hellaswag": 0.44981079466241786,
      "openbookqa": 0.344,
      "boolq": 0.46238532110091746,
      "piqa": 0.691512513601741
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      8,
      8,
      8,
      6,
      4,
      6,
      10,
      6,
      12,
      8,
      14,
      2,
      6,
      6,
      2,
      6,
      14,
      6,
      8,
      6,
      16,
      6,
      8,
      14,
      2,
      4,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27047781569965873,
      "hellaswag": 0.4298944433379805,
      "openbookqa": 0.35,
      "boolq": 0.5874617737003058,
      "piqa": 0.675734494015234,
      "arc_easy": 0.49242424242424243,
      "winogrande": 0.5217048145224941
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      6,
      16,
      12,
      16,
      8,
      6,
      14,
      8,
      10,
      2,
      16,
      4,
      6,
      16,
      6,
      16,
      4,
      10,
      12,
      14,
      6,
      6,
      6,
      10,
      16,
      14,
      10,
      16,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.482262996941896,
      "arc_challenge": 0.28242320819112626,
      "piqa": 0.6860718171926007,
      "openbookqa": 0.348,
      "arc_easy": 0.44612794612794615,
      "hellaswag": 0.4502091216889066,
      "winogrande": 0.5130228887134964
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      2,
      10,
      2,
      6,
      14,
      14,
      2,
      10,
      8,
      10,
      12,
      8,
      4,
      12,
      6,
      6,
      16,
      6,
      10,
      6,
      10,
      10,
      16,
      4,
      12,
      16,
      16,
      12,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "arc_easy": 0.4772727272727273,
      "arc_challenge": 0.27559726962457337,
      "openbookqa": 0.338,
      "winogrande": 0.5114443567482242,
      "piqa": 0.6779107725788901,
      "boolq": 0.5740061162079511
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      16,
      14,
      16,
      14,
      8,
      4,
      14,
      14,
      6,
      8,
      14,
      6,
      16,
      12,
      8,
      12,
      14,
      10,
      2,
      2,
      4,
      12,
      4,
      10,
      16,
      2,
      2,
      12,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6697497279651795,
      "arc_easy": 0.48063973063973064,
      "hellaswag": 0.4303923521210914,
      "arc_challenge": 0.2687713310580205,
      "boolq": 0.6085626911314985,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      10,
      6,
      16,
      8,
      8,
      14,
      2,
      10,
      6,
      8,
      12,
      6,
      16,
      2,
      8,
      8,
      12,
      10,
      16,
      10,
      16,
      16,
      4,
      14,
      12,
      4,
      8,
      10,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.43486238532110094,
      "hellaswag": 0.44991037641904,
      "arc_challenge": 0.28071672354948807,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.348,
      "piqa": 0.6871599564744287,
      "arc_easy": 0.43476430976430974
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      16,
      8,
      6,
      2,
      6,
      6,
      8,
      6,
      6,
      14,
      6,
      2,
      14,
      10,
      2,
      16,
      4,
      2,
      10,
      2,
      14,
      16,
      10,
      10,
      4,
      10,
      16,
      6,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "winogrande": 0.5272296764009471,
      "boolq": 0.4666666666666667,
      "arc_easy": 0.44612794612794615,
      "arc_challenge": 0.28071672354948807,
      "hellaswag": 0.4532961561441944,
      "openbookqa": 0.35
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      2,
      8,
      6,
      12,
      10,
      8,
      10,
      12,
      2,
      2,
      8,
      4,
      10,
      8,
      12,
      12,
      14,
      8,
      10,
      8,
      16,
      6,
      16,
      2,
      12,
      10,
      2,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "arc_challenge": 0.2696245733788396,
      "piqa": 0.6664853101196954,
      "boolq": 0.5908256880733945,
      "openbookqa": 0.356,
      "hellaswag": 0.43158733320055764,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      8,
      8,
      12,
      16,
      14,
      8,
      8,
      14,
      6,
      10,
      4,
      6,
      10,
      2,
      6,
      2,
      8,
      14,
      8,
      2,
      10,
      4,
      8,
      14,
      12,
      16,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4599388379204893,
      "openbookqa": 0.35,
      "arc_easy": 0.4524410774410774,
      "piqa": 0.6860718171926007,
      "arc_challenge": 0.28242320819112626,
      "hellaswag": 0.44851623182632944,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      6,
      2,
      8,
      16,
      10,
      14,
      10,
      6,
      16,
      8,
      8,
      2,
      4,
      2,
      6,
      6,
      14,
      12,
      8,
      8,
      6,
      12,
      8,
      8,
      2,
      12,
      4,
      2,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.348,
      "arc_challenge": 0.2636518771331058,
      "hellaswag": 0.43417645887273454,
      "arc_easy": 0.48442760942760943,
      "piqa": 0.675734494015234,
      "boolq": 0.5923547400611621
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      12,
      10,
      2,
      16,
      10,
      2,
      2,
      12,
      14,
      10,
      2,
      16,
      14,
      8,
      2,
      16,
      14,
      16,
      6,
      14,
      6,
      16,
      2,
      2,
      12,
      8,
      16,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676822633297062,
      "boolq": 0.518960244648318,
      "openbookqa": 0.348,
      "arc_challenge": 0.2790102389078498,
      "hellaswag": 0.433877713602868,
      "arc_easy": 0.48148148148148145,
      "winogrande": 0.5090765588003157
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      2,
      14,
      4,
      6,
      6,
      16,
      10,
      14,
      4,
      6,
      2,
      8,
      16,
      2,
      10,
      6,
      8,
      16,
      16,
      2,
      4,
      12,
      12,
      14,
      16,
      14,
      2,
      14,
      2,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.344,
      "arc_easy": 0.4431818181818182,
      "arc_challenge": 0.2858361774744027,
      "hellaswag": 0.4500099581756622,
      "piqa": 0.6871599564744287,
      "boolq": 0.4596330275229358
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      2,
      4,
      12,
      4,
      2,
      8,
      14,
      10,
      12,
      16,
      10,
      8,
      14,
      16,
      2,
      12,
      14,
      6,
      8,
      4,
      14,
      8,
      10,
      4,
      2,
      6,
      8,
      10,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5090765588003157,
      "hellaswag": 0.433379804819757,
      "arc_easy": 0.48484848484848486,
      "piqa": 0.6724700761697497,
      "arc_challenge": 0.2790102389078498,
      "boolq": 0.5941896024464832,
      "openbookqa": 0.352
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      2,
      10,
      12,
      14,
      2,
      8,
      12,
      2,
      16,
      8,
      8,
      4,
      6,
      4,
      8,
      8,
      16,
      6,
      16,
      8,
      2,
      14,
      4,
      4,
      6,
      16,
      10,
      4,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "arc_challenge": 0.2883959044368601,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.344,
      "hellaswag": 0.44831706831308504,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.42171253822629967
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      16,
      12,
      12,
      2,
      6,
      16,
      4,
      10,
      6,
      4,
      6,
      14,
      10,
      12,
      2,
      12,
      2,
      10,
      4,
      6,
      2,
      6,
      10,
      14,
      2,
      16,
      4,
      4,
      2,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28071672354948807,
      "piqa": 0.6844396082698585,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.4510057757418841,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.47706422018348627,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      4,
      6,
      2,
      2,
      14,
      12,
      8,
      10,
      6,
      14,
      8,
      6,
      10,
      6,
      4,
      14,
      4,
      16,
      2,
      16,
      2,
      6,
      8,
      10,
      12,
      12,
      6,
      4,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4494124676359291,
      "arc_easy": 0.4431818181818182,
      "piqa": 0.6882480957562568,
      "boolq": 0.46972477064220186,
      "openbookqa": 0.348,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.2790102389078498
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      10,
      14,
      14,
      16,
      2,
      12,
      12,
      6,
      10,
      10,
      14,
      12,
      6,
      10,
      6,
      4,
      4,
      6,
      12,
      10,
      10,
      12,
      12,
      16,
      6,
      8,
      12,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4850152905198777,
      "hellaswag": 0.4493128858793069,
      "winogrande": 0.5090765588003157,
      "piqa": 0.690424374319913,
      "arc_challenge": 0.2883959044368601
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      12,
      10,
      10,
      6,
      2,
      14,
      12,
      14,
      8,
      4,
      12,
      2,
      6,
      10,
      16,
      2,
      12,
      4,
      4,
      4,
      14,
      10,
      12,
      4,
      4,
      8,
      2,
      8,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.563914373088685,
      "arc_easy": 0.4802188552188552,
      "openbookqa": 0.35,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.4309898426608245,
      "arc_challenge": 0.26621160409556316,
      "piqa": 0.6659412404787813
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      12,
      12,
      12,
      2,
      14,
      6,
      2,
      14,
      8,
      6,
      16,
      16,
      12,
      8,
      10,
      16,
      4,
      16,
      16,
      8,
      8,
      6,
      12,
      8,
      2,
      10,
      4,
      12,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "arc_easy": 0.48148148148148145,
      "arc_challenge": 0.2738907849829352,
      "boolq": 0.5608562691131499,
      "hellaswag": 0.4296952798247361,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      6,
      2,
      16,
      10,
      12,
      12,
      10,
      8,
      12,
      16,
      14,
      8,
      10,
      14,
      2,
      8,
      8,
      8,
      2,
      2,
      16,
      8,
      14,
      4,
      4,
      10,
      6,
      10,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27559726962457337,
      "boolq": 0.4379204892966361,
      "hellaswag": 0.4484166500697072,
      "arc_easy": 0.4457070707070707,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.346
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      6,
      16,
      4,
      12,
      10,
      6,
      6,
      6,
      4,
      16,
      4,
      2,
      8,
      6,
      6,
      16,
      8,
      16,
      16,
      14,
      2,
      10,
      8,
      8,
      2,
      14,
      14,
      8,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.4500099581756622,
      "arc_challenge": 0.28071672354948807,
      "boolq": 0.46299694189602447,
      "piqa": 0.690968443960827,
      "openbookqa": 0.35
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      12,
      16,
      12,
      2,
      14,
      6,
      8,
      6,
      4,
      8,
      4,
      6,
      12,
      12,
      12,
      8,
      2,
      14,
      6,
      6,
      12,
      14,
      10,
      14,
      4,
      6,
      12,
      8,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.691512513601741,
      "hellaswag": 0.44971121290579563,
      "boolq": 0.4743119266055046,
      "openbookqa": 0.348,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5232833464877664,
      "arc_easy": 0.4452861952861953
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      8,
      2,
      16,
      6,
      2,
      6,
      2,
      2,
      6,
      2,
      12,
      16,
      16,
      16,
      6,
      2,
      16,
      2,
      16,
      2,
      2,
      14,
      8,
      8,
      6,
      12,
      12,
      16,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2773037542662116,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6866158868335147,
      "openbookqa": 0.346,
      "hellaswag": 0.4480183230432185,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4666666666666667
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      16,
      8,
      16,
      8,
      2,
      8,
      4,
      14,
      4,
      8,
      2,
      16,
      10,
      6,
      2,
      2,
      2,
      16,
      4,
      2,
      6,
      10,
      16,
      10,
      12,
      10,
      2,
      10,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "piqa": 0.6838955386289445,
      "openbookqa": 0.35,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.28071672354948807,
      "boolq": 0.4363914373088685,
      "hellaswag": 0.44981079466241786
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      14,
      8,
      4,
      6,
      14,
      10,
      12,
      8,
      12,
      16,
      2,
      10,
      4,
      10,
      12,
      4,
      10,
      4,
      6,
      10,
      4,
      14,
      16,
      8,
      8,
      4,
      8,
      4,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4936868686868687,
      "openbookqa": 0.36,
      "hellaswag": 0.4305915156343358,
      "boolq": 0.5746177370030581,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.2696245733788396
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      4,
      12,
      12,
      16,
      12,
      12,
      2,
      2,
      4,
      4,
      4,
      14,
      16,
      10,
      14,
      14,
      10,
      10,
      2,
      10,
      6,
      12,
      10,
      4,
      8,
      14,
      6,
      6,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5889908256880734,
      "hellaswag": 0.43009360685122483,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.2764505119453925,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.35
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      14,
      16,
      6,
      10,
      6,
      12,
      6,
      4,
      14,
      14,
      10,
      14,
      8,
      12,
      14,
      6,
      8,
      6,
      6,
      2,
      6,
      16,
      10,
      2,
      16,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "arc_easy": 0.43813131313131315,
      "openbookqa": 0.35,
      "arc_challenge": 0.2773037542662116,
      "hellaswag": 0.44761999601672975,
      "boolq": 0.45902140672782876,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      4,
      6,
      2,
      6,
      14,
      10,
      12,
      2,
      14,
      12,
      6,
      6,
      6,
      8,
      8,
      10,
      16,
      4,
      10,
      12,
      8,
      8,
      10,
      8,
      10,
      10,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4484166500697072,
      "arc_challenge": 0.28498293515358364,
      "piqa": 0.6898803046789989,
      "boolq": 0.44464831804281346,
      "openbookqa": 0.352,
      "winogrande": 0.5288082083662194,
      "arc_easy": 0.4457070707070707
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      2,
      6,
      6,
      14,
      14,
      10,
      16,
      6,
      2,
      4,
      12,
      2,
      4,
      16,
      8,
      10,
      14,
      10,
      16,
      6,
      6,
      14,
      16,
      16,
      10,
      12,
      6,
      16,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.344,
      "arc_easy": 0.44907407407407407,
      "hellaswag": 0.44911372236606256,
      "boolq": 0.4510703363914373,
      "arc_challenge": 0.28071672354948807,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6844396082698585
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      12,
      6,
      4,
      12,
      16,
      8,
      16,
      4,
      2,
      16,
      10,
      8,
      16,
      6,
      6,
      8,
      12,
      6,
      12,
      10,
      6,
      16,
      8,
      4,
      4,
      16,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "openbookqa": 0.35,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.2721843003412969,
      "hellaswag": 0.42929695279824737,
      "winogrande": 0.5201262825572218,
      "boolq": 0.5629969418960244
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      10,
      4,
      4,
      4,
      2,
      14,
      10,
      10,
      10,
      6,
      16,
      16,
      10,
      14,
      8,
      10,
      8,
      8,
      16,
      4,
      14,
      14,
      12,
      4,
      16,
      6,
      2,
      14,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.354,
      "arc_easy": 0.4861111111111111,
      "arc_challenge": 0.26621160409556316,
      "hellaswag": 0.43288189603664606,
      "boolq": 0.590519877675841,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      6,
      14,
      2,
      6,
      14,
      8,
      8,
      2,
      14,
      10,
      14,
      10,
      2,
      4,
      12,
      8,
      2,
      14,
      12,
      6,
      14,
      2,
      16,
      12,
      10,
      8,
      6,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.26621160409556316,
      "piqa": 0.6735582154515778,
      "hellaswag": 0.43168691495717987,
      "openbookqa": 0.344,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.4911616161616162,
      "boolq": 0.5969418960244648
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      16,
      8,
      2,
      6,
      2,
      16,
      8,
      2,
      8,
      12,
      4,
      14,
      10,
      10,
      8,
      2,
      12,
      4,
      16,
      12,
      4,
      4,
      10,
      10,
      16,
      16,
      12,
      14,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45202020202020204,
      "boolq": 0.40275229357798165,
      "arc_challenge": 0.27986348122866894,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.4508066122286397,
      "piqa": 0.6920565832426551,
      "openbookqa": 0.348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      4,
      14,
      14,
      16,
      12,
      8,
      6,
      2,
      6,
      10,
      4,
      6,
      6,
      2,
      14,
      8,
      14,
      6,
      4,
      10,
      6,
      12,
      14,
      16,
      14,
      4,
      10,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "winogrande": 0.5177584846093133,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6686615886833515,
      "hellaswag": 0.43288189603664606,
      "boolq": 0.5767584097859327,
      "arc_challenge": 0.27047781569965873
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      2,
      4,
      14,
      16,
      10,
      2,
      14,
      8,
      2,
      8,
      12,
      6,
      10,
      12,
      6,
      10,
      8,
      10,
      12,
      6,
      8,
      4,
      10,
      16,
      4,
      12,
      12,
      12,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "boolq": 0.5834862385321101,
      "hellaswag": 0.4302927703644692,
      "arc_challenge": 0.26706484641638223,
      "arc_easy": 0.48442760942760943,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      8,
      16,
      12,
      12,
      4,
      16,
      6,
      4,
      6,
      16,
      16,
      4,
      14,
      12,
      4,
      4,
      4,
      8,
      14,
      4,
      6,
      6,
      6,
      4,
      14,
      2,
      12,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43019318860784705,
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6730141458106638,
      "arc_challenge": 0.26621160409556316,
      "openbookqa": 0.354,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5880733944954128
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      6,
      4,
      12,
      14,
      10,
      10,
      2,
      8,
      10,
      8,
      16,
      6,
      6,
      4,
      12,
      8,
      4,
      8,
      4,
      14,
      10,
      10,
      6,
      16,
      6,
      8,
      4,
      14,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2738907849829352,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.427504481179048,
      "openbookqa": 0.346,
      "winogrande": 0.5201262825572218,
      "boolq": 0.5764525993883792
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      8,
      12,
      2,
      16,
      16,
      4,
      14,
      4,
      6,
      4,
      16,
      10,
      4,
      8,
      4,
      14,
      8,
      14,
      6,
      8,
      6,
      12,
      14,
      12,
      14,
      16,
      4,
      16,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.44761999601672975,
      "boolq": 0.48990825688073397,
      "piqa": 0.691512513601741,
      "arc_easy": 0.44991582491582494,
      "arc_challenge": 0.28498293515358364,
      "openbookqa": 0.348
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      10,
      4,
      10,
      14,
      6,
      8,
      12,
      12,
      10,
      16,
      16,
      6,
      4,
      10,
      12,
      6,
      14,
      16,
      6,
      2,
      16,
      12,
      4,
      16,
      16,
      10,
      2,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.35,
      "piqa": 0.690424374319913,
      "hellaswag": 0.45070703047201754,
      "boolq": 0.45902140672782876,
      "arc_challenge": 0.28071672354948807
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      4,
      12,
      8,
      2,
      10,
      8,
      14,
      2,
      14,
      12,
      12,
      4,
      10,
      8,
      10,
      6,
      14,
      14,
      14,
      2,
      2,
      12,
      10,
      12,
      10,
      2,
      16,
      12,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4473212507468632,
      "arc_easy": 0.44234006734006737,
      "arc_challenge": 0.2841296928327645,
      "boolq": 0.42813455657492355,
      "winogrande": 0.5256511444356748,
      "openbookqa": 0.344,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      6,
      8,
      8,
      2,
      8,
      10,
      6,
      8,
      10,
      14,
      12,
      8,
      16,
      4,
      2,
      14,
      16,
      14,
      12,
      2,
      6,
      4,
      4,
      10,
      10,
      8,
      12,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4312885879306911,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5209155485398579,
      "boolq": 0.6021406727828746,
      "arc_easy": 0.4831649831649832,
      "arc_challenge": 0.27303754266211605,
      "openbookqa": 0.346
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      16,
      2,
      4,
      4,
      14,
      2,
      8,
      6,
      16,
      8,
      16,
      14,
      16,
      10,
      2,
      4,
      16,
      10,
      6,
      10,
      4,
      14,
      12,
      16,
      16,
      14,
      12,
      2,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28071672354948807,
      "arc_easy": 0.44696969696969696,
      "boolq": 0.4620795107033639,
      "openbookqa": 0.346,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.44851623182632944
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      12,
      14,
      8,
      10,
      14,
      6,
      16,
      16,
      6,
      2,
      8,
      12,
      14,
      6,
      12,
      8,
      6,
      10,
      6,
      8,
      4,
      14,
      4,
      16,
      4,
      12,
      2,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4414983164983165,
      "arc_challenge": 0.28242320819112626,
      "hellaswag": 0.4501095399322844,
      "boolq": 0.4666666666666667
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      16,
      4,
      10,
      16,
      14,
      12,
      14,
      4,
      4,
      16,
      12,
      10,
      14,
      14,
      2,
      4,
      16,
      14,
      10,
      10,
      6,
      16,
      8,
      8,
      16,
      14,
      16,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4793771043771044,
      "hellaswag": 0.43288189603664606,
      "openbookqa": 0.348,
      "winogrande": 0.516179952644041,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.26621160409556316,
      "boolq": 0.5801223241590214
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      4,
      12,
      2,
      10,
      8,
      10,
      10,
      14,
      16,
      2,
      10,
      8,
      4,
      12,
      12,
      16,
      16,
      12,
      10,
      4,
      10,
      2,
      4,
      8,
      14,
      6,
      2,
      12,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4318860784704242,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6713819368879217,
      "boolq": 0.590519877675841,
      "openbookqa": 0.352,
      "arc_challenge": 0.2738907849829352,
      "winogrande": 0.5217048145224941
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      8,
      10,
      16,
      14,
      12,
      10,
      8,
      12,
      6,
      16,
      6,
      16,
      2,
      12,
      12,
      4,
      2,
      12,
      14,
      12,
      14,
      14,
      4,
      14,
      12,
      14,
      12,
      10,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6931447225244831,
      "arc_challenge": 0.27559726962457337,
      "arc_easy": 0.4478114478114478,
      "hellaswag": 0.44901414060944034,
      "boolq": 0.517125382262997,
      "winogrande": 0.526440410418311,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      14,
      8,
      12,
      2,
      4,
      2,
      14,
      10,
      14,
      6,
      8,
      12,
      8,
      12,
      8,
      14,
      14,
      10,
      10,
      14,
      10,
      10,
      12,
      10,
      4,
      2,
      12,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5862385321100917,
      "hellaswag": 0.4320852419836686,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.2645051194539249,
      "openbookqa": 0.358,
      "arc_easy": 0.4890572390572391
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      6,
      16,
      4,
      16,
      8,
      8,
      14,
      16,
      14,
      16,
      12,
      2,
      8,
      2,
      4,
      12,
      8,
      16,
      10,
      16,
      16,
      8,
      12,
      12,
      16,
      8,
      14,
      10,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.4320852419836686,
      "arc_challenge": 0.2790102389078498,
      "boolq": 0.5840978593272171,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      12,
      6,
      12,
      16,
      2,
      8,
      14,
      14,
      8,
      6,
      2,
      16,
      4,
      4,
      4,
      12,
      10,
      8,
      10,
      6,
      8,
      14,
      4,
      10,
      12,
      4,
      10,
      8,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5240726124704025,
      "arc_easy": 0.484006734006734,
      "openbookqa": 0.352,
      "arc_challenge": 0.27559726962457337,
      "hellaswag": 0.43218482374029077,
      "boolq": 0.5935779816513761,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      8,
      14,
      10,
      10,
      2,
      14,
      12,
      2,
      16,
      16,
      10,
      2,
      16,
      12,
      8,
      8,
      8,
      16,
      10,
      6,
      4,
      14,
      16,
      4,
      4,
      14,
      14,
      16,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2841296928327645,
      "boolq": 0.4581039755351682,
      "piqa": 0.6866158868335147,
      "arc_easy": 0.44276094276094274,
      "openbookqa": 0.344,
      "hellaswag": 0.45050786695877315,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      14,
      2,
      6,
      14,
      4,
      12,
      12,
      4,
      12,
      2,
      14,
      12,
      6,
      14,
      12,
      2,
      8,
      14,
      2,
      6,
      4,
      8,
      2,
      6,
      8,
      4,
      10,
      14,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.49284511784511786,
      "openbookqa": 0.354,
      "arc_challenge": 0.2721843003412969,
      "hellaswag": 0.43308105954989046,
      "boolq": 0.5715596330275229
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      4,
      14,
      16,
      4,
      10,
      4,
      16,
      4,
      2,
      6,
      14,
      4,
      6,
      12,
      12,
      14,
      14,
      14,
      6,
      4,
      10,
      2,
      10,
      16,
      6,
      6,
      10,
      6,
      6,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5709480122324159,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.4831649831649832,
      "openbookqa": 0.35,
      "arc_challenge": 0.2713310580204778,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.4302927703644692
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      12,
      4,
      14,
      14,
      12,
      6,
      12,
      10,
      16,
      12,
      6,
      8,
      14,
      2,
      8,
      6,
      12,
      10,
      6,
      14,
      16,
      10,
      10,
      8,
      12,
      4,
      8,
      2,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "arc_challenge": 0.2738907849829352,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.43178649671380204,
      "boolq": 0.5755351681957187,
      "openbookqa": 0.35,
      "piqa": 0.6751904243743199
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      16,
      2,
      12,
      14,
      8,
      4,
      14,
      16,
      8,
      8,
      2,
      8,
      10,
      8,
      16,
      2,
      4,
      16,
      6,
      8,
      12,
      14,
      6,
      10,
      16,
      12,
      2,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.342,
      "hellaswag": 0.4501095399322844,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.27986348122866894,
      "boolq": 0.45321100917431195,
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.4444444444444444
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      16,
      6,
      12,
      2,
      8,
      8,
      8,
      6,
      8,
      8,
      14,
      12,
      10,
      12,
      2,
      10,
      10,
      16,
      16,
      2,
      16,
      16,
      12,
      10,
      4,
      8,
      6,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4452861952861953,
      "openbookqa": 0.352,
      "hellaswag": 0.4495120493925513,
      "winogrande": 0.526440410418311,
      "boolq": 0.454434250764526,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.28754266211604096
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      14,
      12,
      4,
      2,
      10,
      8,
      6,
      6,
      2,
      10,
      2,
      16,
      10,
      14,
      14,
      4,
      2,
      8,
      8,
      6,
      14,
      10,
      12,
      2,
      6,
      2,
      14,
      4,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48695286195286197,
      "winogrande": 0.516179952644041,
      "piqa": 0.6719260065288357,
      "openbookqa": 0.35,
      "boolq": 0.5941896024464832,
      "arc_challenge": 0.2773037542662116,
      "hellaswag": 0.43178649671380204
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      12,
      2,
      6,
      6,
      14,
      14,
      14,
      12,
      12,
      2,
      12,
      16,
      4,
      8,
      8,
      10,
      10,
      12,
      16,
      14,
      4,
      14,
      4,
      12,
      4,
      16,
      14,
      12,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "arc_easy": 0.4457070707070707,
      "arc_challenge": 0.28754266211604096,
      "winogrande": 0.5240726124704025,
      "boolq": 0.4767584097859327,
      "hellaswag": 0.4487153953395738,
      "piqa": 0.6898803046789989
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      12,
      2,
      6,
      2,
      10,
      8,
      6,
      12,
      16,
      4,
      14,
      4,
      14,
      16,
      8,
      4,
      6,
      12,
      2,
      2,
      14,
      2,
      12,
      8,
      8,
      16,
      12,
      12,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "hellaswag": 0.43178649671380204,
      "boolq": 0.5850152905198777,
      "openbookqa": 0.352,
      "piqa": 0.6741022850924918,
      "arc_challenge": 0.2721843003412969,
      "arc_easy": 0.48358585858585856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      4,
      10,
      2,
      14,
      6,
      6,
      4,
      10,
      2,
      4,
      10,
      10,
      8,
      8,
      14,
      12,
      8,
      4,
      12,
      8,
      12,
      12,
      10,
      2,
      12,
      6,
      6,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "boolq": 0.581039755351682,
      "hellaswag": 0.4326827325234017,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6724700761697497,
      "arc_challenge": 0.2773037542662116,
      "arc_easy": 0.48148148148148145
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      14,
      6,
      14,
      2,
      16,
      16,
      10,
      4,
      2,
      14,
      8,
      4,
      2,
      10,
      4,
      10,
      10,
      14,
      8,
      2,
      8,
      16,
      10,
      10,
      6,
      6,
      12,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5201262825572218,
      "boolq": 0.43027522935779816,
      "piqa": 0.6855277475516867,
      "arc_easy": 0.4457070707070707,
      "hellaswag": 0.44921330412268473,
      "openbookqa": 0.344,
      "arc_challenge": 0.2832764505119454
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      16,
      16,
      16,
      14,
      10,
      10,
      10,
      8,
      2,
      8,
      8,
      12,
      14,
      2,
      2,
      12,
      6,
      16,
      8,
      8,
      12,
      12,
      8,
      8,
      2,
      12,
      12,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "piqa": 0.6784548422198041,
      "boolq": 0.5501529051987768,
      "arc_challenge": 0.2738907849829352,
      "openbookqa": 0.344,
      "hellaswag": 0.43218482374029077,
      "arc_easy": 0.4793771043771044
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      12,
      16,
      10,
      14,
      4,
      2,
      12,
      4,
      16,
      12,
      14,
      12,
      16,
      8,
      16,
      2,
      4,
      4,
      8,
      2,
      12,
      16,
      16,
      8,
      4,
      10,
      4,
      2,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.2815699658703072,
      "boolq": 0.47339449541284406,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.352,
      "hellaswag": 0.4500099581756622,
      "arc_easy": 0.4398148148148148
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      6,
      16,
      4,
      12,
      12,
      14,
      8,
      12,
      16,
      2,
      4,
      10,
      16,
      8,
      10,
      10,
      16,
      12,
      8,
      2,
      8,
      4,
      6,
      8,
      16,
      10,
      2,
      4,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.344,
      "boolq": 0.46452599388379207,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.44191919191919193,
      "hellaswag": 0.44742083250348536,
      "arc_challenge": 0.2841296928327645,
      "winogrande": 0.5232833464877664
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      4,
      10,
      8,
      10,
      8,
      16,
      12,
      8,
      12,
      14,
      10,
      14,
      10,
      10,
      2,
      8,
      8,
      14,
      4,
      6,
      12,
      14,
      6,
      6,
      14,
      16,
      8,
      14,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5177584846093133,
      "piqa": 0.6702937976060935,
      "boolq": 0.5981651376146789,
      "hellaswag": 0.43288189603664606,
      "openbookqa": 0.344,
      "arc_easy": 0.48442760942760943,
      "arc_challenge": 0.2713310580204778
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      12,
      14,
      14,
      10,
      12,
      2,
      12,
      12,
      2,
      10,
      4,
      2,
      2,
      2,
      14,
      14,
      16,
      12,
      16,
      8,
      10,
      6,
      14,
      2,
      12,
      12,
      12,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6860718171926007,
      "hellaswag": 0.4493128858793069,
      "arc_easy": 0.44696969696969696,
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.354,
      "arc_challenge": 0.2832764505119454,
      "boolq": 0.41437308868501527
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      8,
      16,
      10,
      6,
      2,
      10,
      14,
      2,
      4,
      6,
      8,
      16,
      2,
      12,
      12,
      14,
      2,
      6,
      6,
      4,
      14,
      4,
      12,
      14,
      10,
      12,
      4,
      16,
      10,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4890572390572391,
      "arc_challenge": 0.2738907849829352,
      "hellaswag": 0.43238398725353516,
      "piqa": 0.6708378672470077,
      "boolq": 0.5418960244648318,
      "openbookqa": 0.34,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      4,
      4,
      12,
      14,
      6,
      14,
      10,
      6,
      4,
      6,
      10,
      14,
      8,
      14,
      4,
      14,
      8,
      14,
      6,
      4,
      10,
      8,
      12,
      2,
      12,
      14,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4452861952861953,
      "openbookqa": 0.344,
      "boolq": 0.4437308868501529,
      "hellaswag": 0.448814977096196,
      "piqa": 0.690968443960827,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.28071672354948807
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      12,
      2,
      8,
      6,
      2,
      14,
      14,
      8,
      14,
      16,
      14,
      12,
      12,
      14,
      2,
      12,
      2,
      6,
      10,
      12,
      10,
      14,
      6,
      12,
      14,
      12,
      16,
      14,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.26706484641638223,
      "winogrande": 0.5043409629044988,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.6064220183486239,
      "openbookqa": 0.354,
      "hellaswag": 0.429097789285003,
      "piqa": 0.676822633297062
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      4,
      10,
      14,
      2,
      16,
      8,
      12,
      4,
      10,
      14,
      2,
      10,
      10,
      10,
      10,
      16,
      10,
      4,
      8,
      6,
      6,
      4,
      10,
      10,
      12,
      4,
      10,
      14,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.691512513601741,
      "boolq": 0.4581039755351682,
      "arc_easy": 0.45075757575757575,
      "arc_challenge": 0.28242320819112626,
      "openbookqa": 0.34,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.4519020115514838
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      14,
      4,
      14,
      2,
      16,
      10,
      8,
      6,
      6,
      8,
      12,
      16,
      6,
      4,
      10,
      10,
      2,
      2,
      4,
      16,
      14,
      16,
      4,
      10,
      16,
      14,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4343756223859789,
      "arc_challenge": 0.28242320819112626,
      "openbookqa": 0.352,
      "winogrande": 0.5177584846093133,
      "arc_easy": 0.4861111111111111,
      "boolq": 0.57217125382263,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      6,
      8,
      4,
      6,
      16,
      4,
      16,
      4,
      6,
      4,
      14,
      8,
      4,
      2,
      6,
      8,
      6,
      14,
      6,
      10,
      6,
      12,
      12,
      8,
      2,
      14,
      2,
      8,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.342,
      "arc_easy": 0.45580808080808083,
      "boolq": 0.4831804281345566,
      "piqa": 0.691512513601741,
      "hellaswag": 0.4506074487153953,
      "arc_challenge": 0.2790102389078498,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      6,
      4,
      16,
      10,
      4,
      12,
      8,
      4,
      2,
      16,
      12,
      2,
      16,
      10,
      6,
      12,
      14,
      2,
      6,
      8,
      8,
      6,
      8,
      14,
      2,
      10,
      16,
      4,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.45749235474006117,
      "hellaswag": 0.4482174865564629,
      "arc_challenge": 0.28498293515358364,
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.526440410418311,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      10,
      14,
      6,
      4,
      10,
      6,
      14,
      10,
      6,
      16,
      4,
      6,
      2,
      6,
      12,
      10,
      12,
      12,
      10,
      16,
      16,
      8,
      12,
      4,
      12,
      14,
      2,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5743119266055046,
      "hellaswag": 0.4312885879306911,
      "piqa": 0.6746463547334058,
      "arc_easy": 0.48737373737373735,
      "arc_challenge": 0.27047781569965873,
      "openbookqa": 0.35,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      8,
      12,
      12,
      16,
      10,
      6,
      12,
      4,
      12,
      8,
      8,
      6,
      10,
      10,
      8,
      2,
      8,
      16,
      4,
      4,
      6,
      10,
      12,
      14,
      6,
      10,
      10,
      10,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.448814977096196,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.42232415902140674,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6844396082698585,
      "openbookqa": 0.352,
      "arc_challenge": 0.2815699658703072
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      2,
      12,
      12,
      6,
      12,
      4,
      4,
      6,
      14,
      2,
      14,
      14,
      16,
      8,
      4,
      14,
      8,
      14,
      14,
      10,
      8,
      14,
      2,
      8,
      6,
      8,
      2,
      4,
      6,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "boolq": 0.5990825688073395,
      "hellaswag": 0.4305915156343358,
      "openbookqa": 0.354,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.4852693602693603,
      "piqa": 0.675734494015234
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      10,
      6,
      16,
      14,
      8,
      10,
      4,
      6,
      6,
      16,
      4,
      6,
      2,
      6,
      12,
      2,
      4,
      12,
      6,
      4,
      12,
      14,
      14,
      14,
      10,
      12,
      16,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.28071672354948807,
      "openbookqa": 0.354,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.4669724770642202,
      "hellaswag": 0.44851623182632944,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      16,
      6,
      6,
      14,
      14,
      12,
      8,
      16,
      12,
      14,
      8,
      4,
      2,
      8,
      10,
      14,
      2,
      6,
      10,
      12,
      4,
      4,
      6,
      4,
      16,
      16,
      8,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.354,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6773667029379761,
      "boolq": 0.5792048929663609,
      "arc_challenge": 0.26706484641638223,
      "hellaswag": 0.43009360685122483
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      8,
      12,
      16,
      14,
      4,
      14,
      4,
      2,
      12,
      4,
      2,
      4,
      8,
      12,
      14,
      2,
      10,
      16,
      4,
      10,
      12,
      14,
      2,
      6,
      8,
      10,
      12,
      8,
      8,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44402356902356904,
      "winogrande": 0.5248618784530387,
      "boolq": 0.44311926605504587,
      "openbookqa": 0.346,
      "piqa": 0.6920565832426551,
      "arc_challenge": 0.2832764505119454,
      "hellaswag": 0.44831706831308504
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      10,
      6,
      14,
      14,
      12,
      14,
      2,
      4,
      2,
      14,
      8,
      10,
      6,
      4,
      12,
      14,
      10,
      8,
      10,
      6,
      16,
      4,
      2,
      6,
      12,
      16,
      4,
      6,
      4,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690968443960827,
      "winogrande": 0.5185477505919495,
      "boolq": 0.44678899082568807,
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.346,
      "arc_easy": 0.4524410774410774,
      "hellaswag": 0.4523999203345947
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      2,
      16,
      16,
      6,
      12,
      12,
      12,
      10,
      12,
      4,
      12,
      2,
      14,
      2,
      6,
      4,
      16,
      16,
      12,
      14,
      12,
      8,
      12,
      2,
      10,
      8,
      8,
      16,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.492003367003367,
      "boolq": 0.5694189602446483,
      "openbookqa": 0.354,
      "arc_challenge": 0.2738907849829352,
      "piqa": 0.675734494015234,
      "winogrande": 0.5019731649565904,
      "hellaswag": 0.4325831507667795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      10,
      14,
      10,
      8,
      14,
      2,
      6,
      4,
      12,
      6,
      10,
      16,
      14,
      8,
      12,
      10,
      10,
      12,
      8,
      8,
      14,
      14,
      12,
      8,
      8,
      16,
      6,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "hellaswag": 0.43248356901015733,
      "boolq": 0.5678899082568807,
      "openbookqa": 0.348,
      "arc_easy": 0.48148148148148145,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.2645051194539249
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      8,
      14,
      4,
      4,
      6,
      6,
      2,
      16,
      8,
      12,
      10,
      4,
      12,
      8,
      2,
      4,
      12,
      2,
      8,
      4,
      14,
      10,
      16,
      2,
      12,
      8,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4331806413065126,
      "arc_easy": 0.49158249158249157,
      "arc_challenge": 0.26535836177474403,
      "openbookqa": 0.348,
      "boolq": 0.5669724770642202,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      16,
      2,
      12,
      8,
      6,
      4,
      4,
      16,
      10,
      10,
      2,
      8,
      8,
      12,
      2,
      10,
      2,
      4,
      12,
      4,
      4,
      4,
      14,
      6,
      14,
      4,
      10,
      6,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "arc_easy": 0.44654882154882153,
      "hellaswag": 0.4506074487153953,
      "arc_challenge": 0.2883959044368601,
      "boolq": 0.4724770642201835,
      "winogrande": 0.526440410418311,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      4,
      2,
      12,
      12,
      16,
      16,
      12,
      8,
      2,
      16,
      16,
      6,
      2,
      6,
      12,
      2,
      16,
      2,
      2,
      10,
      6,
      8,
      6,
      4,
      4,
      6,
      8,
      2,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5138121546961326,
      "arc_easy": 0.48358585858585856,
      "boolq": 0.5883792048929664,
      "piqa": 0.6730141458106638,
      "arc_challenge": 0.2593856655290102,
      "openbookqa": 0.348,
      "hellaswag": 0.43178649671380204
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      14,
      8,
      10,
      16,
      8,
      6,
      2,
      4,
      12,
      16,
      12,
      4,
      10,
      4,
      10,
      12,
      6,
      2,
      14,
      10,
      8,
      8,
      12,
      12,
      16,
      8,
      4,
      12,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "winogrande": 0.5067087608524072,
      "openbookqa": 0.35,
      "arc_challenge": 0.2713310580204778,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6741022850924918,
      "boolq": 0.5581039755351682
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      16,
      12,
      10,
      12,
      12,
      14,
      8,
      6,
      12,
      6,
      4,
      4,
      4,
      8,
      8,
      8,
      8,
      10,
      14,
      16,
      4,
      12,
      2,
      16,
      14,
      10,
      2,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "arc_challenge": 0.26535836177474403,
      "openbookqa": 0.354,
      "boolq": 0.6003058103975535,
      "hellaswag": 0.4325831507667795,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      6,
      12,
      16,
      4,
      4,
      4,
      10,
      6,
      4,
      12,
      12,
      16,
      2,
      6,
      16,
      8,
      6,
      4,
      6,
      12,
      8,
      4,
      6,
      10,
      14,
      10,
      10,
      14,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43019318860784705,
      "arc_challenge": 0.2773037542662116,
      "boolq": 0.5724770642201835,
      "openbookqa": 0.356,
      "piqa": 0.6724700761697497,
      "arc_easy": 0.48569023569023567,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      4,
      16,
      8,
      8,
      12,
      14,
      8,
      10,
      10,
      8,
      16,
      4,
      16,
      6,
      12,
      14,
      4,
      6,
      2,
      2,
      2,
      4,
      14,
      10,
      14,
      6,
      4,
      4,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6871599564744287,
      "openbookqa": 0.352,
      "boolq": 0.4834862385321101,
      "hellaswag": 0.44891455885281817,
      "arc_easy": 0.4414983164983165,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.2815699658703072
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      12,
      2,
      16,
      2,
      12,
      12,
      2,
      16,
      12,
      16,
      14,
      12,
      14,
      2,
      16,
      16,
      12,
      8,
      6,
      6,
      8,
      16,
      6,
      16,
      16,
      12,
      16,
      2,
      4,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.5082872928176796,
      "openbookqa": 0.35,
      "arc_challenge": 0.28242320819112626,
      "boolq": 0.44464831804281346,
      "hellaswag": 0.44981079466241786,
      "piqa": 0.6871599564744287
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      6,
      12,
      2,
      10,
      14,
      16,
      16,
      10,
      12,
      12,
      12,
      8,
      2,
      4,
      14,
      10,
      10,
      4,
      10,
      16,
      6,
      4,
      2,
      16,
      12,
      12,
      8,
      12,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5224940805051302,
      "arc_challenge": 0.2593856655290102,
      "boolq": 0.5229357798165137,
      "hellaswag": 0.4305915156343358,
      "openbookqa": 0.354,
      "arc_easy": 0.4823232323232323,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      8,
      2,
      10,
      12,
      12,
      12,
      10,
      12,
      2,
      10,
      6,
      16,
      12,
      8,
      10,
      14,
      4,
      16,
      4,
      12,
      8,
      10,
      8,
      4,
      8,
      6,
      6,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4334793865763792,
      "arc_challenge": 0.27559726962457337,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.35,
      "piqa": 0.676822633297062,
      "arc_easy": 0.4797979797979798,
      "boolq": 0.563302752293578
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      12,
      14,
      2,
      6,
      2,
      4,
      2,
      12,
      4,
      8,
      14,
      4,
      12,
      16,
      16,
      16,
      10,
      6,
      8,
      16,
      8,
      10,
      6,
      6,
      12,
      2,
      2,
      16,
      8,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4474006116207951,
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.44851623182632944,
      "arc_challenge": 0.2738907849829352,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4494949494949495,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      4,
      8,
      12,
      4,
      12,
      10,
      12,
      14,
      16,
      12,
      4,
      4,
      12,
      2,
      2,
      6,
      12,
      14,
      6,
      6,
      6,
      2,
      8,
      10,
      8,
      14,
      6,
      6,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.43397729535949015,
      "boolq": 0.5847094801223242,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.27474402730375425,
      "openbookqa": 0.364
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      10,
      14,
      14,
      12,
      2,
      16,
      14,
      16,
      6,
      14,
      2,
      4,
      6,
      14,
      6,
      2,
      12,
      12,
      14,
      4,
      2,
      16,
      4,
      2,
      14,
      4,
      4,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4478114478114478,
      "openbookqa": 0.346,
      "boolq": 0.42171253822629967,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.44971121290579563,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.2858361774744027
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      8,
      8,
      8,
      2,
      16,
      4,
      2,
      10,
      6,
      16,
      8,
      4,
      2,
      16,
      14,
      8,
      16,
      6,
      8,
      2,
      8,
      16,
      6,
      6,
      14,
      6,
      16,
      10,
      10,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2832764505119454,
      "arc_easy": 0.44065656565656564,
      "piqa": 0.690424374319913,
      "openbookqa": 0.342,
      "winogrande": 0.5311760063141279,
      "boolq": 0.47370030581039757,
      "hellaswag": 0.44851623182632944
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      14,
      16,
      12,
      2,
      16,
      6,
      8,
      8,
      14,
      12,
      2,
      4,
      6,
      6,
      2,
      16,
      12,
      4,
      12,
      2,
      2,
      16,
      6,
      4,
      12,
      8,
      16,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "hellaswag": 0.43198566022704643,
      "boolq": 0.5629969418960244,
      "arc_easy": 0.4802188552188552,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.2764505119453925,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      16,
      10,
      10,
      8,
      2,
      12,
      8,
      2,
      4,
      14,
      12,
      16,
      6,
      10,
      10,
      6,
      16,
      4,
      16,
      14,
      12,
      2,
      14,
      6,
      10,
      2,
      6,
      16,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.27303754266211605,
      "arc_easy": 0.48737373737373735,
      "openbookqa": 0.354,
      "boolq": 0.5880733944954128,
      "winogrande": 0.510655090765588,
      "hellaswag": 0.4291973710416252
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      2,
      10,
      4,
      12,
      8,
      10,
      4,
      2,
      8,
      10,
      16,
      16,
      4,
      4,
      2,
      8,
      4,
      2,
      4,
      10,
      8,
      2,
      8,
      10,
      4,
      14,
      12,
      4,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2883959044368601,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.348,
      "boolq": 0.44403669724770645,
      "arc_easy": 0.4562289562289562,
      "hellaswag": 0.45050786695877315,
      "piqa": 0.690424374319913
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      16,
      16,
      16,
      4,
      10,
      2,
      6,
      16,
      10,
      14,
      4,
      8,
      10,
      8,
      14,
      2,
      8,
      8,
      4,
      4,
      14,
      6,
      6,
      6,
      14,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.2636518771331058,
      "hellaswag": 0.4304919338777136,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.354,
      "piqa": 0.6773667029379761,
      "boolq": 0.599388379204893
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      12,
      10,
      10,
      2,
      6,
      8,
      16,
      2,
      6,
      4,
      16,
      4,
      2,
      2,
      14,
      14,
      14,
      8,
      6,
      14,
      16,
      12,
      10,
      12,
      16,
      6,
      8,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.342,
      "winogrande": 0.5130228887134964,
      "piqa": 0.6887921653971708,
      "boolq": 0.4795107033639144,
      "arc_easy": 0.44654882154882153,
      "hellaswag": 0.45160326628161723,
      "arc_challenge": 0.2832764505119454
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      6,
      4,
      16,
      2,
      16,
      14,
      8,
      12,
      4,
      16,
      12,
      10,
      10,
      2,
      12,
      12,
      16,
      12,
      2,
      2,
      4,
      12,
      4,
      16,
      4,
      2,
      2,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "arc_challenge": 0.2636518771331058,
      "boolq": 0.5562691131498471,
      "piqa": 0.6779107725788901,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.4861111111111111,
      "hellaswag": 0.4342760406293567
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      10,
      10,
      16,
      2,
      8,
      12,
      12,
      14,
      8,
      2,
      4,
      8,
      14,
      10,
      16,
      2,
      2,
      6,
      4,
      4,
      12,
      12,
      12,
      8,
      4,
      14,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5090765588003157,
      "boolq": 0.5862385321100917,
      "arc_challenge": 0.27559726962457337,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.352,
      "hellaswag": 0.43238398725353516,
      "arc_easy": 0.4852693602693603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      16,
      4,
      2,
      4,
      14,
      12,
      6,
      10,
      4,
      4,
      10,
      8,
      10,
      12,
      4,
      14,
      12,
      2,
      4,
      2,
      6,
      10,
      14,
      14,
      12,
      10,
      8,
      12,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "arc_easy": 0.44486531986531985,
      "hellaswag": 0.45030870344552876,
      "boolq": 0.44954128440366975,
      "arc_challenge": 0.28071672354948807,
      "winogrande": 0.5193370165745856,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      12,
      10,
      8,
      16,
      16,
      4,
      10,
      10,
      8,
      8,
      16,
      2,
      2,
      6,
      14,
      10,
      10,
      10,
      12,
      4,
      14,
      16,
      4,
      6,
      12,
      12,
      12,
      6,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "hellaswag": 0.4325831507667795,
      "arc_easy": 0.48148148148148145,
      "boolq": 0.6048929663608563,
      "piqa": 0.6741022850924918,
      "openbookqa": 0.35,
      "arc_challenge": 0.2713310580204778
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      8,
      8,
      10,
      2,
      10,
      6,
      14,
      6,
      6,
      16,
      8,
      8,
      4,
      8,
      4,
      16,
      16,
      8,
      2,
      10,
      8,
      10,
      4,
      10,
      2,
      2,
      8,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43069109739095796,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.2687713310580205,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6724700761697497,
      "openbookqa": 0.34,
      "boolq": 0.5837920489296636
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      10,
      14,
      8,
      6,
      16,
      6,
      14,
      14,
      16,
      6,
      4,
      8,
      2,
      4,
      8,
      14,
      12,
      6,
      14,
      4,
      12,
      6,
      14,
      16,
      2,
      4,
      8,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4519020115514838,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.44464831804281346,
      "openbookqa": 0.348,
      "arc_challenge": 0.2883959044368601,
      "piqa": 0.690424374319913,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      8,
      10,
      12,
      8,
      10,
      16,
      16,
      16,
      6,
      14,
      6,
      16,
      10,
      16,
      16,
      10,
      6,
      2,
      10,
      16,
      4,
      8,
      12,
      16,
      4,
      10,
      14,
      4,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6773667029379761,
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.35,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.4336785500896236,
      "arc_challenge": 0.27303754266211605,
      "boolq": 0.5896024464831804
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      8,
      16,
      6,
      10,
      4,
      4,
      2,
      4,
      2,
      16,
      6,
      4,
      14,
      8,
      4,
      8,
      4,
      8,
      8,
      16,
      4,
      8,
      12,
      4,
      10,
      6,
      16,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.28242320819112626,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.44911372236606256,
      "piqa": 0.6942328618063112,
      "boolq": 0.4886850152905199,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      8,
      12,
      12,
      6,
      4,
      10,
      16,
      14,
      16,
      16,
      10,
      4,
      10,
      10,
      10,
      4,
      16,
      14,
      4,
      6,
      8,
      8,
      8,
      10,
      4,
      12,
      16,
      2,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.35,
      "arc_easy": 0.4473905723905724,
      "boolq": 0.4724770642201835,
      "piqa": 0.6877040261153428,
      "hellaswag": 0.44761999601672975,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      10,
      6,
      4,
      12,
      8,
      8,
      10,
      2,
      6,
      4,
      10,
      8,
      14,
      2,
      16,
      4,
      4,
      2,
      4,
      4,
      12,
      10,
      4,
      4,
      4,
      4,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6692056583242655,
      "arc_challenge": 0.2738907849829352,
      "arc_easy": 0.4861111111111111,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5785932721712538,
      "hellaswag": 0.43527185819557856,
      "openbookqa": 0.35
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      4,
      4,
      10,
      2,
      14,
      14,
      16,
      2,
      12,
      12,
      10,
      4,
      12,
      10,
      6,
      14,
      10,
      6,
      14,
      16,
      2,
      6,
      10,
      12,
      16,
      2,
      10,
      8,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44811790479984065,
      "boolq": 0.4437308868501529,
      "piqa": 0.6877040261153428,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.35,
      "arc_challenge": 0.27986348122866894,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      10,
      14,
      10,
      6,
      14,
      14,
      6,
      12,
      8,
      12,
      4,
      4,
      10,
      8,
      6,
      16,
      2,
      6,
      10,
      12,
      8,
      14,
      2,
      10,
      16,
      12,
      6,
      14,
      4,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5767584097859327,
      "hellaswag": 0.4335789683330014,
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.2636518771331058,
      "piqa": 0.6735582154515778
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      4,
      6,
      6,
      6,
      16,
      16,
      4,
      2,
      8,
      12,
      6,
      14,
      4,
      4,
      16,
      6,
      10,
      6,
      2,
      14,
      10,
      6,
      10,
      6,
      4,
      14,
      2,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "openbookqa": 0.358,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6708378672470077,
      "boolq": 0.5660550458715596,
      "arc_challenge": 0.2645051194539249,
      "hellaswag": 0.4327823142800239
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      12,
      14,
      14,
      10,
      6,
      14,
      4,
      10,
      2,
      16,
      8,
      4,
      10,
      14,
      14,
      4,
      8,
      12,
      12,
      2,
      8,
      10,
      4,
      10,
      2,
      8,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4740061162079511,
      "arc_easy": 0.43897306397306396,
      "openbookqa": 0.348,
      "hellaswag": 0.4487153953395738,
      "arc_challenge": 0.28498293515358364,
      "piqa": 0.6860718171926007,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      4,
      16,
      16,
      16,
      8,
      6,
      8,
      10,
      8,
      14,
      10,
      16,
      16,
      8,
      16,
      14,
      14,
      14,
      8,
      14,
      2,
      10,
      16,
      10,
      12,
      2,
      12,
      8,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6055045871559633,
      "arc_easy": 0.4831649831649832,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.27303754266211605,
      "hellaswag": 0.42869946225851424,
      "winogrande": 0.5138121546961326,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      16,
      6,
      16,
      12,
      10,
      4,
      14,
      4,
      14,
      12,
      16,
      2,
      4,
      4,
      6,
      14,
      14,
      4,
      16,
      12,
      4,
      14,
      2,
      8,
      10,
      12,
      6,
      12,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28498293515358364,
      "openbookqa": 0.348,
      "arc_easy": 0.4524410774410774,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.4506074487153953,
      "boolq": 0.4675840978593272,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      10,
      4,
      6,
      16,
      10,
      14,
      14,
      8,
      14,
      10,
      2,
      8,
      12,
      4,
      2,
      10,
      2,
      10,
      8,
      6,
      12,
      8,
      12,
      12,
      8,
      2,
      10,
      4,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28242320819112626,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.4506074487153953,
      "boolq": 0.427217125382263,
      "openbookqa": 0.352,
      "arc_easy": 0.4541245791245791,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      6,
      4,
      14,
      10,
      8,
      16,
      6,
      14,
      10,
      8,
      14,
      8,
      14,
      6,
      2,
      12,
      2,
      6,
      2,
      2,
      8,
      14,
      4,
      2,
      12,
      14,
      4,
      4,
      16,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2687713310580205,
      "boolq": 0.6,
      "hellaswag": 0.4318860784704242,
      "piqa": 0.676278563656148,
      "openbookqa": 0.352,
      "arc_easy": 0.48569023569023567,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      12,
      10,
      14,
      10,
      6,
      10,
      4,
      8,
      16,
      6,
      4,
      2,
      4,
      10,
      16,
      14,
      2,
      2,
      8,
      6,
      10,
      4,
      8,
      10,
      10,
      10,
      6,
      8,
      8,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "openbookqa": 0.348,
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.2713310580204778,
      "boolq": 0.5850152905198777,
      "arc_easy": 0.48863636363636365,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      2,
      10,
      14,
      14,
      6,
      8,
      10,
      10,
      16,
      8,
      2,
      2,
      12,
      10,
      6,
      10,
      16,
      12,
      10,
      2,
      12,
      16,
      2,
      12,
      4,
      2,
      6,
      2,
      10,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4457070707070707,
      "arc_challenge": 0.28924914675767915,
      "piqa": 0.6936887921653971,
      "openbookqa": 0.348,
      "hellaswag": 0.44991037641904,
      "boolq": 0.42844036697247706,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      8,
      6,
      14,
      14,
      8,
      14,
      14,
      16,
      4,
      6,
      14,
      16,
      16,
      16,
      6,
      12,
      10,
      10,
      16,
      6,
      6,
      12,
      10,
      12,
      10,
      14,
      4,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.344,
      "arc_challenge": 0.27986348122866894,
      "piqa": 0.6871599564744287,
      "hellaswag": 0.44991037641904,
      "boolq": 0.5051987767584097,
      "arc_easy": 0.4385521885521885
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      12,
      4,
      14,
      12,
      10,
      12,
      14,
      10,
      12,
      14,
      14,
      16,
      4,
      4,
      6,
      2,
      12,
      14,
      14,
      14,
      16,
      2,
      10,
      16,
      16,
      16,
      6,
      8,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44865319865319864,
      "boolq": 0.4504587155963303,
      "hellaswag": 0.4487153953395738,
      "winogrande": 0.5177584846093133,
      "arc_challenge": 0.2815699658703072,
      "piqa": 0.6887921653971708,
      "openbookqa": 0.354
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      6,
      10,
      10,
      4,
      8,
      14,
      12,
      12,
      4,
      12,
      12,
      10,
      14,
      10,
      12,
      12,
      6,
      6,
      16,
      8,
      16,
      8,
      6,
      2,
      14,
      2,
      12,
      16,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4305915156343358,
      "piqa": 0.6784548422198041,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.48484848484848486,
      "arc_challenge": 0.2627986348122867,
      "boolq": 0.5792048929663609,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      8,
      12,
      6,
      12,
      2,
      14,
      4,
      10,
      6,
      8,
      10,
      14,
      6,
      8,
      8,
      2,
      10,
      4,
      14,
      12,
      16,
      12,
      10,
      16,
      4,
      14,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6920565832426551,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4473905723905724,
      "arc_challenge": 0.27986348122866894,
      "boolq": 0.47553516819571867,
      "openbookqa": 0.348,
      "hellaswag": 0.4511053574985063
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      8,
      2,
      12,
      8,
      4,
      6,
      8,
      10,
      16,
      6,
      2,
      16,
      8,
      16,
      14,
      12,
      6,
      10,
      10,
      16,
      2,
      16,
      6,
      14,
      4,
      2,
      14,
      4,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5130228887134964,
      "arc_challenge": 0.28498293515358364,
      "openbookqa": 0.348,
      "arc_easy": 0.4452861952861953,
      "hellaswag": 0.44722166899024096,
      "piqa": 0.6898803046789989,
      "boolq": 0.47889908256880737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      2,
      8,
      12,
      12,
      8,
      8,
      2,
      2,
      12,
      14,
      6,
      8,
      14,
      10,
      2,
      2,
      8,
      12,
      10,
      4,
      2,
      4,
      2,
      10,
      4,
      2,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_challenge": 0.2781569965870307,
      "hellaswag": 0.4523999203345947,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6887921653971708,
      "arc_easy": 0.45580808080808083,
      "boolq": 0.5058103975535169
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      6,
      6,
      16,
      16,
      2,
      14,
      8,
      16,
      10,
      4,
      10,
      8,
      14,
      12,
      8,
      2,
      4,
      16,
      8,
      10,
      10,
      4,
      14,
      16,
      6,
      2,
      12,
      12,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.43248356901015733,
      "arc_challenge": 0.27047781569965873,
      "openbookqa": 0.362,
      "piqa": 0.6779107725788901,
      "boolq": 0.5871559633027523
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      2,
      12,
      12,
      2,
      14,
      2,
      12,
      16,
      8,
      10,
      6,
      6,
      2,
      4,
      10,
      12,
      2,
      6,
      6,
      2,
      16,
      16,
      8,
      8,
      2,
      14,
      8,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676278563656148,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.49158249158249157,
      "boolq": 0.5844036697247706,
      "hellaswag": 0.4327823142800239,
      "openbookqa": 0.346,
      "arc_challenge": 0.26109215017064846
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      2,
      16,
      6,
      4,
      16,
      8,
      6,
      6,
      6,
      6,
      2,
      10,
      12,
      16,
      8,
      4,
      8,
      12,
      2,
      16,
      16,
      6,
      6,
      14,
      2,
      4,
      4,
      14,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6877040261153428,
      "winogrande": 0.5146014206787688,
      "boolq": 0.445565749235474,
      "arc_challenge": 0.2790102389078498,
      "hellaswag": 0.4536944831706831,
      "openbookqa": 0.346,
      "arc_easy": 0.4524410774410774
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      6,
      2,
      16,
      2,
      10,
      16,
      14,
      2,
      12,
      4,
      2,
      4,
      10,
      4,
      14,
      8,
      8,
      12,
      6,
      12,
      4,
      6,
      8,
      14,
      16,
      8,
      10,
      12,
      8,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2645051194539249,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.348,
      "boolq": 0.5626911314984709,
      "hellaswag": 0.4331806413065126
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      8,
      8,
      12,
      16,
      4,
      8,
      16,
      16,
      6,
      6,
      16,
      4,
      6,
      4,
      6,
      8,
      8,
      6,
      2,
      14,
      14,
      16,
      10,
      8,
      10,
      8,
      10,
      12,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5712538226299694,
      "hellaswag": 0.43228440549691294,
      "openbookqa": 0.354,
      "arc_challenge": 0.27047781569965873,
      "arc_easy": 0.4764309764309764,
      "winogrande": 0.5146014206787688,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      16,
      10,
      12,
      12,
      2,
      6,
      12,
      10,
      2,
      14,
      8,
      4,
      6,
      8,
      8,
      10,
      2,
      6,
      4,
      14,
      6,
      12,
      14,
      14,
      16,
      10,
      6,
      10,
      12,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2858361774744027,
      "hellaswag": 0.4495120493925513,
      "openbookqa": 0.344,
      "piqa": 0.6898803046789989,
      "boolq": 0.42018348623853213,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.44612794612794615
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      4,
      12,
      6,
      14,
      2,
      12,
      6,
      8,
      14,
      10,
      4,
      4,
      8,
      10,
      16,
      16,
      6,
      10,
      14,
      14,
      4,
      12,
      16,
      6,
      4,
      8,
      14,
      10,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6692056583242655,
      "openbookqa": 0.354,
      "boolq": 0.5737003058103975,
      "arc_challenge": 0.2713310580204778,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.49284511784511786,
      "hellaswag": 0.43168691495717987
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      14,
      4,
      10,
      12,
      2,
      12,
      12,
      12,
      16,
      2,
      2,
      10,
      12,
      12,
      16,
      12,
      4,
      6,
      12,
      6,
      6,
      6,
      10,
      14,
      16,
      2,
      4,
      2,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2790102389078498,
      "arc_easy": 0.4372895622895623,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.4501095399322844,
      "openbookqa": 0.34,
      "winogrande": 0.5185477505919495,
      "boolq": 0.43516819571865445
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      10,
      10,
      2,
      16,
      12,
      12,
      6,
      12,
      14,
      8,
      4,
      2,
      8,
      16,
      8,
      2,
      10,
      16,
      16,
      16,
      8,
      16,
      10,
      2,
      2,
      10,
      2,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2832764505119454,
      "boolq": 0.45015290519877676,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5240726124704025,
      "hellaswag": 0.4486158135829516,
      "openbookqa": 0.346,
      "arc_easy": 0.44234006734006737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      14,
      8,
      6,
      4,
      16,
      16,
      2,
      4,
      6,
      10,
      12,
      16,
      10,
      14,
      8,
      2,
      14,
      16,
      8,
      16,
      4,
      4,
      10,
      8,
      12,
      14,
      2,
      2,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2773037542662116,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6898803046789989,
      "boolq": 0.41162079510703364,
      "openbookqa": 0.348,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.44961163114917346
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      12,
      12,
      14,
      12,
      2,
      12,
      12,
      2,
      14,
      12,
      4,
      16,
      2,
      16,
      12,
      16,
      14,
      12,
      6,
      16,
      16,
      14,
      16,
      16,
      12,
      10,
      12,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44991582491582494,
      "openbookqa": 0.342,
      "boolq": 0.4914373088685015,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.4482174865564629,
      "arc_challenge": 0.2832764505119454,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      10,
      12,
      12,
      6,
      2,
      8,
      12,
      6,
      4,
      2,
      12,
      6,
      8,
      16,
      6,
      16,
      2,
      4,
      6,
      6,
      12,
      8,
      10,
      2,
      14,
      8,
      16,
      14,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "openbookqa": 0.346,
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.44692292372037445,
      "boolq": 0.4730886850152905,
      "arc_challenge": 0.2858361774744027,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      6,
      10,
      14,
      16,
      12,
      4,
      14,
      12,
      6,
      10,
      2,
      2,
      6,
      10,
      2,
      14,
      12,
      12,
      2,
      14,
      8,
      12,
      2,
      2,
      2,
      6,
      8,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.44911372236606256,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6866158868335147,
      "boolq": 0.4599388379204893,
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.346
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      2,
      16,
      4,
      8,
      8,
      6,
      6,
      12,
      12,
      8,
      14,
      16,
      10,
      12,
      12,
      16,
      2,
      6,
      14,
      10,
      8,
      14,
      6,
      4,
      6,
      6,
      12,
      10,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2815699658703072,
      "openbookqa": 0.35,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.44921330412268473,
      "piqa": 0.6936887921653971,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.5103975535168196
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      8,
      4,
      10,
      2,
      8,
      2,
      16,
      2,
      2,
      6,
      14,
      4,
      6,
      10,
      6,
      14,
      6,
      10,
      16,
      2,
      2,
      2,
      2,
      12,
      2,
      10,
      16,
      12,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.26535836177474403,
      "arc_easy": 0.4797979797979798,
      "openbookqa": 0.348,
      "piqa": 0.6686615886833515,
      "boolq": 0.5844036697247706,
      "winogrande": 0.5272296764009471,
      "hellaswag": 0.4311890061740689
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      2,
      6,
      2,
      6,
      2,
      2,
      10,
      12,
      12,
      8,
      10,
      14,
      4,
      8,
      2,
      14,
      4,
      12,
      6,
      8,
      12,
      12,
      16,
      2,
      14,
      4,
      12,
      8,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5938837920489297,
      "hellaswag": 0.4312885879306911,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.27474402730375425,
      "openbookqa": 0.348,
      "arc_easy": 0.48484848484848486,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      4,
      12,
      10,
      6,
      6,
      2,
      10,
      2,
      10,
      12,
      2,
      4,
      10,
      4,
      4,
      2,
      2,
      6,
      14,
      6,
      4,
      6,
      16,
      14,
      2,
      4,
      14,
      6,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.344,
      "boolq": 0.4614678899082569,
      "arc_easy": 0.44486531986531985,
      "winogrande": 0.5232833464877664,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.45160326628161723,
      "arc_challenge": 0.2773037542662116
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      4,
      16,
      10,
      8,
      8,
      14,
      2,
      16,
      14,
      12,
      10,
      16,
      10,
      14,
      16,
      10,
      16,
      6,
      8,
      8,
      6,
      10,
      12,
      16,
      12,
      4,
      2,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.44991582491582494,
      "arc_challenge": 0.2815699658703072,
      "piqa": 0.690968443960827,
      "openbookqa": 0.344,
      "hellaswag": 0.4484166500697072,
      "boolq": 0.4235474006116208
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      8,
      16,
      14,
      10,
      14,
      6,
      8,
      12,
      8,
      2,
      10,
      12,
      2,
      6,
      4,
      16,
      6,
      10,
      12,
      8,
      8,
      12,
      6,
      16,
      6,
      14,
      12,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.526440410418311,
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.352,
      "boolq": 0.5785932721712538,
      "hellaswag": 0.4325831507667795,
      "arc_challenge": 0.2781569965870307,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      6,
      4,
      2,
      14,
      10,
      12,
      12,
      10,
      12,
      16,
      16,
      8,
      10,
      2,
      8,
      14,
      4,
      10,
      14,
      16,
      14,
      12,
      4,
      14,
      10,
      14,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.348,
      "hellaswag": 0.43158733320055764,
      "boolq": 0.5798165137614679,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.2636518771331058,
      "arc_easy": 0.47895622895622897
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      14,
      8,
      6,
      6,
      10,
      12,
      10,
      2,
      6,
      16,
      2,
      12,
      2,
      16,
      2,
      16,
      12,
      8,
      4,
      12,
      12,
      2,
      6,
      8,
      6,
      2,
      16,
      16,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.43027522935779816,
      "hellaswag": 0.448814977096196,
      "arc_easy": 0.44907407407407407,
      "piqa": 0.690424374319913,
      "winogrande": 0.5177584846093133,
      "arc_challenge": 0.2790102389078498,
      "openbookqa": 0.348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      12,
      4,
      8,
      12,
      4,
      14,
      12,
      6,
      2,
      14,
      6,
      4,
      12,
      10,
      4,
      12,
      16,
      12,
      14,
      10,
      16,
      4,
      8,
      14,
      12,
      12,
      6,
      6,
      4,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "openbookqa": 0.352,
      "arc_easy": 0.4802188552188552,
      "boolq": 0.5902140672782875,
      "piqa": 0.6719260065288357,
      "hellaswag": 0.4313881696873133,
      "arc_challenge": 0.2781569965870307
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      2,
      14,
      6,
      4,
      16,
      2,
      2,
      4,
      8,
      10,
      12,
      12,
      6,
      4,
      6,
      10,
      4,
      6,
      14,
      2,
      2,
      6,
      16,
      12,
      16,
      2,
      12,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6746463547334058,
      "boolq": 0.5697247706422018,
      "arc_easy": 0.4793771043771044,
      "winogrande": 0.5256511444356748,
      "hellaswag": 0.4327823142800239,
      "arc_challenge": 0.2696245733788396,
      "openbookqa": 0.356
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      6,
      10,
      2,
      2,
      4,
      4,
      6,
      4,
      2,
      4,
      10,
      8,
      10,
      10,
      8,
      4,
      8,
      6,
      10,
      12,
      6,
      10,
      2,
      10,
      8,
      10,
      14,
      14,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.354,
      "piqa": 0.6724700761697497,
      "arc_easy": 0.4861111111111111,
      "hellaswag": 0.4298944433379805,
      "arc_challenge": 0.2687713310580205,
      "boolq": 0.5990825688073395
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      4,
      8,
      6,
      16,
      12,
      14,
      14,
      10,
      12,
      10,
      14,
      8,
      4,
      14,
      12,
      14,
      4,
      2,
      2,
      4,
      8,
      2,
      6,
      12,
      2,
      8,
      12,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.26535836177474403,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.48063973063973064,
      "boolq": 0.6039755351681957,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.35,
      "hellaswag": 0.43158733320055764
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      12,
      16,
      10,
      2,
      16,
      16,
      16,
      4,
      8,
      14,
      2,
      8,
      16,
      10,
      6,
      10,
      6,
      8,
      6,
      10,
      4,
      12,
      8,
      14,
      4,
      10,
      12,
      10,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_easy": 0.4852693602693603,
      "boolq": 0.5709480122324159,
      "arc_challenge": 0.2696245733788396,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.4336785500896236,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      14,
      10,
      6,
      10,
      16,
      4,
      16,
      8,
      4,
      4,
      2,
      12,
      4,
      8,
      14,
      12,
      8,
      4,
      16,
      10,
      6,
      8,
      14,
      4,
      4,
      8,
      8,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4327823142800239,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.5886850152905199,
      "arc_challenge": 0.27047781569965873,
      "winogrande": 0.5059194948697711,
      "openbookqa": 0.356,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      8,
      14,
      16,
      12,
      10,
      12,
      8,
      2,
      8,
      2,
      6,
      12,
      6,
      10,
      10,
      12,
      6,
      10,
      14,
      16,
      14,
      10,
      10,
      6,
      12,
      8,
      16,
      4,
      2,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5130228887134964,
      "arc_challenge": 0.26535836177474403,
      "boolq": 0.5996941896024465,
      "hellaswag": 0.43198566022704643,
      "openbookqa": 0.36
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      8,
      6,
      2,
      10,
      12,
      8,
      10,
      2,
      4,
      6,
      4,
      10,
      6,
      16,
      4,
      16,
      4,
      6,
      12,
      14,
      16,
      8,
      2,
      12,
      16,
      10,
      6,
      8,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.46452599388379207,
      "openbookqa": 0.346,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.28242320819112626,
      "hellaswag": 0.44991037641904,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.4452861952861953
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      2,
      12,
      2,
      2,
      14,
      16,
      4,
      12,
      4,
      16,
      6,
      2,
      6,
      4,
      10,
      16,
      14,
      8,
      4,
      8,
      14,
      2,
      6,
      14,
      10,
      2,
      16,
      14,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4326827325234017,
      "boolq": 0.5311926605504587,
      "openbookqa": 0.35,
      "arc_easy": 0.48442760942760943,
      "piqa": 0.6702937976060935,
      "winogrande": 0.5248618784530387,
      "arc_challenge": 0.2696245733788396
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      4,
      12,
      14,
      14,
      8,
      4,
      8,
      10,
      8,
      14,
      8,
      16,
      6,
      6,
      14,
      6,
      10,
      12,
      10,
      8,
      6,
      14,
      10,
      16,
      14,
      2,
      12,
      2,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44991582491582494,
      "openbookqa": 0.35,
      "boolq": 0.499388379204893,
      "arc_challenge": 0.28071672354948807,
      "hellaswag": 0.44971121290579563,
      "piqa": 0.6849836779107725,
      "winogrande": 0.5130228887134964
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      6,
      12,
      8,
      8,
      4,
      2,
      14,
      14,
      14,
      16,
      16,
      12,
      16,
      6,
      16,
      12,
      6,
      16,
      14,
      8,
      12,
      8,
      10,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.45070703047201754,
      "openbookqa": 0.346,
      "arc_easy": 0.44696969696969696,
      "piqa": 0.6887921653971708,
      "boolq": 0.4547400611620795,
      "arc_challenge": 0.2790102389078498
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      2,
      8,
      16,
      14,
      10,
      10,
      8,
      4,
      10,
      16,
      16,
      4,
      2,
      12,
      16,
      6,
      12,
      8,
      10,
      14,
      8,
      12,
      2,
      2,
      10,
      10,
      16,
      14,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.354,
      "piqa": 0.6719260065288357,
      "hellaswag": 0.433379804819757,
      "boolq": 0.5966360856269113,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.49074074074074076,
      "arc_challenge": 0.2687713310580205
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      8,
      4,
      2,
      10,
      16,
      14,
      6,
      12,
      10,
      10,
      14,
      16,
      10,
      8,
      10,
      8,
      8,
      6,
      6,
      14,
      10,
      2,
      14,
      4,
      8,
      16,
      4,
      4,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.42800238996215895,
      "boolq": 0.5507645259938838,
      "winogrande": 0.5169692186266772,
      "arc_challenge": 0.27303754266211605,
      "arc_easy": 0.4936868686868687,
      "openbookqa": 0.352,
      "piqa": 0.6735582154515778
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      14,
      4,
      14,
      14,
      2,
      14,
      10,
      4,
      16,
      16,
      8,
      14,
      4,
      10,
      12,
      2,
      14,
      8,
      16,
      12,
      4,
      2,
      8,
      12,
      12,
      8,
      10,
      14,
      2,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5877675840978593,
      "arc_easy": 0.4831649831649832,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.344,
      "arc_challenge": 0.27047781569965873,
      "hellaswag": 0.43019318860784705,
      "piqa": 0.6681175190424374
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      8,
      10,
      16,
      2,
      4,
      4,
      8,
      10,
      16,
      6,
      12,
      16,
      4,
      2,
      2,
      4,
      14,
      16,
      12,
      4,
      12,
      14,
      16,
      4,
      14,
      8,
      8,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4502091216889066,
      "piqa": 0.690424374319913,
      "openbookqa": 0.348,
      "arc_easy": 0.45454545454545453,
      "arc_challenge": 0.2815699658703072,
      "boolq": 0.45718654434250766,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      10,
      10,
      12,
      4,
      14,
      8,
      2,
      16,
      6,
      10,
      2,
      4,
      14,
      8,
      14,
      10,
      2,
      16,
      8,
      16,
      4,
      10,
      16,
      10,
      4,
      4,
      2,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2841296928327645,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.44991037641904,
      "winogrande": 0.5232833464877664,
      "boolq": 0.4767584097859327,
      "openbookqa": 0.344,
      "arc_easy": 0.44696969696969696
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      10,
      2,
      10,
      12,
      14,
      16,
      12,
      16,
      12,
      12,
      12,
      8,
      6,
      8,
      8,
      16,
      14,
      4,
      4,
      6,
      2,
      14,
      2,
      12,
      16,
      2,
      8,
      8,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4302927703644692,
      "piqa": 0.6751904243743199,
      "openbookqa": 0.348,
      "arc_challenge": 0.2687713310580205,
      "boolq": 0.5516819571865443,
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      6,
      12,
      2,
      4,
      2,
      10,
      14,
      4,
      12,
      6,
      8,
      16,
      6,
      14,
      14,
      4,
      2,
      12,
      16,
      16,
      6,
      6,
      14,
      8,
      6,
      10,
      14,
      6,
      16,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.27047781569965873,
      "hellaswag": 0.4302927703644692,
      "piqa": 0.6735582154515778,
      "openbookqa": 0.346,
      "boolq": 0.5663608562691131
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      6,
      8,
      6,
      16,
      4,
      12,
      10,
      14,
      10,
      12,
      2,
      2,
      12,
      14,
      2,
      12,
      8,
      16,
      2,
      4,
      6,
      2,
      14,
      4,
      14,
      16,
      14,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.346,
      "arc_easy": 0.44654882154882153,
      "piqa": 0.6882480957562568,
      "boolq": 0.42324159021406726,
      "hellaswag": 0.4482174865564629,
      "arc_challenge": 0.28498293515358364,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      2,
      12,
      12,
      16,
      14,
      2,
      16,
      8,
      10,
      4,
      14,
      4,
      6,
      4,
      2,
      4,
      12,
      6,
      16,
      2,
      8,
      4,
      4,
      16,
      2,
      12,
      10,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "arc_easy": 0.484006734006734,
      "boolq": 0.5801223241590214,
      "openbookqa": 0.336,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.27047781569965873,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      2,
      4,
      10,
      2,
      12,
      12,
      12,
      14,
      6,
      14,
      12,
      16,
      16,
      16,
      14,
      14,
      10,
      12,
      4,
      4,
      4,
      10,
      12,
      8,
      4,
      12,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "openbookqa": 0.352,
      "boolq": 0.5697247706422018,
      "hellaswag": 0.4342760406293567,
      "arc_challenge": 0.26535836177474403,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.48653198653198654
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      10,
      6,
      12,
      14,
      14,
      10,
      14,
      16,
      10,
      8,
      8,
      10,
      8,
      12,
      6,
      8,
      16,
      8,
      14,
      2,
      10,
      4,
      2,
      10,
      10,
      16,
      2,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4444444444444444,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.342,
      "boolq": 0.4565749235474006,
      "hellaswag": 0.4478191595299741,
      "piqa": 0.6920565832426551,
      "arc_challenge": 0.2790102389078498
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      2,
      12,
      10,
      12,
      16,
      10,
      8,
      14,
      8,
      10,
      10,
      6,
      12,
      8,
      16,
      4,
      4,
      6,
      2,
      4,
      2,
      10,
      10,
      10,
      16,
      6,
      12,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6866158868335147,
      "arc_challenge": 0.2858361774744027,
      "openbookqa": 0.35,
      "arc_easy": 0.44023569023569026,
      "hellaswag": 0.4478191595299741,
      "winogrande": 0.5138121546961326,
      "boolq": 0.42385321100917434
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      16,
      4,
      14,
      6,
      6,
      2,
      10,
      2,
      4,
      14,
      6,
      12,
      4,
      12,
      2,
      14,
      10,
      8,
      2,
      14,
      6,
      8,
      6,
      10,
      10,
      6,
      4,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4691131498470948,
      "hellaswag": 0.44831706831308504,
      "arc_challenge": 0.2815699658703072,
      "arc_easy": 0.44696969696969696,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6893362350380848,
      "openbookqa": 0.342
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      10,
      4,
      12,
      16,
      10,
      14,
      8,
      16,
      10,
      12,
      14,
      4,
      4,
      16,
      10,
      4,
      16,
      10,
      6,
      4,
      2,
      4,
      2,
      8,
      6,
      4,
      16,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.463914373088685,
      "arc_easy": 0.44823232323232326,
      "hellaswag": 0.45070703047201754,
      "openbookqa": 0.344,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.2841296928327645
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      2,
      2,
      4,
      4,
      6,
      14,
      4,
      2,
      4,
      14,
      16,
      12,
      12,
      4,
      4,
      6,
      8,
      6,
      2,
      16,
      2,
      2,
      16,
      2,
      14,
      2,
      14,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5240726124704025,
      "piqa": 0.6860718171926007,
      "hellaswag": 0.4495120493925513,
      "arc_easy": 0.45075757575757575,
      "boolq": 0.42660550458715596,
      "openbookqa": 0.348,
      "arc_challenge": 0.27474402730375425
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      14,
      2,
      16,
      16,
      2,
      10,
      8,
      2,
      12,
      12,
      16,
      2,
      16,
      12,
      14,
      4,
      16,
      6,
      16,
      8,
      2,
      6,
      10,
      12,
      4,
      2,
      4,
      4,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.44036697247706424,
      "arc_easy": 0.44402356902356904,
      "openbookqa": 0.344,
      "winogrande": 0.5256511444356748,
      "hellaswag": 0.4484166500697072,
      "arc_challenge": 0.2858361774744027,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      16,
      6,
      12,
      16,
      8,
      6,
      8,
      4,
      12,
      6,
      14,
      10,
      12,
      12,
      12,
      2,
      8,
      12,
      14,
      8,
      2,
      10,
      10,
      14,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4782874617737003,
      "arc_challenge": 0.2773037542662116,
      "piqa": 0.690424374319913,
      "openbookqa": 0.346,
      "hellaswag": 0.4475204142601075,
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.4524410774410774
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      10,
      4,
      4,
      6,
      12,
      6,
      10,
      2,
      12,
      2,
      14,
      16,
      8,
      2,
      10,
      6,
      6,
      6,
      4,
      8,
      16,
      12,
      10,
      8,
      12,
      2,
      6,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.4477195777733519,
      "winogrande": 0.5240726124704025,
      "boolq": 0.42782874617737005,
      "openbookqa": 0.348,
      "piqa": 0.691512513601741,
      "arc_challenge": 0.28242320819112626
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      8,
      14,
      2,
      4,
      10,
      14,
      14,
      12,
      16,
      8,
      10,
      14,
      14,
      16,
      2,
      2,
      16,
      4,
      10,
      12,
      6,
      8,
      12,
      2,
      6,
      16,
      10,
      6,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4326827325234017,
      "boolq": 0.5871559633027523,
      "arc_easy": 0.4898989898989899,
      "arc_challenge": 0.26706484641638223,
      "piqa": 0.6741022850924918,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.36
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      6,
      2,
      10,
      10,
      16,
      14,
      16,
      14,
      14,
      8,
      8,
      10,
      12,
      4,
      16,
      10,
      14,
      4,
      2,
      16,
      16,
      4,
      2,
      8,
      10,
      12,
      10,
      14,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.336,
      "hellaswag": 0.4487153953395738,
      "boolq": 0.44954128440366975,
      "arc_challenge": 0.28668941979522183,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44276094276094274,
      "winogrande": 0.5280189423835833
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      4,
      14,
      8,
      10,
      2,
      10,
      12,
      2,
      8,
      10,
      10,
      8,
      10,
      8,
      6,
      2,
      14,
      12,
      2,
      6,
      8,
      12,
      6,
      4,
      12,
      4,
      14,
      6,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44107744107744107,
      "boolq": 0.4666666666666667,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.35,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.28754266211604096,
      "hellaswag": 0.4486158135829516
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      8,
      12,
      6,
      10,
      16,
      6,
      4,
      12,
      8,
      2,
      2,
      6,
      14,
      16,
      2,
      14,
      12,
      14,
      2,
      16,
      12,
      2,
      16,
      8,
      14,
      12,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5516819571865443,
      "winogrande": 0.5232833464877664,
      "piqa": 0.6746463547334058,
      "openbookqa": 0.34,
      "arc_challenge": 0.27474402730375425,
      "arc_easy": 0.4877946127946128,
      "hellaswag": 0.43308105954989046
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      12,
      4,
      6,
      4,
      8,
      16,
      6,
      12,
      8,
      10,
      16,
      6,
      12,
      6,
      12,
      14,
      2,
      16,
      2,
      12,
      16,
      4,
      2,
      4,
      14,
      16,
      2,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4507645259938838,
      "winogrande": 0.5193370165745856,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.27474402730375425,
      "hellaswag": 0.4502091216889066,
      "openbookqa": 0.342
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      2,
      6,
      8,
      12,
      14,
      14,
      2,
      4,
      12,
      14,
      6,
      10,
      14,
      10,
      12,
      6,
      4,
      8,
      16,
      16,
      6,
      14,
      16,
      14,
      12,
      2,
      2,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6936887921653971,
      "openbookqa": 0.348,
      "hellaswag": 0.45130452101175067,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.43700305810397555,
      "arc_challenge": 0.2738907849829352,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      2,
      2,
      12,
      4,
      14,
      2,
      10,
      14,
      6,
      16,
      8,
      12,
      6,
      10,
      8,
      10,
      10,
      8,
      2,
      2,
      2,
      16,
      6,
      10,
      12,
      10,
      14,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "hellaswag": 0.4344752041426011,
      "piqa": 0.6730141458106638,
      "boolq": 0.5840978593272171,
      "openbookqa": 0.354,
      "arc_easy": 0.48358585858585856,
      "arc_challenge": 0.2696245733788396
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      6,
      10,
      14,
      4,
      4,
      6,
      8,
      16,
      4,
      16,
      6,
      2,
      6,
      10,
      16,
      6,
      6,
      12,
      10,
      12,
      2,
      14,
      2,
      2,
      2,
      12,
      4,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.348,
      "arc_challenge": 0.2790102389078498,
      "hellaswag": 0.4501095399322844,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.4363914373088685,
      "winogrande": 0.5240726124704025,
      "piqa": 0.6871599564744287
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      2,
      14,
      4,
      14,
      8,
      6,
      4,
      14,
      6,
      4,
      6,
      4,
      4,
      16,
      2,
      8,
      10,
      14,
      2,
      2,
      4,
      12,
      8,
      16,
      8,
      12,
      10,
      2,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "boolq": 0.43425076452599387,
      "arc_easy": 0.4562289562289562,
      "openbookqa": 0.352,
      "piqa": 0.691512513601741,
      "hellaswag": 0.45050786695877315,
      "arc_challenge": 0.2841296928327645
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      12,
      8,
      16,
      16,
      10,
      12,
      2,
      16,
      6,
      8,
      10,
      12,
      14,
      10,
      14,
      14,
      8,
      4,
      6,
      16,
      10,
      4,
      10,
      2,
      12,
      8,
      12,
      12,
      16,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.44617737003058106,
      "openbookqa": 0.354,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2815699658703072,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.44921330412268473,
      "arc_easy": 0.4414983164983165
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      4,
      14,
      4,
      8,
      8,
      14,
      2,
      6,
      14,
      10,
      4,
      4,
      14,
      12,
      6,
      8,
      10,
      14,
      12,
      16,
      8,
      16,
      4,
      16,
      2,
      16,
      6,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.2764505119453925,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.43158733320055764,
      "arc_easy": 0.4810606060606061,
      "openbookqa": 0.35,
      "boolq": 0.5749235474006116
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      16,
      6,
      16,
      10,
      4,
      10,
      4,
      8,
      14,
      2,
      8,
      10,
      2,
      16,
      4,
      12,
      16,
      16,
      8,
      6,
      4,
      10,
      16,
      2,
      2,
      2,
      12,
      8,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28924914675767915,
      "boolq": 0.42110091743119266,
      "arc_easy": 0.43897306397306396,
      "piqa": 0.6942328618063112,
      "openbookqa": 0.352,
      "hellaswag": 0.44761999601672975,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      14,
      12,
      4,
      14,
      6,
      12,
      12,
      2,
      16,
      16,
      6,
      8,
      4,
      14,
      6,
      4,
      2,
      12,
      4,
      16,
      6,
      12,
      10,
      4,
      12,
      12,
      6,
      6,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6741022850924918,
      "hellaswag": 0.4309898426608245,
      "boolq": 0.5944954128440367,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.2627986348122867,
      "arc_easy": 0.48274410774410775,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      12,
      2,
      10,
      12,
      8,
      14,
      14,
      12,
      4,
      10,
      2,
      8,
      16,
      16,
      10,
      8,
      10,
      16,
      10,
      4,
      4,
      10,
      4,
      10,
      14,
      8,
      2,
      16,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2790102389078498,
      "winogrande": 0.5090765588003157,
      "arc_easy": 0.4898989898989899,
      "openbookqa": 0.352,
      "boolq": 0.5883792048929664,
      "piqa": 0.6653971708378672,
      "hellaswag": 0.43248356901015733
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      2,
      6,
      6,
      8,
      8,
      6,
      14,
      8,
      14,
      4,
      2,
      2,
      14,
      6,
      8,
      8,
      6,
      10,
      14,
      12,
      6,
      10,
      12,
      16,
      4,
      14,
      6,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4312885879306911,
      "arc_challenge": 0.27047781569965873,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.4823232323232323,
      "openbookqa": 0.342,
      "piqa": 0.6713819368879217,
      "boolq": 0.5944954128440367
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      4,
      10,
      10,
      4,
      10,
      8,
      12,
      8,
      8,
      2,
      4,
      14,
      6,
      16,
      4,
      4,
      14,
      16,
      16,
      10,
      8,
      4,
      8,
      10,
      10,
      8,
      8,
      8,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6702937976060935,
      "boolq": 0.5844036697247706,
      "arc_challenge": 0.27303754266211605,
      "hellaswag": 0.43089026090420235,
      "openbookqa": 0.342,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      4,
      12,
      4,
      6,
      10,
      14,
      10,
      4,
      2,
      4,
      14,
      12,
      10,
      6,
      10,
      4,
      16,
      2,
      8,
      16,
      12,
      8,
      4,
      2,
      12,
      8,
      2,
      4,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6103975535168196,
      "piqa": 0.6708378672470077,
      "arc_easy": 0.4797979797979798,
      "hellaswag": 0.4329814777932683,
      "openbookqa": 0.344,
      "arc_challenge": 0.27047781569965873,
      "winogrande": 0.5090765588003157
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      12,
      10,
      6,
      16,
      6,
      14,
      14,
      6,
      2,
      12,
      6,
      10,
      2,
      14,
      6,
      12,
      14,
      16,
      10,
      8,
      6,
      14,
      10,
      12,
      10,
      4,
      6,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "boolq": 0.5804281345565749,
      "arc_challenge": 0.27303754266211605,
      "hellaswag": 0.43218482374029077,
      "openbookqa": 0.354,
      "piqa": 0.6719260065288357,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      2,
      6,
      2,
      14,
      4,
      12,
      16,
      8,
      2,
      16,
      8,
      12,
      2,
      4,
      14,
      16,
      14,
      6,
      2,
      14,
      14,
      6,
      16,
      8,
      6,
      4,
      8,
      12,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2832764505119454,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.4503367003367003,
      "hellaswag": 0.4523003385779725,
      "piqa": 0.6871599564744287,
      "openbookqa": 0.348,
      "boolq": 0.4636085626911315
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      6,
      4,
      8,
      8,
      4,
      6,
      2,
      4,
      10,
      4,
      6,
      2,
      14,
      8,
      10,
      8,
      4,
      6,
      14,
      8,
      16,
      8,
      8,
      8,
      6,
      16,
      10,
      6,
      2,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2713310580204778,
      "boolq": 0.5669724770642202,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.43108942441744674,
      "piqa": 0.6670293797606094,
      "arc_easy": 0.484006734006734,
      "openbookqa": 0.35
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      2,
      6,
      2,
      16,
      14,
      2,
      6,
      8,
      16,
      4,
      2,
      12,
      2,
      10,
      8,
      16,
      8,
      10,
      12,
      4,
      10,
      16,
      12,
      12,
      10,
      12,
      12,
      4,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.26621160409556316,
      "arc_easy": 0.47769360269360267,
      "openbookqa": 0.35,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6670293797606094,
      "hellaswag": 0.4344752041426011,
      "boolq": 0.5813455657492355
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      16,
      2,
      12,
      8,
      2,
      4,
      4,
      14,
      10,
      14,
      6,
      2,
      4,
      8,
      6,
      2,
      4,
      6,
      14,
      14,
      10,
      10,
      6,
      16,
      12,
      10,
      8,
      6,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.27986348122866894,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4541245791245791,
      "hellaswag": 0.44991037641904,
      "openbookqa": 0.35,
      "boolq": 0.4327217125382263
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      14,
      6,
      8,
      8,
      14,
      10,
      12,
      12,
      2,
      4,
      12,
      16,
      12,
      4,
      10,
      10,
      8,
      14,
      2,
      8,
      14,
      14,
      6,
      6,
      8,
      16,
      14,
      8,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4541284403669725,
      "hellaswag": 0.4487153953395738,
      "arc_easy": 0.44234006734006737,
      "winogrande": 0.5232833464877664,
      "piqa": 0.690968443960827,
      "openbookqa": 0.344,
      "arc_challenge": 0.27986348122866894
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      14,
      14,
      2,
      16,
      2,
      8,
      6,
      2,
      10,
      12,
      10,
      12,
      2,
      2,
      4,
      10,
      14,
      2,
      6,
      6,
      14,
      8,
      16,
      6,
      14,
      14,
      16,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2696245733788396,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5929663608562691,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.4326827325234017,
      "openbookqa": 0.348,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      12,
      16,
      2,
      16,
      2,
      8,
      10,
      14,
      16,
      12,
      10,
      16,
      12,
      12,
      2,
      6,
      16,
      8,
      2,
      10,
      12,
      8,
      2,
      4,
      2,
      6,
      14,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "piqa": 0.691512513601741,
      "arc_easy": 0.45286195286195285,
      "winogrande": 0.5217048145224941,
      "boolq": 0.40581039755351683,
      "arc_challenge": 0.2858361774744027,
      "hellaswag": 0.4487153953395738
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      8,
      8,
      6,
      16,
      10,
      8,
      4,
      2,
      10,
      14,
      10,
      8,
      8,
      4,
      6,
      2,
      2,
      2,
      14,
      10,
      16,
      10,
      14,
      14,
      8,
      16,
      12,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4810606060606061,
      "arc_challenge": 0.2738907849829352,
      "hellaswag": 0.4272057359091814,
      "openbookqa": 0.346,
      "winogrande": 0.5185477505919495,
      "boolq": 0.6048929663608563,
      "piqa": 0.6730141458106638
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      16,
      4,
      2,
      6,
      4,
      6,
      6,
      2,
      6,
      6,
      16,
      12,
      10,
      14,
      8,
      8,
      16,
      12,
      4,
      12,
      6,
      6,
      6,
      10,
      14,
      12,
      12,
      10,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43228440549691294,
      "boolq": 0.5834862385321101,
      "openbookqa": 0.352,
      "arc_challenge": 0.27047781569965873,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5090765588003157,
      "arc_easy": 0.4810606060606061
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      10,
      12,
      16,
      8,
      14,
      10,
      4,
      6,
      14,
      8,
      8,
      14,
      8,
      10,
      8,
      2,
      12,
      6,
      8,
      16,
      8,
      8,
      6,
      4,
      10,
      12,
      12,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6702937976060935,
      "boolq": 0.6015290519877676,
      "arc_easy": 0.48947811447811446,
      "hellaswag": 0.42929695279824737,
      "arc_challenge": 0.2696245733788396,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      8,
      16,
      4,
      8,
      6,
      16,
      6,
      2,
      2,
      6,
      14,
      10,
      14,
      2,
      10,
      16,
      8,
      2,
      8,
      6,
      2,
      6,
      6,
      12,
      14,
      12,
      14,
      14,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.47155963302752296,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.45030870344552876,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2841296928327645,
      "openbookqa": 0.348,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      10,
      12,
      4,
      4,
      6,
      16,
      12,
      12,
      14,
      8,
      12,
      10,
      12,
      14,
      16,
      16,
      2,
      12,
      4,
      10,
      8,
      6,
      2,
      6,
      8,
      10,
      16,
      4,
      2,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "arc_easy": 0.47769360269360267,
      "boolq": 0.5758409785932722,
      "openbookqa": 0.35,
      "arc_challenge": 0.27303754266211605,
      "hellaswag": 0.43228440549691294,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      10,
      6,
      14,
      6,
      2,
      10,
      4,
      8,
      2,
      14,
      10,
      16,
      14,
      4,
      2,
      4,
      16,
      14,
      6,
      6,
      14,
      10,
      16,
      4,
      10,
      2,
      4,
      4,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4436026936026936,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.4495120493925513,
      "openbookqa": 0.358,
      "boolq": 0.45902140672782876,
      "arc_challenge": 0.28071672354948807
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      2,
      10,
      6,
      4,
      16,
      10,
      12,
      12,
      8,
      16,
      12,
      14,
      16,
      4,
      14,
      10,
      14,
      10,
      4,
      12,
      2,
      14,
      10,
      16,
      4,
      4,
      10,
      16,
      10,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.43108942441744674,
      "arc_easy": 0.48695286195286197,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.27303754266211605,
      "piqa": 0.6741022850924918,
      "boolq": 0.5865443425076453,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      12,
      10,
      16,
      16,
      12,
      6,
      8,
      8,
      6,
      12,
      10,
      16,
      6,
      8,
      8,
      2,
      2,
      4,
      14,
      8,
      6,
      6,
      8,
      14,
      12,
      14,
      2,
      6,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.42691131498470947,
      "arc_challenge": 0.28242320819112626,
      "openbookqa": 0.35,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44402356902356904,
      "hellaswag": 0.4466241784505079,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      14,
      12,
      12,
      10,
      6,
      6,
      14,
      16,
      16,
      12,
      6,
      16,
      2,
      12,
      6,
      16,
      10,
      16,
      4,
      4,
      2,
      8,
      4,
      4,
      14,
      2,
      16,
      12,
      16,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27986348122866894,
      "openbookqa": 0.344,
      "winogrande": 0.5138121546961326,
      "hellaswag": 0.4495120493925513,
      "piqa": 0.6849836779107725,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.41376146788990825
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      4,
      6,
      10,
      2,
      14,
      4,
      2,
      8,
      6,
      12,
      16,
      6,
      2,
      10,
      6,
      14,
      4,
      14,
      12,
      8,
      14,
      4,
      14,
      12,
      8,
      4,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4309898426608245,
      "arc_easy": 0.4764309764309764,
      "openbookqa": 0.354,
      "winogrande": 0.5193370165745856,
      "boolq": 0.5663608562691131,
      "arc_challenge": 0.26706484641638223,
      "piqa": 0.6730141458106638
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      12,
      8,
      2,
      6,
      10,
      14,
      2,
      12,
      10,
      12,
      8,
      4,
      6,
      10,
      6,
      12,
      4,
      10,
      4,
      12,
      12,
      2,
      10,
      2,
      6,
      8,
      10,
      16,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "boolq": 0.44128440366972477,
      "openbookqa": 0.35,
      "arc_easy": 0.4503367003367003,
      "arc_challenge": 0.2832764505119454,
      "piqa": 0.6849836779107725,
      "hellaswag": 0.4493128858793069
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      8,
      12,
      16,
      14,
      10,
      12,
      16,
      14,
      16,
      8,
      2,
      10,
      12,
      2,
      10,
      10,
      6,
      4,
      14,
      16,
      12,
      12,
      10,
      14,
      4,
      10,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5908256880733945,
      "arc_challenge": 0.27047781569965873,
      "openbookqa": 0.348,
      "piqa": 0.6692056583242655,
      "hellaswag": 0.4313881696873133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      4,
      2,
      4,
      16,
      12,
      10,
      10,
      2,
      6,
      14,
      12,
      14,
      4,
      4,
      12,
      16,
      2,
      6,
      2,
      16,
      12,
      16,
      12,
      16,
      8,
      8,
      4,
      12,
      6,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4320852419836686,
      "arc_easy": 0.48863636363636365,
      "arc_challenge": 0.2721843003412969,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6730141458106638,
      "boolq": 0.5951070336391437,
      "openbookqa": 0.356
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      6,
      12,
      8,
      10,
      14,
      6,
      12,
      6,
      12,
      16,
      14,
      16,
      8,
      10,
      14,
      10,
      16,
      16,
      2,
      12,
      12,
      4,
      16,
      2,
      16,
      4,
      14,
      2,
      10,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.27559726962457337,
      "piqa": 0.6686615886833515,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.4326827325234017,
      "boolq": 0.591743119266055,
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      16,
      16,
      14,
      16,
      8,
      10,
      6,
      16,
      12,
      10,
      12,
      16,
      12,
      6,
      12,
      14,
      4,
      12,
      10,
      6,
      8,
      10,
      2,
      16,
      4,
      8,
      4,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "piqa": 0.6877040261153428,
      "boolq": 0.42324159021406726,
      "hellaswag": 0.4464250149372635,
      "openbookqa": 0.35,
      "arc_easy": 0.44191919191919193,
      "arc_challenge": 0.2773037542662116
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      2,
      16,
      12,
      8,
      6,
      16,
      14,
      6,
      16,
      8,
      12,
      14,
      8,
      16,
      8,
      6,
      8,
      16,
      4,
      10,
      10,
      6,
      8,
      16,
      4,
      16,
      16,
      12,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5694189602446483,
      "arc_challenge": 0.2687713310580205,
      "hellaswag": 0.43417645887273454,
      "winogrande": 0.5074980268350434,
      "openbookqa": 0.35,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.49452861952861954
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      10,
      4,
      2,
      12,
      12,
      6,
      16,
      10,
      16,
      12,
      12,
      16,
      10,
      16,
      14,
      2,
      12,
      6,
      12,
      8,
      16,
      8,
      8,
      14,
      4,
      16,
      8,
      8,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.344,
      "arc_challenge": 0.2841296928327645,
      "arc_easy": 0.4473905723905724,
      "piqa": 0.6877040261153428,
      "hellaswag": 0.44921330412268473,
      "boolq": 0.4773700305810398,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      10,
      8,
      2,
      6,
      2,
      10,
      8,
      10,
      2,
      16,
      14,
      2,
      16,
      12,
      2,
      16,
      14,
      14,
      12,
      16,
      2,
      8,
      10,
      12,
      8,
      6,
      4,
      10,
      16,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45454545454545453,
      "hellaswag": 0.44921330412268473,
      "arc_challenge": 0.2773037542662116,
      "piqa": 0.6931447225244831,
      "winogrande": 0.5209155485398579,
      "boolq": 0.48807339449541287,
      "openbookqa": 0.352
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      16,
      8,
      14,
      8,
      4,
      6,
      10,
      12,
      10,
      10,
      4,
      12,
      16,
      16,
      12,
      8,
      8,
      4,
      14,
      14,
      16,
      16,
      2,
      14,
      14,
      12,
      10,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.44652459669388567,
      "piqa": 0.6877040261153428,
      "openbookqa": 0.348,
      "winogrande": 0.5098658247829518,
      "arc_challenge": 0.2815699658703072,
      "arc_easy": 0.4398148148148148,
      "boolq": 0.47889908256880737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      6,
      14,
      10,
      4,
      8,
      2,
      14,
      14,
      14,
      6,
      6,
      12,
      6,
      14,
      4,
      16,
      16,
      16,
      14,
      16,
      8,
      8,
      12,
      16,
      12,
      10,
      4,
      6,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.342,
      "boolq": 0.4908256880733945,
      "arc_challenge": 0.28498293515358364,
      "piqa": 0.690424374319913,
      "arc_easy": 0.4431818181818182,
      "hellaswag": 0.450408285202151,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      8,
      2,
      16,
      2,
      2,
      2,
      16,
      16,
      12,
      8,
      8,
      16,
      10,
      10,
      16,
      14,
      8,
      6,
      14,
      10,
      14,
      16,
      10,
      8,
      8,
      2,
      4,
      12,
      2,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2721843003412969,
      "winogrande": 0.516179952644041,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.348,
      "hellaswag": 0.4320852419836686,
      "boolq": 0.5788990825688073,
      "arc_easy": 0.48442760942760943
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      4,
      12,
      8,
      6,
      16,
      16,
      8,
      8,
      16,
      12,
      16,
      10,
      2,
      6,
      16,
      10,
      2,
      14,
      4,
      8,
      2,
      6,
      14,
      12,
      4,
      4,
      2,
      4,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.352,
      "boolq": 0.6033639143730887,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6735582154515778,
      "hellaswag": 0.433877713602868,
      "winogrande": 0.5059194948697711,
      "arc_challenge": 0.2713310580204778
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      10,
      2,
      2,
      10,
      14,
      14,
      6,
      8,
      10,
      14,
      8,
      16,
      6,
      8,
      4,
      16,
      14,
      8,
      8,
      10,
      6,
      12,
      16,
      14,
      16,
      4,
      16,
      8,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "piqa": 0.6887921653971708,
      "arc_easy": 0.45454545454545453,
      "boolq": 0.44128440366972477,
      "openbookqa": 0.346,
      "hellaswag": 0.4493128858793069,
      "arc_challenge": 0.2773037542662116
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      12,
      16,
      16,
      6,
      16,
      8,
      14,
      16,
      4,
      6,
      10,
      16,
      14,
      8,
      12,
      6,
      14,
      4,
      4,
      12,
      14,
      16,
      6,
      2,
      12,
      2,
      2,
      14,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.45050786695877315,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44276094276094274,
      "openbookqa": 0.35,
      "arc_challenge": 0.28498293515358364,
      "boolq": 0.4541284403669725
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      6,
      14,
      12,
      8,
      10,
      8,
      14,
      16,
      16,
      6,
      16,
      2,
      14,
      2,
      14,
      4,
      2,
      10,
      16,
      6,
      16,
      16,
      14,
      2,
      4,
      6,
      12,
      10,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48863636363636365,
      "piqa": 0.676278563656148,
      "boolq": 0.5614678899082569,
      "arc_challenge": 0.2645051194539249,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.342,
      "hellaswag": 0.43158733320055764
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      16,
      6,
      6,
      16,
      6,
      6,
      6,
      2,
      10,
      16,
      10,
      16,
      8,
      2,
      6,
      16,
      16,
      14,
      2,
      14,
      6,
      6,
      4,
      2,
      2,
      8,
      8,
      6,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5764525993883792,
      "piqa": 0.6708378672470077,
      "openbookqa": 0.34,
      "hellaswag": 0.43089026090420235,
      "arc_challenge": 0.2738907849829352,
      "winogrande": 0.5130228887134964,
      "arc_easy": 0.4831649831649832
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      14,
      12,
      16,
      16,
      2,
      6,
      4,
      10,
      2,
      6,
      8,
      16,
      16,
      6,
      16,
      10,
      16,
      2,
      6,
      16,
      12,
      2,
      4,
      2,
      10,
      6,
      2,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.544954128440367,
      "winogrande": 0.5082872928176796,
      "arc_challenge": 0.26791808873720135,
      "openbookqa": 0.354,
      "hellaswag": 0.4311890061740689,
      "arc_easy": 0.4797979797979798,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      10,
      14,
      2,
      6,
      2,
      16,
      12,
      4,
      16,
      10,
      4,
      4,
      16,
      12,
      2,
      6,
      10,
      16,
      4,
      12,
      16,
      14,
      2,
      2,
      16,
      2,
      8,
      6,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "boolq": 0.4400611620795107,
      "hellaswag": 0.44981079466241786,
      "openbookqa": 0.342,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.690968443960827,
      "arc_challenge": 0.2773037542662116
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      16,
      6,
      6,
      6,
      2,
      8,
      12,
      4,
      6,
      10,
      10,
      8,
      14,
      8,
      14,
      2,
      6,
      10,
      16,
      6,
      10,
      2,
      6,
      12,
      10,
      6,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.43248356901015733,
      "openbookqa": 0.348,
      "boolq": 0.5709480122324159,
      "arc_challenge": 0.26791808873720135,
      "arc_easy": 0.47769360269360267
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      12,
      16,
      8,
      16,
      14,
      12,
      6,
      6,
      10,
      10,
      2,
      16,
      6,
      4,
      8,
      16,
      6,
      16,
      8,
      14,
      2,
      14,
      12,
      12,
      12,
      10,
      2,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "hellaswag": 0.4309898426608245,
      "boolq": 0.5648318042813456,
      "arc_challenge": 0.2764505119453925,
      "winogrande": 0.5098658247829518,
      "arc_easy": 0.4751683501683502,
      "openbookqa": 0.35
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      4,
      14,
      14,
      6,
      6,
      2,
      16,
      14,
      10,
      12,
      2,
      10,
      6,
      2,
      16,
      14,
      4,
      4,
      8,
      2,
      2,
      6,
      14,
      14,
      6,
      6,
      6,
      14,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.4502091216889066,
      "arc_easy": 0.45075757575757575,
      "piqa": 0.6871599564744287,
      "boolq": 0.46299694189602447,
      "arc_challenge": 0.28498293515358364,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.342
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      8,
      14,
      12,
      12,
      12,
      2,
      6,
      10,
      16,
      6,
      2,
      14,
      16,
      12,
      10,
      4,
      16,
      16,
      14,
      14,
      16,
      16,
      8,
      4,
      16,
      8,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.44961163114917346,
      "arc_challenge": 0.28242320819112626,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4444444444444444,
      "openbookqa": 0.35,
      "boolq": 0.47553516819571867
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      10,
      14,
      8,
      4,
      6,
      8,
      12,
      10,
      6,
      12,
      4,
      12,
      4,
      4,
      12,
      4,
      16,
      16,
      12,
      6,
      10,
      16,
      8,
      14,
      4,
      8,
      8,
      6,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5440366972477064,
      "openbookqa": 0.342,
      "hellaswag": 0.43487353116908983,
      "arc_challenge": 0.26791808873720135,
      "arc_easy": 0.4852693602693603,
      "piqa": 0.6746463547334058,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      10,
      8,
      8,
      16,
      16,
      16,
      2,
      14,
      14,
      8,
      4,
      6,
      10,
      6,
      6,
      12,
      16,
      8,
      6,
      10,
      2,
      6,
      6,
      14,
      2,
      12,
      2,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.4730886850152905,
      "hellaswag": 0.4506074487153953,
      "arc_challenge": 0.2764505119453925,
      "arc_easy": 0.44612794612794615,
      "winogrande": 0.5098658247829518,
      "openbookqa": 0.348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      16,
      10,
      8,
      8,
      12,
      16,
      14,
      4,
      4,
      14,
      12,
      14,
      2,
      6,
      14,
      16,
      8,
      6,
      4,
      2,
      14,
      6,
      16,
      8,
      8,
      12,
      12,
      4,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5935779816513761,
      "arc_easy": 0.476010101010101,
      "piqa": 0.6702937976060935,
      "hellaswag": 0.4313881696873133,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.348,
      "arc_challenge": 0.26621160409556316
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      2,
      4,
      16,
      6,
      14,
      6,
      10,
      6,
      6,
      8,
      10,
      14,
      2,
      10,
      14,
      6,
      16,
      6,
      16,
      2,
      10,
      2,
      6,
      4,
      6,
      12,
      8,
      14,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.45140410276837284,
      "piqa": 0.6877040261153428,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.35,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.44770642201834865,
      "arc_challenge": 0.28754266211604096
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      10,
      14,
      16,
      6,
      8,
      14,
      14,
      2,
      2,
      2,
      4,
      14,
      12,
      12,
      12,
      6,
      6,
      4,
      4,
      10,
      12,
      14,
      4,
      12,
      8,
      16,
      6,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2841296928327645,
      "boolq": 0.42110091743119266,
      "arc_easy": 0.4414983164983165,
      "openbookqa": 0.35,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.4506074487153953,
      "winogrande": 0.5288082083662194
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      14,
      10,
      4,
      6,
      8,
      2,
      2,
      8,
      16,
      2,
      12,
      4,
      10,
      16,
      6,
      2,
      12,
      8,
      16,
      16,
      8,
      10,
      16,
      16,
      8,
      14,
      16,
      12,
      10,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.28071672354948807,
      "piqa": 0.6860718171926007,
      "hellaswag": 0.4484166500697072,
      "boolq": 0.4602446483180428,
      "arc_easy": 0.4473905723905724,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.352
    }
  }
]