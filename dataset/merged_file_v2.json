[
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6393,
      "arc_challenge": 0.3567,
      "winogrande": 0.6133,
      "openbookqa": 0.406,
      "boolq": 0.5034,
      "piqa": 0.7524,
      "hellaswag": 0.641
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6347,
      "arc_challenge": 0.3567,
      "winogrande": 0.6038,
      "openbookqa": 0.296,
      "boolq": 0.578,
      "piqa": 0.7535,
      "hellaswag": 0.6431
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6313,
      "arc_challenge": 0.3584,
      "winogrande": 0.6062,
      "openbookqa": 0.404,
      "boolq": 0.4859,
      "piqa": 0.7519,
      "hellaswag": 0.6405
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6423,
      "arc_challenge": 0.3567,
      "winogrande": 0.6046,
      "openbookqa": 0.412,
      "boolq": 0.6162,
      "piqa": 0.7497,
      "hellaswag": 0.6432
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      16.0,
      16.0,
      2.0,
      2.0,
      2.0,
      8.0,
      2.0,
      16.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6292,
      "arc_challenge": 0.3592,
      "winogrande": 0.6077,
      "openbookqa": 0.41,
      "boolq": 0.5251,
      "piqa": 0.7546,
      "hellaswag": 0.6398
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      6.0,
      10.0,
      10.0,
      2.0,
      10.0,
      6.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      6.0,
      2.0,
      2.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.633,
      "arc_challenge": 0.3601,
      "winogrande": 0.6101,
      "openbookqa": 0.4,
      "boolq": 0.585,
      "piqa": 0.7568,
      "hellaswag": 0.6423
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      2.0,
      8.0,
      2.0,
      8.0,
      12.0,
      4.0,
      2.0,
      10.0,
      12.0,
      10.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      10.0,
      2.0,
      12.0,
      12.0,
      8.0,
      4.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6242,
      "arc_challenge": 0.3507,
      "winogrande": 0.6196,
      "openbookqa": 0.412,
      "boolq": 0.5193,
      "piqa": 0.7617,
      "hellaswag": 0.6387
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      10.0,
      4.0,
      2.0,
      4.0,
      2.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      2.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      12.0,
      4.0,
      4.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6326,
      "arc_challenge": 0.3558,
      "winogrande": 0.6054,
      "openbookqa": 0.408,
      "boolq": 0.5814,
      "piqa": 0.7595,
      "hellaswag": 0.6395
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6313,
      "arc_challenge": 0.3507,
      "winogrande": 0.6085,
      "openbookqa": 0.402,
      "boolq": 0.526,
      "piqa": 0.7557,
      "hellaswag": 0.636
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6258,
      "arc_challenge": 0.3635,
      "winogrande": 0.6077,
      "openbookqa": 0.406,
      "boolq": 0.5792,
      "piqa": 0.7546,
      "hellaswag": 0.6396
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.484,
      "arc_challenge": 0.2645,
      "winogrande": 0.5201,
      "openbookqa": 0.34,
      "boolq": 0.5951,
      "piqa": 0.6687,
      "hellaswag": 0.4318
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      10.0,
      12.0,
      12.0,
      6.0,
      10.0,
      6.0,
      6.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      12.0,
      12.0,
      6.0,
      4.0,
      10.0,
      6.0,
      2.0,
      2.0,
      8.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4848,
      "arc_challenge": 0.2782,
      "winogrande": 0.513,
      "openbookqa": 0.358,
      "boolq": 0.5697,
      "piqa": 0.6763,
      "hellaswag": 0.4334
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      12.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      2.0,
      6.0,
      12.0,
      2.0,
      2.0,
      4.0,
      8.0,
      6.0,
      2.0,
      12.0,
      4.0,
      2.0,
      2.0,
      2.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4861,
      "arc_challenge": 0.2782,
      "winogrande": 0.5162,
      "openbookqa": 0.352,
      "boolq": 0.5532,
      "piqa": 0.6752,
      "hellaswag": 0.4305
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      6.0,
      8.0,
      4.0,
      12.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      10.0,
      8.0,
      4.0,
      4.0,
      2.0,
      12.0,
      10.0,
      12.0,
      2.0,
      6.0,
      6.0,
      4.0,
      2.0,
      8.0,
      2.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819,
      "arc_challenge": 0.2747,
      "winogrande": 0.5107,
      "openbookqa": 0.352,
      "boolq": 0.5428,
      "piqa": 0.6741,
      "hellaswag": 0.4348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      4.0,
      6.0,
      2.0,
      2.0,
      10.0,
      4.0,
      6.0,
      12.0,
      12.0,
      2.0,
      2.0,
      12.0,
      6.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      10.0,
      10.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.476,
      "arc_challenge": 0.2611,
      "winogrande": 0.5107,
      "openbookqa": 0.346,
      "boolq": 0.5902,
      "piqa": 0.6752,
      "hellaswag": 0.4327
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      8.0,
      2.0,
      2.0,
      8.0,
      10.0,
      2.0,
      2.0,
      12.0,
      6.0,
      8.0,
      2.0,
      2.0,
      2.0,
      10.0,
      10.0,
      8.0,
      2.0,
      6.0,
      2.0,
      4.0,
      10.0,
      2.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4773,
      "arc_challenge": 0.2782,
      "winogrande": 0.5162,
      "openbookqa": 0.356,
      "boolq": 0.5872,
      "piqa": 0.6697,
      "hellaswag": 0.4332
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4836,
      "arc_challenge": 0.2654,
      "winogrande": 0.5154,
      "openbookqa": 0.358,
      "boolq": 0.5804,
      "piqa": 0.673,
      "hellaswag": 0.432
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      6.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4853,
      "arc_challenge": 0.2756,
      "winogrande": 0.5154,
      "openbookqa": 0.354,
      "boolq": 0.5963,
      "piqa": 0.667,
      "hellaswag": 0.43
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      4.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      6.0,
      4.0,
      12.0,
      8.0,
      12.0,
      2.0,
      10.0,
      6.0,
      4.0,
      6.0,
      2.0,
      10.0,
      10.0,
      4.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.487,
      "arc_challenge": 0.2637,
      "winogrande": 0.5178,
      "openbookqa": 0.342,
      "boolq": 0.5872,
      "piqa": 0.6708,
      "hellaswag": 0.4324
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      4.0,
      4.0,
      10.0,
      6.0,
      12.0,
      8.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      12.0,
      6.0,
      4.0,
      4.0,
      2.0,
      10.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.479,
      "arc_challenge": 0.2765,
      "winogrande": 0.517,
      "openbookqa": 0.354,
      "boolq": 0.5991,
      "piqa": 0.673,
      "hellaswag": 0.4331
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      4.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      8.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      10.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4806,
      "arc_challenge": 0.2705,
      "winogrande": 0.5241,
      "openbookqa": 0.346,
      "boolq": 0.5587,
      "piqa": 0.6714,
      "hellaswag": 0.4311
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      4.0,
      12.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      6.0,
      4.0,
      4.0,
      2.0,
      10.0,
      10.0,
      6.0,
      4.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4811,
      "arc_challenge": 0.2747,
      "winogrande": 0.5178,
      "openbookqa": 0.34,
      "boolq": 0.5777,
      "piqa": 0.6714,
      "hellaswag": 0.4297
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      2.0,
      4.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      8.0,
      4.0,
      4.0,
      2.0,
      10.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4865,
      "arc_challenge": 0.2671,
      "winogrande": 0.5249,
      "openbookqa": 0.342,
      "boolq": 0.5621,
      "piqa": 0.6697,
      "hellaswag": 0.433
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      6.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      6.0,
      4.0,
      4.0,
      2.0,
      10.0,
      10.0,
      6.0,
      4.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4811,
      "arc_challenge": 0.2722,
      "winogrande": 0.5138,
      "openbookqa": 0.348,
      "boolq": 0.5804,
      "piqa": 0.6736,
      "hellaswag": 0.435
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      4.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      6.0,
      8.0,
      4.0,
      2.0,
      10.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4853,
      "arc_challenge": 0.2688,
      "winogrande": 0.5185,
      "openbookqa": 0.35,
      "boolq": 0.5914,
      "piqa": 0.6725,
      "hellaswag": 0.4311
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      4.0,
      10.0,
      6.0,
      12.0,
      12.0,
      4.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      6.0,
      12.0,
      2.0,
      10.0,
      6.0,
      4.0,
      4.0,
      2.0,
      10.0,
      12.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4832,
      "arc_challenge": 0.2765,
      "winogrande": 0.5217,
      "openbookqa": 0.354,
      "boolq": 0.5676,
      "piqa": 0.6746,
      "hellaswag": 0.4306
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.673,
      "arc_challenge": 0.3771,
      "winogrande": 0.6314,
      "openbookqa": 0.404,
      "boolq": 0.5777,
      "piqa": 0.7758,
      "hellaswag": 0.6716
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      2.0,
      10.0,
      6.0,
      2.0,
      10.0,
      12.0,
      12.0,
      12.0,
      2.0,
      8.0,
      6.0,
      10.0,
      6.0,
      10.0,
      2.0,
      6.0,
      2.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6768,
      "arc_challenge": 0.3805,
      "winogrande": 0.6385,
      "openbookqa": 0.408,
      "boolq": 0.5651,
      "piqa": 0.7709,
      "hellaswag": 0.6732
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.673,
      "arc_challenge": 0.3771,
      "winogrande": 0.6314,
      "openbookqa": 0.404,
      "boolq": 0.5777,
      "piqa": 0.7758,
      "hellaswag": 0.6716
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      16.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6734,
      "arc_challenge": 0.3737,
      "winogrande": 0.6369,
      "openbookqa": 0.404,
      "boolq": 0.5098,
      "piqa": 0.7726,
      "hellaswag": 0.6732
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6599,
      "arc_challenge": 0.3695,
      "winogrande": 0.6425,
      "openbookqa": 0.41,
      "boolq": 0.5673,
      "piqa": 0.7726,
      "hellaswag": 0.6685
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      10.0,
      12.0,
      2.0,
      12.0,
      12.0,
      10.0,
      8.0,
      12.0,
      4.0,
      6.0,
      6.0,
      4.0,
      10.0,
      4.0,
      2.0,
      10.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6755,
      "arc_challenge": 0.3695,
      "winogrande": 0.6401,
      "openbookqa": 0.404,
      "boolq": 0.541,
      "piqa": 0.7715,
      "hellaswag": 0.6703
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      16.0,
      2.0,
      16.0,
      2.0,
      16.0,
      2.0,
      4.0,
      16.0,
      4.0,
      2.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6832,
      "arc_challenge": 0.3788,
      "winogrande": 0.6354,
      "openbookqa": 0.4,
      "boolq": 0.5138,
      "piqa": 0.7726,
      "hellaswag": 0.6742
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      16.0,
      16.0,
      2.0,
      2.0,
      2.0,
      8.0,
      2.0,
      16.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.67,
      "arc_challenge": 0.3746,
      "winogrande": 0.6251,
      "openbookqa": 0.406,
      "boolq": 0.6,
      "piqa": 0.7715,
      "hellaswag": 0.6684
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      6.0,
      10.0,
      10.0,
      2.0,
      10.0,
      6.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      6.0,
      2.0,
      2.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6646,
      "arc_challenge": 0.3677,
      "winogrande": 0.6354,
      "openbookqa": 0.406,
      "boolq": 0.6119,
      "piqa": 0.7688,
      "hellaswag": 0.6665
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      10.0,
      10.0,
      10.0,
      2.0,
      2.0,
      2.0,
      4.0,
      10.0,
      4.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      10.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6717,
      "arc_challenge": 0.3643,
      "winogrande": 0.6306,
      "openbookqa": 0.412,
      "boolq": 0.5899,
      "piqa": 0.7693,
      "hellaswag": 0.667
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      8.0,
      16.0,
      2.0,
      8.0,
      16.0,
      16.0,
      2.0,
      16.0,
      8.0,
      2.0,
      2.0,
      2.0,
      16.0,
      16.0,
      16.0,
      8.0,
      2.0,
      4.0,
      2.0,
      2.0,
      16.0,
      2.0,
      2.0,
      16.0,
      16.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6641,
      "arc_challenge": 0.372,
      "winogrande": 0.6346,
      "openbookqa": 0.402,
      "boolq": 0.4847,
      "piqa": 0.7573,
      "hellaswag": 0.6684
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      16.0,
      2.0,
      2.0,
      2.0,
      16.0,
      2.0,
      16.0,
      16.0,
      4.0,
      16.0,
      4.0,
      16.0,
      8.0,
      16.0,
      2.0,
      2.0,
      8.0,
      8.0,
      16.0,
      8.0,
      4.0,
      2.0,
      16.0,
      16.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6595,
      "arc_challenge": 0.3746,
      "winogrande": 0.6401,
      "openbookqa": 0.412,
      "boolq": 0.5982,
      "piqa": 0.7693,
      "hellaswag": 0.6656
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      10.0,
      4.0,
      2.0,
      4.0,
      2.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      2.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      12.0,
      4.0,
      4.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6439,
      "arc_challenge": 0.366,
      "winogrande": 0.6046,
      "openbookqa": 0.41,
      "boolq": 0.5034,
      "piqa": 0.7601,
      "hellaswag": 0.6429
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5901,
      "arc_challenge": 0.3379,
      "winogrande": 0.6062,
      "openbookqa": 0.388,
      "boolq": 0.5881,
      "piqa": 0.7437,
      "hellaswag": 0.607
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      16.0,
      16.0,
      2.0,
      2.0,
      2.0,
      8.0,
      2.0,
      16.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5985,
      "arc_challenge": 0.3396,
      "winogrande": 0.5983,
      "openbookqa": 0.394,
      "boolq": 0.5694,
      "piqa": 0.7508,
      "hellaswag": 0.6069
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      6.0,
      10.0,
      10.0,
      2.0,
      10.0,
      6.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      6.0,
      2.0,
      2.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5863,
      "arc_challenge": 0.3464,
      "winogrande": 0.603,
      "openbookqa": 0.376,
      "boolq": 0.5813,
      "piqa": 0.7541,
      "hellaswag": 0.6118
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      10.0,
      10.0,
      10.0,
      2.0,
      2.0,
      2.0,
      4.0,
      10.0,
      4.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      10.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6094,
      "arc_challenge": 0.3481,
      "winogrande": 0.6022,
      "openbookqa": 0.39,
      "boolq": 0.5758,
      "piqa": 0.7557,
      "hellaswag": 0.6163
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      2.0,
      8.0,
      2.0,
      8.0,
      12.0,
      4.0,
      2.0,
      10.0,
      12.0,
      10.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      10.0,
      2.0,
      12.0,
      12.0,
      8.0,
      4.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5972,
      "arc_challenge": 0.3422,
      "winogrande": 0.6093,
      "openbookqa": 0.384,
      "boolq": 0.5841,
      "piqa": 0.7454,
      "hellaswag": 0.6125
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      10.0,
      4.0,
      2.0,
      4.0,
      2.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      2.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      12.0,
      4.0,
      4.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5972,
      "arc_challenge": 0.3481,
      "winogrande": 0.6101,
      "openbookqa": 0.3394,
      "boolq": 0.5789,
      "piqa": 0.7514,
      "hellaswag": 0.6064
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5922,
      "arc_challenge": 0.3447,
      "winogrande": 0.5975,
      "openbookqa": 0.386,
      "boolq": 0.5801,
      "piqa": 0.7535,
      "hellaswag": 0.6089
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5842,
      "arc_challenge": 0.3404,
      "winogrande": 0.6125,
      "openbookqa": 0.37,
      "boolq": 0.5557,
      "piqa": 0.7514,
      "hellaswag": 0.6077
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      10.0,
      12.0,
      12.0,
      6.0,
      10.0,
      6.0,
      6.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      12.0,
      12.0,
      6.0,
      4.0,
      10.0,
      6.0,
      2.0,
      2.0,
      8.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6048,
      "arc_challenge": 0.3336,
      "winogrande": 0.5885,
      "openbookqa": 0.392,
      "boolq": 0.564,
      "piqa": 0.7573,
      "hellaswag": 0.6131
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      4.0,
      6.0,
      2.0,
      2.0,
      10.0,
      4.0,
      6.0,
      12.0,
      12.0,
      2.0,
      2.0,
      12.0,
      6.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      10.0,
      10.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5898,
      "arc_challenge": 0.3362,
      "winogrande": 0.6014,
      "openbookqa": 0.396,
      "boolq": 0.5991,
      "piqa": 0.7557,
      "hellaswag": 0.6155
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6376,
      "arc_challenge": 0.3711,
      "winogrande": 0.6338,
      "openbookqa": 0.406,
      "boolq": 0.633,
      "piqa": 0.7682,
      "hellaswag": 0.6868
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      6.0,
      4.0,
      6.0,
      2.0,
      6.0,
      6.0,
      6.0,
      4.0,
      2.0,
      4.0,
      2.0,
      6.0,
      2.0,
      6.0,
      4.0,
      2.0,
      2.0,
      6.0,
      6.0,
      4.0,
      6.0,
      2.0,
      6.0,
      2.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6343,
      "arc_challenge": 0.3695,
      "winogrande": 0.6369,
      "openbookqa": 0.402,
      "boolq": 0.6486,
      "piqa": 0.7688,
      "hellaswag": 0.6833
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      4.0,
      4.0,
      2.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      6.0,
      4.0,
      6.0,
      4.0,
      6.0,
      6.0,
      2.0,
      6.0,
      6.0,
      6.0,
      6.0,
      6.0,
      4.0,
      6.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6452,
      "arc_challenge": 0.3788,
      "winogrande": 0.6346,
      "openbookqa": 0.408,
      "boolq": 0.645,
      "piqa": 0.7666,
      "hellaswag": 0.6865
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      2.0,
      2.0,
      6.0,
      6.0,
      6.0,
      6.0,
      6.0,
      2.0,
      4.0,
      6.0,
      4.0,
      6.0,
      6.0,
      4.0,
      2.0,
      6.0,
      4.0,
      6.0,
      6.0,
      2.0,
      4.0,
      4.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6469,
      "arc_challenge": 0.3737,
      "winogrande": 0.633,
      "openbookqa": 0.404,
      "boolq": 0.6483,
      "piqa": 0.7693,
      "hellaswag": 0.6883
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      4.0,
      10.0,
      4.0,
      6.0,
      6.0,
      2.0,
      10.0,
      8.0,
      12.0,
      12.0,
      10.0,
      12.0,
      12.0,
      10.0,
      6.0,
      6.0,
      8.0,
      8.0,
      10.0,
      6.0,
      12.0,
      12.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6456,
      "arc_challenge": 0.3695,
      "winogrande": 0.6393,
      "openbookqa": 0.406,
      "boolq": 0.6483,
      "piqa": 0.7699,
      "hellaswag": 0.6847
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6524,
      "arc_challenge": 0.3754,
      "winogrande": 0.6314,
      "openbookqa": 0.408,
      "boolq": 0.6691,
      "piqa": 0.7693,
      "hellaswag": 0.6878
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      10.0,
      12.0,
      2.0,
      12.0,
      12.0,
      10.0,
      8.0,
      12.0,
      4.0,
      6.0,
      6.0,
      4.0,
      10.0,
      4.0,
      2.0,
      10.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6469,
      "arc_challenge": 0.3737,
      "winogrande": 0.6393,
      "openbookqa": 0.408,
      "boolq": 0.6437,
      "piqa": 0.7688,
      "hellaswag": 0.6892
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      2.0,
      4.0,
      4.0,
      12.0,
      2.0,
      10.0,
      6.0,
      2.0,
      10.0,
      12.0,
      12.0,
      12.0,
      2.0,
      8.0,
      6.0,
      10.0,
      6.0,
      10.0,
      2.0,
      6.0,
      2.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.641,
      "arc_challenge": 0.3797,
      "winogrande": 0.633,
      "openbookqa": 0.408,
      "boolq": 0.6459,
      "piqa": 0.7671,
      "hellaswag": 0.6878
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      16.0,
      2.0,
      16.0,
      2.0,
      16.0,
      2.0,
      4.0,
      16.0,
      4.0,
      2.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6439,
      "arc_challenge": 0.3737,
      "winogrande": 0.6393,
      "openbookqa": 0.4,
      "boolq": 0.6425,
      "piqa": 0.7688,
      "hellaswag": 0.6863
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      16.0,
      2.0,
      16.0,
      16.0,
      16.0,
      2.0,
      4.0,
      16.0,
      16.0,
      2.0,
      4.0,
      4.0,
      16.0,
      16.0,
      16.0,
      2.0,
      2.0,
      2.0,
      8.0,
      2.0,
      16.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6376,
      "arc_challenge": 0.3643,
      "winogrande": 0.6354,
      "openbookqa": 0.402,
      "boolq": 0.6498,
      "piqa": 0.7671,
      "hellaswag": 0.688
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      4.0,
      4.0,
      4.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      10.0,
      6.0,
      10.0,
      10.0,
      4.0,
      2.0,
      6.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      10.0,
      2.0,
      2.0,
      6.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6448,
      "arc_challenge": 0.3695,
      "winogrande": 0.6385,
      "openbookqa": 0.404,
      "boolq": 0.645,
      "piqa": 0.7688,
      "hellaswag": 0.688
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      10.0,
      2.0,
      10.0,
      4.0,
      4.0,
      2.0,
      10.0,
      4.0,
      4.0,
      10.0,
      6.0,
      10.0,
      10.0,
      10.0,
      10.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6288,
      "arc_challenge": 0.3754,
      "winogrande": 0.6322,
      "openbookqa": 0.406,
      "boolq": 0.6517,
      "piqa": 0.7666,
      "hellaswag": 0.6873
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      10.0,
      6.0,
      6.0,
      10.0,
      6.0,
      10.0,
      10.0,
      4.0,
      10.0,
      10.0,
      4.0,
      6.0,
      2.0,
      2.0,
      10.0,
      4.0,
      4.0,
      10.0,
      2.0,
      10.0,
      10.0,
      4.0,
      2.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6473,
      "arc_challenge": 0.366,
      "winogrande": 0.6346,
      "openbookqa": 0.408,
      "boolq": 0.6443,
      "piqa": 0.7699,
      "hellaswag": 0.6875
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      4.0,
      10.0,
      10.0,
      6.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      2.0,
      2.0,
      10.0,
      2.0,
      4.0,
      2.0,
      10.0,
      10.0,
      10.0,
      4.0,
      10.0,
      10.0,
      6.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6465,
      "arc_challenge": 0.3754,
      "winogrande": 0.6306,
      "openbookqa": 0.408,
      "boolq": 0.6486,
      "piqa": 0.7704,
      "hellaswag": 0.69
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6162,
      "arc_challenge": 0.3746,
      "winogrande": 0.6267,
      "openbookqa": 0.4,
      "boolq": 0.659,
      "piqa": 0.7682,
      "hellaswag": 0.6835
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6561,
      "arc_challenge": 0.3873,
      "winogrande": 0.6172,
      "openbookqa": 0.41,
      "boolq": 0.63,
      "piqa": 0.7666,
      "hellaswag": 0.6843
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6284,
      "arc_challenge": 0.3677,
      "winogrande": 0.6322,
      "openbookqa": 0.398,
      "boolq": 0.6648,
      "piqa": 0.7682,
      "hellaswag": 0.6788
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6532,
      "arc_challenge": 0.3771,
      "winogrande": 0.6314,
      "openbookqa": 0.41,
      "boolq": 0.6443,
      "piqa": 0.7715,
      "hellaswag": 0.6852
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6397,
      "arc_challenge": 0.3729,
      "winogrande": 0.6361,
      "openbookqa": 0.398,
      "boolq": 0.6581,
      "piqa": 0.7699,
      "hellaswag": 0.6856
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      10.0,
      6.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6452,
      "arc_challenge": 0.3865,
      "winogrande": 0.6204,
      "openbookqa": 0.4,
      "boolq": 0.6728,
      "piqa": 0.765,
      "hellaswag": 0.6808
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5871,
      "arc_challenge": 0.337,
      "winogrande": 0.6314,
      "openbookqa": 0.398,
      "boolq": 0.6373,
      "piqa": 0.7465,
      "hellaswag": 0.6357
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      10.0,
      12.0,
      12.0,
      6.0,
      10.0,
      6.0,
      6.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      12.0,
      12.0,
      6.0,
      4.0,
      10.0,
      6.0,
      2.0,
      2.0,
      8.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5926,
      "arc_challenge": 0.3464,
      "winogrande": 0.6251,
      "openbookqa": 0.384,
      "boolq": 0.6352,
      "piqa": 0.7465,
      "hellaswag": 0.6345
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      10.0,
      10.0,
      10.0,
      2.0,
      2.0,
      2.0,
      4.0,
      10.0,
      4.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      10.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5871,
      "arc_challenge": 0.3379,
      "winogrande": 0.6227,
      "openbookqa": 0.386,
      "boolq": 0.6373,
      "piqa": 0.747,
      "hellaswag": 0.6341
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      6.0,
      10.0,
      10.0,
      2.0,
      10.0,
      6.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      6.0,
      2.0,
      2.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5859,
      "arc_challenge": 0.3404,
      "winogrande": 0.6219,
      "openbookqa": 0.394,
      "boolq": 0.6324,
      "piqa": 0.7492,
      "hellaswag": 0.6343
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      10.0,
      4.0,
      2.0,
      4.0,
      2.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      2.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      12.0,
      4.0,
      4.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5981,
      "arc_challenge": 0.3302,
      "winogrande": 0.6227,
      "openbookqa": 0.39,
      "boolq": 0.6465,
      "piqa": 0.7519,
      "hellaswag": 0.6363
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      2.0,
      8.0,
      2.0,
      8.0,
      12.0,
      4.0,
      2.0,
      10.0,
      12.0,
      10.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      10.0,
      2.0,
      12.0,
      12.0,
      8.0,
      4.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5825,
      "arc_challenge": 0.3404,
      "winogrande": 0.6298,
      "openbookqa": 0.372,
      "boolq": 0.6621,
      "piqa": 0.7421,
      "hellaswag": 0.6208
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      10.0,
      12.0,
      2.0,
      12.0,
      12.0,
      10.0,
      8.0,
      12.0,
      4.0,
      6.0,
      6.0,
      4.0,
      10.0,
      4.0,
      2.0,
      10.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5976,
      "arc_challenge": 0.3345,
      "winogrande": 0.6259,
      "openbookqa": 0.394,
      "boolq": 0.6443,
      "piqa": 0.7486,
      "hellaswag": 0.6341
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      6.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5699,
      "arc_challenge": 0.3396,
      "winogrande": 0.629,
      "openbookqa": 0.384,
      "boolq": 0.6422,
      "piqa": 0.7437,
      "hellaswag": 0.6241
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      8.0,
      4.0,
      2.0,
      12.0,
      10.0,
      4.0,
      4.0,
      2.0,
      6.0,
      4.0,
      6.0,
      10.0,
      4.0,
      2.0,
      8.0,
      6.0,
      12.0,
      10.0,
      4.0,
      6.0,
      6.0,
      6.0,
      8.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.601,
      "arc_challenge": 0.3362,
      "winogrande": 0.6314,
      "openbookqa": 0.402,
      "boolq": 0.6272,
      "piqa": 0.7437,
      "hellaswag": 0.6361
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      10.0,
      6.0,
      4.0,
      10.0,
      10.0,
      12.0,
      12.0,
      4.0,
      8.0,
      4.0,
      2.0,
      8.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      12.0,
      4.0,
      6.0,
      6.0,
      12.0,
      4.0,
      10.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5741,
      "arc_challenge": 0.3387,
      "winogrande": 0.6314,
      "openbookqa": 0.376,
      "boolq": 0.644,
      "piqa": 0.7421,
      "hellaswag": 0.62
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      2.0,
      6.0,
      12.0,
      6.0,
      12.0,
      10.0,
      6.0,
      4.0,
      8.0,
      8.0,
      12.0,
      2.0,
      2.0,
      6.0,
      8.0,
      4.0,
      12.0,
      12.0,
      2.0,
      4.0,
      2.0,
      6.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5846,
      "arc_challenge": 0.3413,
      "winogrande": 0.6267,
      "openbookqa": 0.394,
      "boolq": 0.6116,
      "piqa": 0.7485,
      "hellaswag": 0.6322
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6141,
      "arc_challenge": 0.3524,
      "winogrande": 0.6361,
      "openbookqa": 0.39,
      "boolq": 0.6569,
      "piqa": 0.7633,
      "hellaswag": 0.6594
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      10.0,
      12.0,
      12.0,
      6.0,
      10.0,
      6.0,
      6.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      12.0,
      12.0,
      6.0,
      4.0,
      10.0,
      6.0,
      2.0,
      2.0,
      8.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6098,
      "arc_challenge": 0.3532,
      "winogrande": 0.6409,
      "openbookqa": 0.394,
      "boolq": 0.6291,
      "piqa": 0.759,
      "hellaswag": 0.6608
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      10.0,
      10.0,
      10.0,
      2.0,
      2.0,
      2.0,
      4.0,
      10.0,
      4.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      10.0,
      2.0,
      2.0,
      10.0,
      10.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6056,
      "arc_challenge": 0.3567,
      "winogrande": 0.6377,
      "openbookqa": 0.392,
      "boolq": 0.6196,
      "piqa": 0.7606,
      "hellaswag": 0.6578
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      10.0,
      4.0,
      2.0,
      4.0,
      2.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      2.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      12.0,
      4.0,
      4.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6111,
      "arc_challenge": 0.3498,
      "winogrande": 0.6354,
      "openbookqa": 0.398,
      "boolq": 0.6297,
      "piqa": 0.759,
      "hellaswag": 0.6579
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      2.0,
      8.0,
      2.0,
      8.0,
      12.0,
      4.0,
      2.0,
      10.0,
      12.0,
      10.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      10.0,
      2.0,
      12.0,
      12.0,
      8.0,
      4.0,
      4.0,
      2.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6077,
      "arc_challenge": 0.3635,
      "winogrande": 0.6093,
      "openbookqa": 0.394,
      "boolq": 0.6743,
      "piqa": 0.7497,
      "hellaswag": 0.6512
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      4.0,
      6.0,
      10.0,
      10.0,
      2.0,
      10.0,
      6.0,
      10.0,
      2.0,
      2.0,
      2.0,
      10.0,
      4.0,
      10.0,
      10.0,
      10.0,
      6.0,
      6.0,
      6.0,
      2.0,
      2.0,
      2.0,
      10.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6086,
      "arc_challenge": 0.3464,
      "winogrande": 0.633,
      "openbookqa": 0.398,
      "boolq": 0.6443,
      "piqa": 0.7584,
      "hellaswag": 0.6607
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      10.0,
      12.0,
      2.0,
      12.0,
      12.0,
      10.0,
      8.0,
      12.0,
      4.0,
      6.0,
      6.0,
      4.0,
      10.0,
      4.0,
      2.0,
      10.0,
      10.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.5976,
      "arc_challenge": 0.3515,
      "winogrande": 0.644,
      "openbookqa": 0.39,
      "boolq": 0.6321,
      "piqa": 0.7573,
      "hellaswag": 0.6593
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      2.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      6.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6002,
      "arc_challenge": 0.3609,
      "winogrande": 0.6164,
      "openbookqa": 0.404,
      "boolq": 0.6719,
      "piqa": 0.7454,
      "hellaswag": 0.6494
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      10.0,
      6.0,
      4.0,
      10.0,
      10.0,
      12.0,
      12.0,
      4.0,
      8.0,
      4.0,
      2.0,
      8.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      12.0,
      4.0,
      6.0,
      6.0,
      12.0,
      4.0,
      10.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6191,
      "arc_challenge": 0.3609,
      "winogrande": 0.6125,
      "openbookqa": 0.388,
      "boolq": 0.6694,
      "piqa": 0.7459,
      "hellaswag": 0.6507
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      6.0,
      8.0,
      4.0,
      2.0,
      12.0,
      10.0,
      4.0,
      4.0,
      2.0,
      6.0,
      4.0,
      6.0,
      10.0,
      4.0,
      2.0,
      8.0,
      6.0,
      12.0,
      10.0,
      4.0,
      6.0,
      6.0,
      6.0,
      8.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6086,
      "arc_challenge": 0.3584,
      "winogrande": 0.6417,
      "openbookqa": 0.394,
      "boolq": 0.6609,
      "piqa": 0.7579,
      "hellaswag": 0.6592
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      10.0,
      6.0,
      4.0,
      10.0,
      10.0,
      12.0,
      12.0,
      4.0,
      8.0,
      4.0,
      2.0,
      8.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      12.0,
      4.0,
      6.0,
      6.0,
      12.0,
      4.0,
      10.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6229,
      "arc_challenge": 0.3695,
      "winogrande": 0.6077,
      "openbookqa": 0.398,
      "boolq": 0.6725,
      "piqa": 0.7476,
      "hellaswag": 0.6499
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      2.0,
      6.0,
      12.0,
      6.0,
      12.0,
      10.0,
      6.0,
      4.0,
      8.0,
      8.0,
      12.0,
      2.0,
      2.0,
      6.0,
      8.0,
      4.0,
      12.0,
      12.0,
      2.0,
      4.0,
      2.0,
      6.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6263,
      "arc_challenge": 0.3677,
      "winogrande": 0.6204,
      "openbookqa": 0.396,
      "boolq": 0.6315,
      "piqa": 0.7595,
      "hellaswag": 0.6597
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      4.0,
      6.0,
      2.0,
      2.0,
      10.0,
      4.0,
      6.0,
      12.0,
      12.0,
      2.0,
      2.0,
      12.0,
      6.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      10.0,
      10.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.6145,
      "arc_challenge": 0.366,
      "winogrande": 0.629,
      "openbookqa": 0.386,
      "boolq": 0.6404,
      "piqa": 0.7579,
      "hellaswag": 0.6597
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.452,
      "arc_challenge": 0.2875,
      "winogrande": 0.5099,
      "openbookqa": 0.346,
      "boolq": 0.4376,
      "piqa": 0.6904,
      "hellaswag": 0.4501
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      10.0,
      12.0,
      12.0,
      6.0,
      10.0,
      6.0,
      6.0,
      8.0,
      2.0,
      2.0,
      12.0,
      2.0,
      12.0,
      12.0,
      6.0,
      4.0,
      10.0,
      6.0,
      2.0,
      2.0,
      8.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4453,
      "arc_challenge": 0.2807,
      "winogrande": 0.5146,
      "openbookqa": 0.352,
      "boolq": 0.4645,
      "piqa": 0.6904,
      "hellaswag": 0.4486
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      2.0,
      12.0,
      6.0,
      10.0,
      2.0,
      2.0,
      6.0,
      2.0,
      6.0,
      12.0,
      2.0,
      2.0,
      4.0,
      8.0,
      6.0,
      2.0,
      12.0,
      4.0,
      2.0,
      2.0,
      2.0,
      10.0,
      6.0,
      4.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4449,
      "arc_challenge": 0.2875,
      "winogrande": 0.5233,
      "openbookqa": 0.35,
      "boolq": 0.4049,
      "piqa": 0.6828,
      "hellaswag": 0.4489
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      6.0,
      8.0,
      4.0,
      12.0,
      4.0,
      2.0,
      2.0,
      10.0,
      10.0,
      10.0,
      8.0,
      4.0,
      4.0,
      2.0,
      12.0,
      10.0,
      12.0,
      2.0,
      6.0,
      6.0,
      4.0,
      2.0,
      8.0,
      2.0,
      4.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4465,
      "arc_challenge": 0.279,
      "winogrande": 0.5272,
      "openbookqa": 0.352,
      "boolq": 0.4566,
      "piqa": 0.6882,
      "hellaswag": 0.4501
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      12.0,
      4.0,
      6.0,
      2.0,
      2.0,
      10.0,
      4.0,
      6.0,
      12.0,
      12.0,
      2.0,
      2.0,
      12.0,
      6.0,
      4.0,
      2.0,
      6.0,
      2.0,
      4.0,
      2.0,
      6.0,
      10.0,
      10.0,
      4.0,
      2.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4566,
      "arc_challenge": 0.2841,
      "winogrande": 0.5193,
      "openbookqa": 0.35,
      "boolq": 0.5165,
      "piqa": 0.6948,
      "hellaswag": 0.4503
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      2.0,
      12.0,
      8.0,
      2.0,
      2.0,
      8.0,
      10.0,
      2.0,
      2.0,
      12.0,
      6.0,
      8.0,
      2.0,
      2.0,
      2.0,
      10.0,
      10.0,
      8.0,
      2.0,
      6.0,
      2.0,
      4.0,
      10.0,
      2.0,
      6.0,
      2.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4478,
      "arc_challenge": 0.279,
      "winogrande": 0.517,
      "openbookqa": 0.354,
      "boolq": 0.4713,
      "piqa": 0.6899,
      "hellaswag": 0.4473
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      6.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      4.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4461,
      "arc_challenge": 0.2807,
      "winogrande": 0.5193,
      "openbookqa": 0.346,
      "boolq": 0.4419,
      "piqa": 0.6899,
      "hellaswag": 0.4489
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8.0,
      8.0,
      8.0,
      8.0,
      4.0,
      12.0,
      12.0,
      12.0,
      12.0,
      10.0,
      8.0,
      10.0,
      6.0,
      2.0,
      8.0,
      6.0,
      8.0,
      2.0,
      8.0,
      2.0,
      8.0,
      10.0,
      12.0,
      12.0,
      10.0,
      4.0,
      4.0,
      6.0,
      2.0,
      12.0,
      8.0,
      8.0
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4428,
      "arc_challenge": 0.2867,
      "winogrande": 0.5178,
      "openbookqa": 0.34,
      "boolq": 0.5034,
      "piqa": 0.6893,
      "hellaswag": 0.451
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      4,
      12,
      2,
      4,
      4,
      6,
      8,
      6,
      4,
      8,
      8,
      8,
      4,
      10,
      8,
      2,
      2,
      2,
      6,
      8,
      12,
      4,
      2,
      12,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6385321100917432,
      "piqa": 0.7595212187159956,
      "hellaswag": 0.659928301135232,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6157407407407407,
      "arc_challenge": 0.3498293515358361,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      2,
      8,
      2,
      12,
      8,
      6,
      2,
      8,
      12,
      4,
      10,
      8,
      8,
      10,
      12,
      8,
      2,
      4,
      10,
      6,
      8,
      4,
      8,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6697247706422018,
      "piqa": 0.7687704026115343,
      "hellaswag": 0.6869149571798446,
      "winogrande": 0.6337805840568271,
      "arc_easy": 0.627104377104377,
      "arc_challenge": 0.3651877133105802,
      "openbookqa": 0.406
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      6,
      2,
      8,
      4,
      2,
      6,
      8,
      8,
      12,
      12,
      4,
      6,
      8,
      8,
      8,
      12,
      8,
      12,
      6,
      10,
      4,
      4,
      8,
      6,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5975535168195719,
      "piqa": 0.6926006528835691,
      "hellaswag": 0.4690300736904999,
      "winogrande": 0.5303867403314917,
      "arc_easy": 0.4688552188552188,
      "arc_challenge": 0.2849829351535836,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      2,
      8,
      8,
      10,
      6,
      6,
      6,
      2,
      4,
      2,
      12,
      2,
      4,
      10,
      10,
      12,
      10,
      8,
      8,
      8,
      4,
      6,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6324159021406728,
      "piqa": 0.7464635473340587,
      "hellaswag": 0.6374228241386178,
      "winogrande": 0.6235201262825573,
      "arc_easy": 0.5867003367003367,
      "arc_challenge": 0.3353242320819112,
      "openbookqa": 0.398
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      6,
      12,
      10,
      2,
      4,
      6,
      2,
      6,
      8,
      2,
      2,
      2,
      12,
      10,
      6,
      4,
      6,
      2,
      8,
      4,
      8,
      12,
      6,
      12,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6009174311926605,
      "piqa": 0.6789989118607181,
      "hellaswag": 0.4441346345349532,
      "winogrande": 0.494869771112865,
      "arc_easy": 0.5,
      "arc_challenge": 0.2798634812286689,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      12,
      2,
      10,
      2,
      12,
      8,
      12,
      2,
      4,
      10,
      10,
      10,
      4,
      12,
      12,
      6,
      10,
      12,
      2,
      6,
      6,
      2,
      2,
      12,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5636085626911315,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.667396932881896,
      "winogrande": 0.632991318074191,
      "arc_easy": 0.6830808080808081,
      "arc_challenge": 0.3805460750853242,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      10,
      2,
      2,
      12,
      12,
      6,
      2,
      4,
      10,
      6,
      12,
      8,
      12,
      6,
      2,
      4,
      4,
      2,
      6,
      2,
      6,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5116207951070336,
      "piqa": 0.7578890097932536,
      "hellaswag": 0.6422027484564827,
      "winogrande": 0.6037884767166535,
      "arc_easy": 0.63510101010101,
      "arc_challenge": 0.3506825938566553,
      "openbookqa": 0.406
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      6,
      8,
      2,
      8,
      12,
      2,
      8,
      6,
      6,
      10,
      8,
      6,
      8,
      4,
      12,
      8,
      6,
      2,
      10,
      6,
      2,
      10,
      8,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6113149847094801,
      "piqa": 0.7480957562568009,
      "hellaswag": 0.6109340768771161,
      "winogrande": 0.5990528808208366,
      "arc_easy": 0.5904882154882155,
      "arc_challenge": 0.3506825938566553,
      "openbookqa": 0.392
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      10,
      10,
      8,
      10,
      10,
      12,
      8,
      12,
      8,
      8,
      12,
      4,
      12,
      8,
      2,
      8,
      6,
      2,
      4,
      2,
      10,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6593272171253822,
      "piqa": 0.7671381936887922,
      "hellaswag": 0.6851224855606453,
      "winogrande": 0.6353591160220995,
      "arc_easy": 0.6325757575757576,
      "arc_challenge": 0.3694539249146757,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      2,
      6,
      12,
      2,
      12,
      12,
      2,
      8,
      8,
      2,
      4,
      4,
      10,
      4,
      12,
      4,
      12,
      4,
      6,
      12,
      12,
      10,
      10,
      4,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6403669724770642,
      "piqa": 0.7578890097932536,
      "hellaswag": 0.660426209918343,
      "winogrande": 0.6353591160220995,
      "arc_easy": 0.6115319865319865,
      "arc_challenge": 0.348976109215017,
      "openbookqa": 0.4
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      8,
      2,
      12,
      12,
      2,
      4,
      4,
      12,
      12,
      10,
      8,
      2,
      2,
      12,
      4,
      2,
      12,
      10,
      8,
      8,
      8,
      6,
      10,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6229357798165137,
      "piqa": 0.7426550598476604,
      "hellaswag": 0.6344353714399522,
      "winogrande": 0.6227308602999211,
      "arc_easy": 0.5913299663299664,
      "arc_challenge": 0.3404436860068259,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      4,
      6,
      2,
      2,
      8,
      8,
      2,
      12,
      10,
      2,
      6,
      4,
      12,
      8,
      2,
      6,
      2,
      12,
      6,
      6,
      4,
      2,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5865443425076453,
      "piqa": 0.6893362350380848,
      "hellaswag": 0.4672376020713005,
      "winogrande": 0.5288082083662194,
      "arc_easy": 0.4595959595959596,
      "arc_challenge": 0.2909556313993174,
      "openbookqa": 0.36
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      6,
      2,
      2,
      4,
      2,
      12,
      2,
      12,
      4,
      4,
      8,
      2,
      10,
      2,
      10,
      8,
      2,
      10,
      8,
      12,
      2,
      4,
      2,
      4,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4920489296636086,
      "piqa": 0.7736670293797606,
      "hellaswag": 0.6702848038239394,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6712962962962963,
      "arc_challenge": 0.3720136518771331,
      "openbookqa": 0.4
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      8,
      12,
      4,
      6,
      6,
      10,
      8,
      2,
      8,
      2,
      12,
      6,
      4,
      12,
      8,
      2,
      2,
      10,
      10,
      8,
      8,
      6,
      12,
      4,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.555045871559633,
      "piqa": 0.7731229597388466,
      "hellaswag": 0.668990240987851,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6708754208754208,
      "arc_challenge": 0.3720136518771331,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      2,
      2,
      4,
      4,
      2,
      12,
      2,
      2,
      6,
      10,
      2,
      6,
      8,
      2,
      6,
      4,
      10,
      4,
      12,
      6,
      12,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5923547400611621,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.6679944234216292,
      "winogrande": 0.6369376479873717,
      "arc_easy": 0.6670875420875421,
      "arc_challenge": 0.378839590443686,
      "openbookqa": 0.404
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      8,
      12,
      4,
      10,
      10,
      10,
      2,
      2,
      4,
      10,
      8,
      8,
      12,
      8,
      4,
      2,
      12,
      6,
      10,
      4,
      10,
      4,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.636697247706422,
      "piqa": 0.7665941240478781,
      "hellaswag": 0.6861183031268672,
      "winogrande": 0.6369376479873717,
      "arc_easy": 0.6342592592592593,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.4
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      4,
      12,
      6,
      12,
      10,
      2,
      8,
      8,
      2,
      6,
      2,
      6,
      4,
      6,
      4,
      10,
      4,
      6,
      12,
      2,
      6,
      12,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6400611620795107,
      "piqa": 0.7709466811751904,
      "hellaswag": 0.6883091017725552,
      "winogrande": 0.6345698500394633,
      "arc_easy": 0.6355218855218855,
      "arc_challenge": 0.3694539249146757,
      "openbookqa": 0.404
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      2,
      10,
      10,
      10,
      12,
      10,
      2,
      4,
      4,
      8,
      12,
      6,
      2,
      8,
      8,
      12,
      2,
      6,
      12,
      6,
      2,
      6,
      12,
      8,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6385321100917432,
      "piqa": 0.7752992383025027,
      "hellaswag": 0.6877116112328221,
      "winogrande": 0.6385161799526441,
      "arc_easy": 0.6346801346801347,
      "arc_challenge": 0.3813993174061433,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      2,
      8,
      2,
      12,
      12,
      12,
      4,
      8,
      4,
      12,
      6,
      2,
      6,
      10,
      6,
      6,
      6,
      12,
      12,
      6,
      12,
      2,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6244648318042814,
      "piqa": 0.7714907508161044,
      "hellaswag": 0.6880103565026887,
      "winogrande": 0.6266771902131019,
      "arc_easy": 0.6355218855218855,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.406
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      2,
      6,
      8,
      8,
      12,
      4,
      2,
      6,
      2,
      2,
      2,
      8,
      2,
      12,
      12,
      8,
      10,
      2,
      12,
      12,
      12,
      12,
      10,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6614678899082569,
      "piqa": 0.7709466811751904,
      "hellaswag": 0.6890061740689106,
      "winogrande": 0.6322020520915549,
      "arc_easy": 0.6321548821548821,
      "arc_challenge": 0.3703071672354949,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      6,
      4,
      6,
      8,
      6,
      2,
      4,
      12,
      8,
      12,
      4,
      10,
      8,
      12,
      4,
      4,
      4,
      2,
      12,
      4,
      6,
      10,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6620795107033639,
      "piqa": 0.7616974972796517,
      "hellaswag": 0.6598287193786099,
      "winogrande": 0.6298342541436464,
      "arc_easy": 0.6106902356902357,
      "arc_challenge": 0.35580204778157,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      10,
      12,
      8,
      10,
      4,
      12,
      8,
      8,
      8,
      12,
      10,
      12,
      6,
      6,
      12,
      6,
      10,
      12,
      12,
      6,
      2,
      8,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6330275229357798,
      "piqa": 0.749727965179543,
      "hellaswag": 0.635929097789285,
      "winogrande": 0.6211523283346487,
      "arc_easy": 0.5913299663299664,
      "arc_challenge": 0.3344709897610921,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      8,
      6,
      2,
      8,
      8,
      12,
      2,
      10,
      6,
      6,
      4,
      4,
      10,
      8,
      10,
      6,
      8,
      10,
      12,
      6,
      4,
      6,
      12,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5954128440366973,
      "piqa": 0.6947769314472253,
      "hellaswag": 0.466938856801434,
      "winogrande": 0.5272296764009471,
      "arc_easy": 0.4566498316498316,
      "arc_challenge": 0.2858361774744027,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      10,
      8,
      12,
      8,
      10,
      12,
      8,
      10,
      8,
      4,
      12,
      4,
      2,
      2,
      8,
      4,
      2,
      10,
      6,
      10,
      10,
      4,
      2,
      2,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5785932721712538,
      "piqa": 0.6974972796517954,
      "hellaswag": 0.4644493128858793,
      "winogrande": 0.5280189423835833,
      "arc_easy": 0.4629629629629629,
      "arc_challenge": 0.2866894197952218,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      10,
      12,
      8,
      6,
      6,
      2,
      6,
      8,
      8,
      10,
      2,
      6,
      4,
      2,
      8,
      2,
      4,
      6,
      4,
      6,
      12,
      12,
      12,
      2,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5929663608562691,
      "piqa": 0.6953210010881393,
      "hellaswag": 0.4655447122087233,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.4617003367003367,
      "arc_challenge": 0.2790102389078498,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      4,
      4,
      2,
      12,
      6,
      6,
      12,
      8,
      8,
      6,
      6,
      6,
      8,
      10,
      8,
      2,
      6,
      10,
      10,
      2,
      8,
      2,
      4,
      8,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.535474006116208,
      "piqa": 0.6942328618063112,
      "hellaswag": 0.4642501493726349,
      "winogrande": 0.5374901341752171,
      "arc_easy": 0.4772727272727273,
      "arc_challenge": 0.2849829351535836,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      12,
      2,
      10,
      6,
      6,
      10,
      10,
      10,
      8,
      6,
      2,
      10,
      12,
      6,
      10,
      4,
      10,
      2,
      8,
      12,
      10,
      12,
      12,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5892966360856269,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.4640509858593906,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4642255892255892,
      "arc_challenge": 0.2883959044368601,
      "openbookqa": 0.36
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      4,
      12,
      2,
      4,
      4,
      6,
      8,
      6,
      4,
      8,
      8,
      8,
      4,
      10,
      8,
      2,
      2,
      2,
      6,
      8,
      12,
      4,
      2,
      12,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6385321100917432,
      "piqa": 0.7595212187159956,
      "hellaswag": 0.659928301135232,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6157407407407407,
      "arc_challenge": 0.3498293515358361,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      2,
      8,
      2,
      12,
      8,
      6,
      2,
      8,
      12,
      4,
      10,
      8,
      8,
      10,
      12,
      8,
      2,
      4,
      10,
      6,
      8,
      4,
      8,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6697247706422018,
      "piqa": 0.7687704026115343,
      "hellaswag": 0.6869149571798446,
      "winogrande": 0.6337805840568271,
      "arc_easy": 0.627104377104377,
      "arc_challenge": 0.3651877133105802,
      "openbookqa": 0.406
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      6,
      2,
      8,
      4,
      2,
      6,
      8,
      8,
      12,
      12,
      4,
      6,
      8,
      8,
      8,
      12,
      8,
      12,
      6,
      10,
      4,
      4,
      8,
      6,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5975535168195719,
      "piqa": 0.6926006528835691,
      "hellaswag": 0.4690300736904999,
      "winogrande": 0.5303867403314917,
      "arc_easy": 0.4688552188552188,
      "arc_challenge": 0.2849829351535836,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      2,
      8,
      8,
      10,
      6,
      6,
      6,
      2,
      4,
      2,
      12,
      2,
      4,
      10,
      10,
      12,
      10,
      8,
      8,
      8,
      4,
      6,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6324159021406728,
      "piqa": 0.7464635473340587,
      "hellaswag": 0.6374228241386178,
      "winogrande": 0.6235201262825573,
      "arc_easy": 0.5867003367003367,
      "arc_challenge": 0.3353242320819112,
      "openbookqa": 0.398
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      6,
      12,
      10,
      2,
      4,
      6,
      2,
      6,
      8,
      2,
      2,
      2,
      12,
      10,
      6,
      4,
      6,
      2,
      8,
      4,
      8,
      12,
      6,
      12,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6009174311926605,
      "piqa": 0.6789989118607181,
      "hellaswag": 0.4441346345349532,
      "winogrande": 0.494869771112865,
      "arc_easy": 0.5,
      "arc_challenge": 0.2798634812286689,
      "openbookqa": 0.346
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      12,
      2,
      10,
      2,
      12,
      8,
      12,
      2,
      4,
      10,
      10,
      10,
      4,
      12,
      12,
      6,
      10,
      12,
      2,
      6,
      6,
      2,
      2,
      12,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5636085626911315,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.667396932881896,
      "winogrande": 0.632991318074191,
      "arc_easy": 0.6830808080808081,
      "arc_challenge": 0.3805460750853242,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      10,
      2,
      2,
      12,
      12,
      6,
      2,
      4,
      10,
      6,
      12,
      8,
      12,
      6,
      2,
      4,
      4,
      2,
      6,
      2,
      6,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5116207951070336,
      "piqa": 0.7578890097932536,
      "hellaswag": 0.6422027484564827,
      "winogrande": 0.6037884767166535,
      "arc_easy": 0.63510101010101,
      "arc_challenge": 0.3506825938566553,
      "openbookqa": 0.406
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      6,
      8,
      2,
      8,
      12,
      2,
      8,
      6,
      6,
      10,
      8,
      6,
      8,
      4,
      12,
      8,
      6,
      2,
      10,
      6,
      2,
      10,
      8,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6113149847094801,
      "piqa": 0.7480957562568009,
      "hellaswag": 0.6109340768771161,
      "winogrande": 0.5990528808208366,
      "arc_easy": 0.5904882154882155,
      "arc_challenge": 0.3506825938566553,
      "openbookqa": 0.392
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      10,
      10,
      8,
      10,
      10,
      12,
      8,
      12,
      8,
      8,
      12,
      4,
      12,
      8,
      2,
      8,
      6,
      2,
      4,
      2,
      10,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6593272171253822,
      "piqa": 0.7671381936887922,
      "hellaswag": 0.6851224855606453,
      "winogrande": 0.6353591160220995,
      "arc_easy": 0.6325757575757576,
      "arc_challenge": 0.3694539249146757,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      2,
      6,
      12,
      2,
      12,
      12,
      2,
      8,
      8,
      2,
      4,
      4,
      10,
      4,
      12,
      4,
      12,
      4,
      6,
      12,
      12,
      10,
      10,
      4,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6403669724770642,
      "piqa": 0.7578890097932536,
      "hellaswag": 0.660426209918343,
      "winogrande": 0.6353591160220995,
      "arc_easy": 0.6115319865319865,
      "arc_challenge": 0.348976109215017,
      "openbookqa": 0.4
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      8,
      2,
      12,
      12,
      2,
      4,
      4,
      12,
      12,
      10,
      8,
      2,
      2,
      12,
      4,
      2,
      12,
      10,
      8,
      8,
      8,
      6,
      10,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6229357798165137,
      "piqa": 0.7426550598476604,
      "hellaswag": 0.6344353714399522,
      "winogrande": 0.6227308602999211,
      "arc_easy": 0.5913299663299664,
      "arc_challenge": 0.3404436860068259,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      4,
      6,
      2,
      2,
      8,
      8,
      2,
      12,
      10,
      2,
      6,
      4,
      12,
      8,
      2,
      6,
      2,
      12,
      6,
      6,
      4,
      2,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5865443425076453,
      "piqa": 0.6893362350380848,
      "hellaswag": 0.4672376020713005,
      "winogrande": 0.5288082083662194,
      "arc_easy": 0.4595959595959596,
      "arc_challenge": 0.2909556313993174,
      "openbookqa": 0.36
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      6,
      2,
      2,
      4,
      2,
      12,
      2,
      12,
      4,
      4,
      8,
      2,
      10,
      2,
      10,
      8,
      2,
      10,
      8,
      12,
      2,
      4,
      2,
      4,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4920489296636086,
      "piqa": 0.7736670293797606,
      "hellaswag": 0.6702848038239394,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6712962962962963,
      "arc_challenge": 0.3720136518771331,
      "openbookqa": 0.4
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      8,
      12,
      4,
      6,
      6,
      10,
      8,
      2,
      8,
      2,
      12,
      6,
      4,
      12,
      8,
      2,
      2,
      10,
      10,
      8,
      8,
      6,
      12,
      4,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.555045871559633,
      "piqa": 0.7731229597388466,
      "hellaswag": 0.668990240987851,
      "winogrande": 0.6377269139700079,
      "arc_easy": 0.6708754208754208,
      "arc_challenge": 0.3720136518771331,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      2,
      2,
      4,
      4,
      2,
      12,
      2,
      2,
      6,
      10,
      2,
      6,
      8,
      2,
      6,
      4,
      10,
      4,
      12,
      6,
      12,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5923547400611621,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.6679944234216292,
      "winogrande": 0.6369376479873717,
      "arc_easy": 0.6670875420875421,
      "arc_challenge": 0.378839590443686,
      "openbookqa": 0.404
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      8,
      12,
      4,
      10,
      10,
      10,
      2,
      2,
      4,
      10,
      8,
      8,
      12,
      8,
      4,
      2,
      12,
      6,
      10,
      4,
      10,
      4,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.636697247706422,
      "piqa": 0.7665941240478781,
      "hellaswag": 0.6861183031268672,
      "winogrande": 0.6369376479873717,
      "arc_easy": 0.6342592592592593,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.4
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      4,
      12,
      6,
      12,
      10,
      2,
      8,
      8,
      2,
      6,
      2,
      6,
      4,
      6,
      4,
      10,
      4,
      6,
      12,
      2,
      6,
      12,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6400611620795107,
      "piqa": 0.7709466811751904,
      "hellaswag": 0.6883091017725552,
      "winogrande": 0.6345698500394633,
      "arc_easy": 0.6355218855218855,
      "arc_challenge": 0.3694539249146757,
      "openbookqa": 0.404
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      2,
      10,
      10,
      10,
      12,
      10,
      2,
      4,
      4,
      8,
      12,
      6,
      2,
      8,
      8,
      12,
      2,
      6,
      12,
      6,
      2,
      6,
      12,
      8,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6385321100917432,
      "piqa": 0.7752992383025027,
      "hellaswag": 0.6877116112328221,
      "winogrande": 0.6385161799526441,
      "arc_easy": 0.6346801346801347,
      "arc_challenge": 0.3813993174061433,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      2,
      8,
      2,
      12,
      12,
      12,
      4,
      8,
      4,
      12,
      6,
      2,
      6,
      10,
      6,
      6,
      6,
      12,
      12,
      6,
      12,
      2,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6244648318042814,
      "piqa": 0.7714907508161044,
      "hellaswag": 0.6880103565026887,
      "winogrande": 0.6266771902131019,
      "arc_easy": 0.6355218855218855,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.406
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      12,
      10,
      6,
      6,
      8,
      12,
      2,
      2,
      10,
      6,
      6,
      2,
      6,
      2,
      2,
      4,
      6,
      4,
      8,
      6,
      8,
      6,
      10,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6076452599388379,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.6877116112328221,
      "winogrande": 0.6227308602999211,
      "arc_easy": 0.6355218855218855,
      "arc_challenge": 0.3720136518771331,
      "openbookqa": 0.4
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      8,
      6,
      12,
      4,
      10,
      6,
      10,
      6,
      2,
      2,
      4,
      4,
      8,
      12,
      4,
      6,
      10,
      10,
      4,
      12,
      6,
      2,
      10,
      6,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6379204892966361,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.6908982274447322,
      "winogrande": 0.6187845303867403,
      "arc_easy": 0.6384680134680135,
      "arc_challenge": 0.3771331058020478,
      "openbookqa": 0.404
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      8,
      8,
      4,
      4,
      6,
      6,
      8,
      8,
      2,
      10,
      2,
      8,
      10,
      8,
      4,
      4,
      12,
      2,
      2,
      6,
      8,
      10,
      10,
      8,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6308868501529052,
      "piqa": 0.7709466811751904,
      "hellaswag": 0.6909978092013543,
      "winogrande": 0.6274664561957379,
      "arc_easy": 0.63510101010101,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.41
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      4,
      4,
      2,
      10,
      6,
      12,
      8,
      10,
      10,
      12,
      4,
      8,
      12,
      4,
      6,
      12,
      8,
      10,
      4,
      10,
      8,
      4,
      12,
      12,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6336391437308868,
      "piqa": 0.7720348204570185,
      "hellaswag": 0.6904999004182434,
      "winogrande": 0.6211523283346487,
      "arc_easy": 0.640993265993266,
      "arc_challenge": 0.3728668941979522,
      "openbookqa": 0.408
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      12,
      6,
      8,
      10,
      12,
      2,
      4,
      8,
      4,
      8,
      12,
      8,
      6,
      10,
      8,
      8,
      10,
      10,
      2,
      10,
      4,
      4,
      8,
      12,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5837920489296636,
      "piqa": 0.7714907508161044,
      "hellaswag": 0.6655048795060745,
      "winogrande": 0.6306235201262825,
      "arc_easy": 0.6607744107744108,
      "arc_challenge": 0.371160409556314,
      "openbookqa": 0.416
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      12,
      4,
      4,
      4,
      4,
      12,
      8,
      4,
      4,
      8,
      12,
      2,
      4,
      2,
      6,
      10,
      6,
      2,
      4,
      10,
      4,
      2,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5474006116207951,
      "piqa": 0.7714907508161044,
      "hellaswag": 0.6677952599083847,
      "winogrande": 0.6385161799526441,
      "arc_easy": 0.6641414141414141,
      "arc_challenge": 0.3754266211604095,
      "openbookqa": 0.406
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      12,
      6,
      4,
      8,
      2,
      12,
      6,
      2,
      10,
      10,
      6,
      4,
      10,
      8,
      10,
      8,
      4,
      2,
      4,
      4,
      6,
      8,
      8,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5795107033639144,
      "piqa": 0.7742110990206746,
      "hellaswag": 0.6681935869348735,
      "winogrande": 0.6298342541436464,
      "arc_easy": 0.6637205387205387,
      "arc_challenge": 0.3771331058020478,
      "openbookqa": 0.408
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      12,
      2,
      2,
      4,
      8,
      8,
      8,
      2,
      2,
      4,
      8,
      12,
      4,
      10,
      12,
      12,
      4,
      2,
      2,
      4,
      6,
      12,
      8,
      6,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5923547400611621,
      "piqa": 0.7704026115342764,
      "hellaswag": 0.6683927504481179,
      "winogrande": 0.632991318074191,
      "arc_easy": 0.6620370370370371,
      "arc_challenge": 0.3677474402730375,
      "openbookqa": 0.412
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      8,
      4,
      8,
      2,
      10,
      6,
      4,
      6,
      4,
      2,
      12,
      6,
      12,
      2,
      6,
      2,
      4,
      6,
      4,
      8,
      12,
      12,
      2,
      4,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6345565749235474,
      "piqa": 0.7546245919477693,
      "hellaswag": 0.6608245369448317,
      "winogrande": 0.6077348066298343,
      "arc_easy": 0.6098484848484849,
      "arc_challenge": 0.3583617747440273,
      "openbookqa": 0.386
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      10,
      6,
      10,
      2,
      2,
      6,
      12,
      12,
      12,
      6,
      4,
      8,
      8,
      2,
      8,
      2,
      6,
      4,
      4,
      6,
      6,
      2,
      4,
      12,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6204892966360857,
      "piqa": 0.750272034820457,
      "hellaswag": 0.6309500099581756,
      "winogrande": 0.6235201262825573,
      "arc_easy": 0.6026936026936027,
      "arc_challenge": 0.3404436860068259,
      "openbookqa": 0.392
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      6,
      12,
      2,
      4,
      6,
      8,
      10,
      12,
      2,
      6,
      2,
      2,
      12,
      2,
      2,
      8,
      4,
      10,
      6,
      8,
      12,
      4,
      12,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4886850152905199,
      "piqa": 0.6849836779107725,
      "hellaswag": 0.4526986656044612,
      "winogrande": 0.5240726124704025,
      "arc_easy": 0.4566498316498316,
      "arc_challenge": 0.2866894197952218,
      "openbookqa": 0.356
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      8,
      6,
      4,
      10,
      10,
      10,
      2,
      10,
      10,
      4,
      10,
      4,
      8,
      8,
      10,
      12,
      4,
      12,
      4,
      8,
      10,
      12,
      10,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5807339449541284,
      "piqa": 0.7720348204570185,
      "hellaswag": 0.6674965146385182,
      "winogrande": 0.6322020520915549,
      "arc_easy": 0.67003367003367,
      "arc_challenge": 0.3737201365187713,
      "openbookqa": 0.41
    }
  },
  {
    "name": "vicuna-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      6,
      12,
      12,
      8,
      2,
      12,
      4,
      2,
      6,
      10,
      12,
      8,
      6,
      2,
      12,
      4,
      8,
      10,
      4,
      4,
      12,
      10,
      2,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5859327217125382,
      "piqa": 0.7720348204570185,
      "hellaswag": 0.6696873132842064,
      "winogrande": 0.6274664561957379,
      "arc_easy": 0.648989898989899,
      "arc_challenge": 0.3668941979522184,
      "openbookqa": 0.41
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      2,
      4,
      8,
      2,
      2,
      12,
      8,
      2,
      8,
      6,
      4,
      12,
      10,
      4,
      4,
      8,
      4,
      8,
      8,
      6,
      10,
      8,
      10,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6045871559633027,
      "piqa": 0.7584330794341676,
      "hellaswag": 0.6598287193786099,
      "winogrande": 0.6045777426992897,
      "arc_easy": 0.6111111111111112,
      "arc_challenge": 0.3643344709897611,
      "openbookqa": 0.39
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      4,
      12,
      4,
      2,
      6,
      10,
      6,
      10,
      2,
      10,
      10,
      6,
      12,
      2,
      4,
      2,
      6,
      10,
      4,
      6,
      10,
      10,
      8,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6266055045871559,
      "piqa": 0.7584330794341676,
      "hellaswag": 0.6605257916749652,
      "winogrande": 0.6156274664561957,
      "arc_easy": 0.6153198653198653,
      "arc_challenge": 0.3668941979522184,
      "openbookqa": 0.39
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      4,
      12,
      2,
      12,
      2,
      2,
      10,
      10,
      2,
      10,
      8,
      2,
      4,
      6,
      4,
      6,
      12,
      10,
      6,
      8,
      10,
      2,
      6,
      6,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5990825688073395,
      "piqa": 0.7557127312295974,
      "hellaswag": 0.6591316470822546,
      "winogrande": 0.6156274664561957,
      "arc_easy": 0.6081649831649831,
      "arc_challenge": 0.3609215017064846,
      "openbookqa": 0.386
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      6,
      6,
      12,
      10,
      10,
      12,
      2,
      10,
      8,
      8,
      2,
      2,
      4,
      4,
      10,
      12,
      2,
      10,
      12,
      6,
      4,
      2,
      10,
      10,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6330275229357798,
      "piqa": 0.7562568008705114,
      "hellaswag": 0.6592312288388767,
      "winogrande": 0.6108918705603789,
      "arc_easy": 0.6064814814814815,
      "arc_challenge": 0.3617747440273037,
      "openbookqa": 0.39
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      4,
      4,
      4,
      2,
      2,
      10,
      4,
      12,
      2,
      10,
      2,
      4,
      10,
      6,
      8,
      6,
      4,
      12,
      8,
      2,
      4,
      4,
      10,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6073394495412844,
      "piqa": 0.7540805223068553,
      "hellaswag": 0.6603266281617207,
      "winogrande": 0.6101026045777427,
      "arc_easy": 0.6237373737373737,
      "arc_challenge": 0.3609215017064846,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      6,
      8,
      10,
      2,
      2,
      4,
      10,
      6,
      12,
      2,
      10,
      2,
      6,
      8,
      10,
      2,
      6,
      6,
      10,
      4,
      12,
      12,
      2,
      12,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6296636085626911,
      "piqa": 0.7568008705114254,
      "hellaswag": 0.6605257916749652,
      "winogrande": 0.6148382004735596,
      "arc_easy": 0.6245791245791246,
      "arc_challenge": 0.3626279863481229,
      "openbookqa": 0.388
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      8,
      8,
      4,
      10,
      6,
      12,
      8,
      8,
      10,
      12,
      10,
      2,
      4,
      6,
      4,
      8,
      2,
      6,
      2,
      12,
      12,
      12,
      6,
      8,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6204892966360857,
      "piqa": 0.7595212187159956,
      "hellaswag": 0.6586337382991436,
      "winogrande": 0.6132596685082873,
      "arc_easy": 0.6191077441077442,
      "arc_challenge": 0.3575085324232082,
      "openbookqa": 0.386
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      12,
      10,
      4,
      4,
      4,
      12,
      4,
      6,
      6,
      8,
      10,
      8,
      6,
      8,
      2,
      8,
      2,
      2,
      8,
      6,
      12,
      2,
      2,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4788990825688073,
      "piqa": 0.7513601741022851,
      "hellaswag": 0.6411073491336388,
      "winogrande": 0.6108918705603789,
      "arc_easy": 0.6275252525252525,
      "arc_challenge": 0.35580204778157,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      8,
      10,
      4,
      4,
      6,
      12,
      8,
      12,
      12,
      10,
      12,
      12,
      10,
      6,
      10,
      8,
      10,
      4,
      6,
      2,
      8,
      4,
      8,
      2,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4935779816513762,
      "piqa": 0.7529923830250272,
      "hellaswag": 0.6438956383190599,
      "winogrande": 0.611681136543015,
      "arc_easy": 0.6334175084175084,
      "arc_challenge": 0.3498293515358361,
      "openbookqa": 0.4
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      10,
      4,
      2,
      6,
      6,
      4,
      12,
      4,
      10,
      4,
      12,
      8,
      4,
      6,
      6,
      12,
      2,
      8,
      10,
      4,
      8,
      2,
      12,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5510703363914373,
      "piqa": 0.7551686615886833,
      "hellaswag": 0.6410077673770165,
      "winogrande": 0.6077348066298343,
      "arc_easy": 0.6279461279461279,
      "arc_challenge": 0.3600682593856655,
      "openbookqa": 0.4
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      6,
      8,
      2,
      8,
      12,
      6,
      10,
      4,
      12,
      2,
      2,
      8,
      8,
      2,
      12,
      8,
      8,
      12,
      10,
      12,
      2,
      4,
      4,
      2,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4807339449541284,
      "piqa": 0.7557127312295974,
      "hellaswag": 0.6426010754829715,
      "winogrande": 0.5998421468034728,
      "arc_easy": 0.6262626262626263,
      "arc_challenge": 0.3549488054607508,
      "openbookqa": 0.398
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      12,
      10,
      6,
      2,
      6,
      12,
      8,
      6,
      12,
      2,
      4,
      12,
      4,
      12,
      2,
      8,
      12,
      2,
      2,
      12,
      2,
      12,
      4,
      4,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5507645259938838,
      "piqa": 0.7529923830250272,
      "hellaswag": 0.6446922923720374,
      "winogrande": 0.6069455406471981,
      "arc_easy": 0.6300505050505051,
      "arc_challenge": 0.3583617747440273,
      "openbookqa": 0.408
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      4,
      4,
      6,
      4,
      12,
      4,
      10,
      4,
      12,
      10,
      4,
      10,
      6,
      4,
      6,
      10,
      4,
      12,
      10,
      12,
      2,
      4,
      12,
      10,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5290519877675841,
      "piqa": 0.7546245919477693,
      "hellaswag": 0.6384186417048396,
      "winogrande": 0.6053670086819258,
      "arc_easy": 0.6346801346801347,
      "arc_challenge": 0.3523890784982935,
      "openbookqa": 0.406
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      2,
      10,
      8,
      8,
      8,
      4,
      6,
      2,
      12,
      12,
      12,
      4,
      2,
      12,
      6,
      12,
      2,
      8,
      6,
      6,
      8,
      4,
      2,
      8,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5314984709480123,
      "piqa": 0.7529923830250272,
      "hellaswag": 0.6422027484564827,
      "winogrande": 0.611681136543015,
      "arc_easy": 0.6338383838383839,
      "arc_challenge": 0.356655290102389,
      "openbookqa": 0.406
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      2,
      12,
      6,
      6,
      10,
      12,
      10,
      6,
      8,
      2,
      6,
      10,
      12,
      2,
      2,
      10,
      6,
      2,
      2,
      2,
      4,
      8,
      10,
      8,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5400611620795107,
      "piqa": 0.7524483133841132,
      "hellaswag": 0.6374228241386178,
      "winogrande": 0.611681136543015,
      "arc_easy": 0.6334175084175084,
      "arc_challenge": 0.3549488054607508,
      "openbookqa": 0.408
    }
  },
  {
    "name": "vicuna-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      6,
      2,
      6,
      4,
      4,
      6,
      8,
      8,
      2,
      8,
      6,
      12,
      12,
      6,
      12,
      8,
      2,
      8,
      12,
      12,
      10,
      2,
      8,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5388379204892967,
      "piqa": 0.7540805223068553,
      "hellaswag": 0.642302330213105,
      "winogrande": 0.6006314127861089,
      "arc_easy": 0.6287878787878788,
      "arc_challenge": 0.3583617747440273,
      "openbookqa": 0.402
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      10,
      10,
      8,
      4,
      10,
      10,
      12,
      6,
      10,
      6,
      10,
      6,
      4,
      2,
      8,
      6,
      10,
      8,
      12,
      4,
      2,
      12,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5492354740061162,
      "piqa": 0.7540805223068553,
      "hellaswag": 0.6063533160724955,
      "winogrande": 0.6029992107340174,
      "arc_easy": 0.5925925925925926,
      "arc_challenge": 0.3430034129692833,
      "openbookqa": 0.382
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      6,
      8,
      4,
      6,
      10,
      4,
      4,
      12,
      8,
      10,
      4,
      10,
      6,
      8,
      6,
      10,
      4,
      6,
      8,
      10,
      4,
      4,
      8,
      6,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5703363914373089,
      "piqa": 0.7551686615886833,
      "hellaswag": 0.6070503883688508,
      "winogrande": 0.5951065509076559,
      "arc_easy": 0.5989057239057239,
      "arc_challenge": 0.3438566552901024,
      "openbookqa": 0.392
    }
  },
  {
    "name": "llama-7b_0.20",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      2,
      6,
      8,
      8,
      12,
      4,
      2,
      6,
      2,
      2,
      2,
      8,
      2,
      12,
      12,
      8,
      10,
      2,
      12,
      12,
      12,
      12,
      10,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6614678899082569,
      "piqa": 0.7709466811751904,
      "hellaswag": 0.6890061740689106,
      "winogrande": 0.6322020520915549,
      "arc_easy": 0.6321548821548821,
      "arc_challenge": 0.3703071672354949,
      "openbookqa": 0.394
    }
  },
  {
    "name": "llama-7b_0.25",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      6,
      4,
      6,
      8,
      6,
      2,
      4,
      12,
      8,
      12,
      4,
      10,
      8,
      12,
      4,
      4,
      4,
      2,
      12,
      4,
      6,
      10,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6620795107033639,
      "piqa": 0.7616974972796517,
      "hellaswag": 0.6598287193786099,
      "winogrande": 0.6298342541436464,
      "arc_easy": 0.6106902356902357,
      "arc_challenge": 0.35580204778157,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      10,
      12,
      8,
      10,
      4,
      12,
      8,
      8,
      8,
      12,
      10,
      12,
      6,
      6,
      12,
      6,
      10,
      12,
      12,
      6,
      2,
      8,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6330275229357798,
      "piqa": 0.749727965179543,
      "hellaswag": 0.635929097789285,
      "winogrande": 0.6211523283346487,
      "arc_easy": 0.5913299663299664,
      "arc_challenge": 0.3344709897610921,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      12,
      8,
      6,
      2,
      8,
      8,
      12,
      2,
      10,
      6,
      6,
      4,
      4,
      10,
      8,
      10,
      6,
      8,
      10,
      12,
      6,
      4,
      6,
      12,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5954128440366973,
      "piqa": 0.6947769314472253,
      "hellaswag": 0.466938856801434,
      "winogrande": 0.5272296764009471,
      "arc_easy": 0.4566498316498316,
      "arc_challenge": 0.2858361774744027,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      10,
      8,
      12,
      8,
      10,
      12,
      8,
      10,
      8,
      4,
      12,
      4,
      2,
      2,
      8,
      4,
      2,
      10,
      6,
      10,
      10,
      4,
      2,
      2,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5785932721712538,
      "piqa": 0.6974972796517954,
      "hellaswag": 0.4644493128858793,
      "winogrande": 0.5280189423835833,
      "arc_easy": 0.4629629629629629,
      "arc_challenge": 0.2866894197952218,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      10,
      12,
      8,
      6,
      6,
      2,
      6,
      8,
      8,
      10,
      2,
      6,
      4,
      2,
      8,
      2,
      4,
      6,
      4,
      6,
      12,
      12,
      12,
      2,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5929663608562691,
      "piqa": 0.6953210010881393,
      "hellaswag": 0.4655447122087233,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.4617003367003367,
      "arc_challenge": 0.2790102389078498,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      4,
      4,
      2,
      12,
      6,
      6,
      12,
      8,
      8,
      6,
      6,
      6,
      8,
      10,
      8,
      2,
      6,
      10,
      10,
      2,
      8,
      2,
      4,
      8,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.535474006116208,
      "piqa": 0.6942328618063112,
      "hellaswag": 0.4642501493726349,
      "winogrande": 0.5374901341752171,
      "arc_easy": 0.4772727272727273,
      "arc_challenge": 0.2849829351535836,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      12,
      2,
      10,
      6,
      6,
      10,
      10,
      10,
      8,
      6,
      2,
      10,
      12,
      6,
      10,
      4,
      10,
      2,
      8,
      12,
      10,
      12,
      12,
      8,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5892966360856269,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.4640509858593906,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4642255892255892,
      "arc_challenge": 0.2883959044368601,
      "openbookqa": 0.36
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      8,
      4,
      4,
      2,
      10,
      6,
      10,
      10,
      12,
      10,
      12,
      2,
      2,
      8,
      4,
      10,
      2,
      2,
      4,
      2,
      10,
      10,
      4,
      10,
      8,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4406727828746177,
      "piqa": 0.6877040261153428,
      "hellaswag": 0.4535949014140609,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.4562289562289562,
      "arc_challenge": 0.2858361774744027,
      "openbookqa": 0.352
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      12,
      12,
      6,
      8,
      8,
      4,
      2,
      6,
      4,
      6,
      12,
      2,
      2,
      6,
      10,
      6,
      12,
      4,
      10,
      10,
      4,
      6,
      6,
      12,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4758409785932722,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.4563831905994822,
      "winogrande": 0.5138121546961326,
      "arc_easy": 0.4604377104377104,
      "arc_challenge": 0.2901023890784983,
      "openbookqa": 0.358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      10,
      2,
      2,
      2,
      12,
      2,
      10,
      2,
      8,
      2,
      10,
      6,
      4,
      10,
      4,
      10,
      6,
      8,
      2,
      6,
      10,
      8,
      10,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4532110091743119,
      "piqa": 0.6926006528835691,
      "hellaswag": 0.4558852818163712,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.4612794612794613,
      "arc_challenge": 0.2773037542662116,
      "openbookqa": 0.354
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      6,
      6,
      2,
      10,
      4,
      8,
      2,
      10,
      10,
      12,
      2,
      10,
      12,
      12,
      6,
      10,
      2,
      12,
      10,
      10,
      4,
      10,
      4,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4709480122324159,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.4566819358693487,
      "winogrande": 0.505130228887135,
      "arc_easy": 0.4562289562289562,
      "arc_challenge": 0.2866894197952218,
      "openbookqa": 0.36
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      8,
      2,
      10,
      6,
      4,
      4,
      4,
      12,
      2,
      6,
      4,
      6,
      10,
      12,
      8,
      12,
      2,
      4,
      2,
      6,
      8,
      6,
      12,
      4,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5981651376146789,
      "piqa": 0.6719260065288357,
      "hellaswag": 0.4378609838677554,
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.4882154882154882,
      "arc_challenge": 0.273037542662116,
      "openbookqa": 0.352
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      10,
      12,
      10,
      12,
      12,
      2,
      6,
      6,
      6,
      8,
      4,
      8,
      4,
      2,
      6,
      6,
      2,
      12,
      12,
      12,
      4,
      10,
      2,
      8,
      6,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6085626911314985,
      "piqa": 0.6779107725788901,
      "hellaswag": 0.437661820354511,
      "winogrande": 0.5098658247829518,
      "arc_easy": 0.4873737373737373,
      "arc_challenge": 0.2738907849829352,
      "openbookqa": 0.348
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      4,
      8,
      2,
      12,
      10,
      12,
      6,
      10,
      10,
      10,
      10,
      10,
      12,
      4,
      12,
      6,
      8,
      10,
      12,
      2,
      10,
      4,
      4,
      8,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6036697247706422,
      "piqa": 0.6784548422198041,
      "hellaswag": 0.4369647480581557,
      "winogrande": 0.5130228887134964,
      "arc_easy": 0.4873737373737373,
      "arc_challenge": 0.2773037542662116,
      "openbookqa": 0.344
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      4,
      8,
      8,
      8,
      2,
      4,
      8,
      6,
      12,
      6,
      2,
      12,
      12,
      10,
      2,
      12,
      8,
      10,
      4,
      10,
      10,
      12,
      12,
      10,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5969418960244648,
      "piqa": 0.676278563656148,
      "hellaswag": 0.4394542919737104,
      "winogrande": 0.5035516969218626,
      "arc_easy": 0.4882154882154882,
      "arc_challenge": 0.2773037542662116,
      "openbookqa": 0.356
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      2,
      8,
      12,
      8,
      12,
      4,
      6,
      4,
      6,
      8,
      10,
      6,
      2,
      6,
      4,
      2,
      8,
      12,
      8,
      4,
      8,
      4,
      12,
      10,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5932721712538226,
      "piqa": 0.749183895538629,
      "hellaswag": 0.630551682931687,
      "winogrande": 0.6195737963693765,
      "arc_easy": 0.6014309764309764,
      "arc_challenge": 0.3387372013651877,
      "openbookqa": 0.39
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      2,
      6,
      10,
      12,
      2,
      10,
      8,
      8,
      2,
      8,
      2,
      4,
      4,
      6,
      12,
      12,
      4,
      10,
      12,
      4,
      8,
      6,
      4,
      12,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6152905198776758,
      "piqa": 0.7486398258977149,
      "hellaswag": 0.6283608842859988,
      "winogrande": 0.6156274664561957,
      "arc_easy": 0.5942760942760943,
      "arc_challenge": 0.3421501706484641,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      8,
      10,
      4,
      8,
      10,
      12,
      6,
      12,
      8,
      12,
      2,
      2,
      8,
      4,
      6,
      8,
      12,
      8,
      4,
      8,
      10,
      10,
      8,
      2,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6217125382262997,
      "piqa": 0.749183895538629,
      "hellaswag": 0.6307508464449313,
      "winogrande": 0.6211523283346487,
      "arc_easy": 0.5993265993265994,
      "arc_challenge": 0.3438566552901024,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      12,
      10,
      8,
      4,
      8,
      2,
      4,
      2,
      6,
      6,
      12,
      8,
      8,
      2,
      8,
      4,
      8,
      4,
      12,
      2,
      4,
      10,
      6,
      8,
      2,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6155963302752293,
      "piqa": 0.749183895538629,
      "hellaswag": 0.6299541923919538,
      "winogrande": 0.6227308602999211,
      "arc_easy": 0.5951178451178452,
      "arc_challenge": 0.333617747440273,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      4,
      4,
      4,
      12,
      10,
      12,
      12,
      10,
      2,
      12,
      4,
      6,
      2,
      10,
      8,
      8,
      4,
      8,
      12,
      4,
      10,
      4,
      10,
      10,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6229357798165137,
      "piqa": 0.749727965179543,
      "hellaswag": 0.628460466042621,
      "winogrande": 0.6250986582478295,
      "arc_easy": 0.5963804713804713,
      "arc_challenge": 0.3438566552901024,
      "openbookqa": 0.398
    }
  },
  {
    "name": "llama-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      8,
      4,
      10,
      4,
      6,
      6,
      2,
      8,
      2,
      2,
      8,
      4,
      10,
      4,
      6,
      6,
      12,
      2,
      8,
      12,
      8,
      10,
      4,
      6,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5853211009174312,
      "piqa": 0.7470076169749728,
      "hellaswag": 0.628460466042621,
      "winogrande": 0.6172059984214681,
      "arc_easy": 0.5946969696969697,
      "arc_challenge": 0.3421501706484641,
      "openbookqa": 0.394
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      8,
      4,
      12,
      12,
      10,
      8,
      8,
      2,
      10,
      6,
      6,
      6,
      2,
      8,
      10,
      12,
      8,
      12,
      12,
      10,
      4,
      6,
      2,
      12,
      12,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5131498470948013,
      "piqa": 0.7524483133841132,
      "hellaswag": 0.6080462059350727,
      "winogrande": 0.585635359116022,
      "arc_easy": 0.5963804713804713,
      "arc_challenge": 0.3481228668941979,
      "openbookqa": 0.392
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      6,
      12,
      6,
      2,
      10,
      12,
      12,
      10,
      6,
      6,
      12,
      6,
      2,
      6,
      6,
      12,
      12,
      2,
      10,
      8,
      6,
      4,
      4,
      6,
      6,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5779816513761468,
      "piqa": 0.7513601741022851,
      "hellaswag": 0.6063533160724955,
      "winogrande": 0.6045777426992897,
      "arc_easy": 0.5972222222222222,
      "arc_challenge": 0.3370307167235495,
      "openbookqa": 0.382
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      8,
      8,
      12,
      8,
      6,
      10,
      8,
      6,
      8,
      10,
      2,
      10,
      8,
      8,
      6,
      12,
      10,
      4,
      12,
      2,
      10,
      8,
      8,
      10,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5510703363914373,
      "piqa": 0.7519042437431991,
      "hellaswag": 0.6074487153953396,
      "winogrande": 0.5951065509076559,
      "arc_easy": 0.6018518518518519,
      "arc_challenge": 0.3447098976109215,
      "openbookqa": 0.386
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      12,
      12,
      4,
      12,
      6,
      10,
      4,
      10,
      12,
      2,
      12,
      4,
      10,
      12,
      12,
      12,
      12,
      12,
      2,
      10,
      12,
      4,
      10,
      12,
      10,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5660550458715596,
      "piqa": 0.7546245919477693,
      "hellaswag": 0.6060545708026289,
      "winogrande": 0.6022099447513812,
      "arc_easy": 0.5921717171717171,
      "arc_challenge": 0.3464163822525597,
      "openbookqa": 0.376
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      6,
      8,
      4,
      2,
      12,
      2,
      4,
      12,
      8,
      8,
      10,
      10,
      6,
      10,
      10,
      12,
      8,
      12,
      2,
      12,
      10,
      6,
      10,
      6,
      2,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.536697247706422,
      "piqa": 0.749727965179543,
      "hellaswag": 0.6019717187811193,
      "winogrande": 0.5990528808208366,
      "arc_easy": 0.601010101010101,
      "arc_challenge": 0.3447098976109215,
      "openbookqa": 0.382
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      4,
      8,
      8,
      12,
      2,
      8,
      6,
      10,
      2,
      8,
      6,
      12,
      10,
      4,
      2,
      4,
      8,
      8,
      10,
      10,
      4,
      2,
      2,
      4,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5828746177370031,
      "piqa": 0.7557127312295974,
      "hellaswag": 0.6061541525592511,
      "winogrande": 0.601420678768745,
      "arc_easy": 0.5837542087542088,
      "arc_challenge": 0.3395904436860068,
      "openbookqa": 0.382
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      10,
      8,
      12,
      6,
      12,
      2,
      6,
      10,
      12,
      2,
      8,
      10,
      4,
      2,
      2,
      2,
      2,
      12,
      8,
      8,
      4,
      10,
      4,
      6,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5688073394495413,
      "piqa": 0.7529923830250272,
      "hellaswag": 0.6089424417446724,
      "winogrande": 0.6022099447513812,
      "arc_easy": 0.5913299663299664,
      "arc_challenge": 0.3472696245733788,
      "openbookqa": 0.378
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      2,
      2,
      10,
      2,
      6,
      12,
      4,
      10,
      6,
      8,
      10,
      10,
      8,
      12,
      4,
      10,
      2,
      2,
      6,
      2,
      12,
      10,
      2,
      8,
      4,
      4,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5963302752293578,
      "piqa": 0.7486398258977149,
      "hellaswag": 0.6073491336387173,
      "winogrande": 0.5966850828729282,
      "arc_easy": 0.5955387205387206,
      "arc_challenge": 0.3464163822525597,
      "openbookqa": 0.384
    }
  },
  {
    "name": "vicuna-7b_0.30",
    "rank_list": [
      8,
      8,
      8,
      8,
      4,
      8,
      10,
      10,
      12,
      8,
      8,
      10,
      6,
      10,
      4,
      6,
      2,
      12,
      10,
      2,
      6,
      6,
      2,
      2,
      8,
      8,
      8,
      10,
      2,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0,
      0
    ],
    "performance": {
      "boolq": 0.535474006116208,
      "piqa": 0.7529923830250272,
      "hellaswag": 0.6081457876916949,
      "winogrande": 0.595895816890292,
      "arc_easy": 0.5917508417508418,
      "arc_challenge": 0.3387372013651877,
      "openbookqa": 0.396
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      8,
      2,
      4,
      6,
      2,
      2,
      12,
      10,
      8,
      16,
      14,
      6,
      2,
      16,
      2,
      12,
      10,
      2,
      10,
      4,
      16,
      10,
      12,
      8,
      8,
      16,
      8,
      10,
      12,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6849836779107725,
      "openbookqa": 0.226,
      "boolq": 0.43363914373088686,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.3724357697669787,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.25341296928327645
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      16,
      16,
      16,
      4,
      10,
      2,
      6,
      16,
      10,
      14,
      4,
      8,
      10,
      8,
      14,
      2,
      8,
      8,
      4,
      4,
      14,
      6,
      6,
      6,
      14,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.35789683330013944,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.234,
      "piqa": 0.6773667029379761,
      "boolq": 0.599388379204893
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      2,
      4,
      16,
      6,
      14,
      6,
      10,
      6,
      6,
      8,
      10,
      14,
      2,
      10,
      14,
      6,
      16,
      6,
      16,
      2,
      10,
      2,
      6,
      4,
      6,
      12,
      8,
      14,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3714399522007568,
      "piqa": 0.6877040261153428,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.226,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.44770642201834865,
      "arc_challenge": 0.2551194539249147
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      6,
      12,
      2,
      6,
      4,
      4,
      2,
      4,
      2,
      12,
      6,
      4,
      16,
      8,
      14,
      16,
      10,
      8,
      16,
      16,
      10,
      16,
      8,
      14,
      16,
      8,
      12,
      6,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37064329814777935,
      "boolq": 0.43333333333333335,
      "openbookqa": 0.228,
      "arc_easy": 0.43813131313131315,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5272296764009471
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      6,
      12,
      2,
      4,
      2,
      10,
      14,
      4,
      12,
      6,
      8,
      16,
      6,
      14,
      14,
      4,
      2,
      12,
      16,
      16,
      6,
      6,
      14,
      8,
      6,
      10,
      14,
      6,
      16,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.359788886675961,
      "piqa": 0.6735582154515778,
      "openbookqa": 0.228,
      "boolq": 0.5663608562691131
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      2,
      14,
      6,
      4,
      16,
      2,
      2,
      4,
      8,
      10,
      12,
      12,
      6,
      4,
      6,
      10,
      4,
      6,
      14,
      2,
      2,
      6,
      16,
      12,
      16,
      2,
      12,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6746463547334058,
      "boolq": 0.5697247706422018,
      "arc_easy": 0.4793771043771044,
      "winogrande": 0.5256511444356748,
      "hellaswag": 0.35968930491933876,
      "arc_challenge": 0.2551194539249147,
      "openbookqa": 0.236
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      2,
      6,
      10,
      4,
      16,
      14,
      4,
      16,
      16,
      10,
      10,
      12,
      4,
      14,
      10,
      2,
      12,
      6,
      4,
      6,
      2,
      10,
      8,
      10,
      10,
      12,
      10,
      6,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.41345565749235474,
      "hellaswag": 0.3724357697669787,
      "openbookqa": 0.216,
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2525597269624573
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      4,
      2,
      12,
      4,
      16,
      12,
      6,
      16,
      4,
      14,
      2,
      16,
      6,
      6,
      8,
      10,
      16,
      10,
      6,
      8,
      16,
      2,
      10,
      6,
      8,
      12,
      6,
      8,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6724700761697497,
      "hellaswag": 0.35769766978689504,
      "boolq": 0.5825688073394495,
      "arc_easy": 0.48653198653198654,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      16,
      14,
      16,
      4,
      2,
      14,
      8,
      14,
      2,
      4,
      8,
      12,
      2,
      2,
      12,
      10,
      4,
      10,
      8,
      14,
      14,
      10,
      12,
      14,
      6,
      8,
      14,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.591131498470948,
      "hellaswag": 0.360884285998805,
      "arc_challenge": 0.24744027303754265,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6692056583242655,
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.234
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      16,
      8,
      8,
      6,
      12,
      14,
      16,
      2,
      16,
      10,
      14,
      8,
      10,
      10,
      4,
      16,
      4,
      6,
      4,
      6,
      6,
      2,
      14,
      14,
      10,
      10,
      14,
      16,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35879306910973907,
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5098658247829518,
      "boolq": 0.5715596330275229,
      "arc_easy": 0.48695286195286197,
      "openbookqa": 0.232
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      6,
      6,
      12,
      4,
      8,
      12,
      4,
      2,
      16,
      12,
      12,
      2,
      8,
      8,
      16,
      14,
      4,
      8,
      6,
      16,
      12,
      12,
      6,
      6,
      8,
      14,
      14,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36078470424218284,
      "arc_challenge": 0.24658703071672355,
      "openbookqa": 0.222,
      "piqa": 0.6719260065288357,
      "winogrande": 0.516179952644041,
      "boolq": 0.5770642201834862,
      "arc_easy": 0.4819023569023569
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      6,
      16,
      4,
      16,
      8,
      8,
      14,
      16,
      14,
      16,
      12,
      2,
      8,
      2,
      4,
      12,
      8,
      16,
      10,
      16,
      16,
      8,
      12,
      12,
      16,
      8,
      14,
      10,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.3586934873531169,
      "arc_challenge": 0.257679180887372,
      "boolq": 0.5840978593272171,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.226
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      8,
      12,
      16,
      14,
      4,
      14,
      4,
      2,
      12,
      4,
      2,
      4,
      8,
      12,
      14,
      2,
      10,
      16,
      4,
      10,
      12,
      14,
      2,
      6,
      8,
      10,
      12,
      8,
      8,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44402356902356904,
      "winogrande": 0.5248618784530387,
      "boolq": 0.44311926605504587,
      "openbookqa": 0.22,
      "piqa": 0.6920565832426551,
      "arc_challenge": 0.25341296928327645,
      "hellaswag": 0.3710416251742681
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      10,
      16,
      10,
      16,
      8,
      2,
      4,
      10,
      16,
      2,
      2,
      10,
      14,
      10,
      10,
      12,
      12,
      16,
      6,
      2,
      10,
      10,
      12,
      10,
      6,
      16,
      12,
      14,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "openbookqa": 0.238,
      "arc_challenge": 0.24829351535836178,
      "boolq": 0.5984709480122324,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.3572993427604063,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      12,
      4,
      14,
      14,
      12,
      6,
      12,
      10,
      16,
      12,
      6,
      8,
      14,
      2,
      8,
      6,
      12,
      10,
      6,
      14,
      16,
      10,
      10,
      8,
      12,
      4,
      8,
      2,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.3594901414060944,
      "boolq": 0.5755351681957187,
      "openbookqa": 0.232,
      "piqa": 0.6751904243743199
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      10,
      10,
      12,
      4,
      14,
      8,
      2,
      16,
      6,
      10,
      2,
      4,
      14,
      8,
      14,
      10,
      2,
      16,
      8,
      16,
      4,
      10,
      16,
      10,
      4,
      4,
      2,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.3712407886875124,
      "winogrande": 0.5232833464877664,
      "boolq": 0.4767584097859327,
      "openbookqa": 0.218,
      "arc_easy": 0.44696969696969696
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      6,
      12,
      8,
      8,
      4,
      2,
      14,
      14,
      14,
      16,
      16,
      12,
      16,
      6,
      16,
      12,
      6,
      16,
      14,
      8,
      12,
      8,
      10,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "piqa": 0.6887921653971708,
      "boolq": 0.4666666666666667,
      "arc_easy": 0.4532828282828283,
      "hellaswag": 0.36984664409480184,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      2,
      14,
      2,
      10,
      16,
      10,
      16,
      6,
      16,
      4,
      2,
      16,
      16,
      12,
      12,
      6,
      2,
      16,
      8,
      4,
      12,
      12,
      12,
      4,
      4,
      8,
      2,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "openbookqa": 0.234,
      "piqa": 0.6713819368879217,
      "arc_easy": 0.4970538720538721,
      "boolq": 0.6024464831804281,
      "hellaswag": 0.3602867954590719,
      "arc_challenge": 0.25341296928327645
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      2,
      8,
      14,
      8,
      6,
      6,
      8,
      8,
      8,
      16,
      8,
      14,
      6,
      8,
      6,
      12,
      8,
      8,
      8,
      12,
      10,
      4,
      6,
      6,
      8,
      16,
      16,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676822633297062,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.35839474208325034,
      "arc_easy": 0.492003367003367,
      "boolq": 0.582262996941896,
      "openbookqa": 0.22
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      6,
      4,
      16,
      2,
      16,
      14,
      8,
      12,
      4,
      16,
      12,
      10,
      10,
      2,
      12,
      12,
      16,
      12,
      2,
      2,
      4,
      12,
      4,
      16,
      4,
      2,
      2,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.236,
      "arc_challenge": 0.24146757679180889,
      "boolq": 0.5562691131498471,
      "piqa": 0.6779107725788901,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.4861111111111111,
      "hellaswag": 0.358195578570006
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      4,
      8,
      10,
      8,
      8,
      8,
      14,
      6,
      8,
      12,
      12,
      14,
      6,
      12,
      10,
      10,
      4,
      16,
      14,
      10,
      16,
      16,
      12,
      4,
      10,
      16,
      6,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "winogrande": 0.516179952644041,
      "boolq": 0.43547400611620796,
      "piqa": 0.6844396082698585,
      "arc_easy": 0.45454545454545453,
      "hellaswag": 0.3692491535550687,
      "arc_challenge": 0.25
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      10,
      14,
      8,
      6,
      16,
      6,
      14,
      14,
      16,
      6,
      4,
      8,
      2,
      4,
      8,
      14,
      12,
      6,
      14,
      4,
      12,
      6,
      14,
      16,
      2,
      4,
      8,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3694483170683131,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.44464831804281346,
      "openbookqa": 0.216,
      "arc_challenge": 0.25426621160409557,
      "piqa": 0.690424374319913,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      16,
      10,
      14,
      8,
      10,
      10,
      4,
      8,
      4,
      2,
      12,
      6,
      4,
      8,
      16,
      6,
      16,
      8,
      12,
      10,
      4,
      12,
      14,
      6,
      14,
      16,
      8,
      2,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.216,
      "arc_easy": 0.4385521885521885,
      "arc_challenge": 0.25597269624573377,
      "boolq": 0.4724770642201835,
      "hellaswag": 0.3686516630153356,
      "piqa": 0.690424374319913
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      6,
      2,
      16,
      2,
      10,
      16,
      14,
      2,
      12,
      4,
      2,
      4,
      10,
      4,
      14,
      8,
      8,
      12,
      6,
      12,
      4,
      6,
      8,
      14,
      16,
      8,
      10,
      12,
      8,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24658703071672355,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.232,
      "boolq": 0.5626911314984709,
      "hellaswag": 0.36008763194582755
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      14,
      6,
      12,
      12,
      4,
      2,
      12,
      12,
      12,
      8,
      8,
      6,
      16,
      14,
      8,
      14,
      2,
      2,
      14,
      14,
      6,
      12,
      4,
      8,
      12,
      14,
      4,
      6,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36885082652858,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.44486531986531985,
      "arc_challenge": 0.2551194539249147,
      "boolq": 0.4779816513761468,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.214
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      10,
      6,
      8,
      10,
      10,
      4,
      14,
      8,
      2,
      8,
      16,
      10,
      12,
      16,
      16,
      6,
      8,
      4,
      12,
      4,
      8,
      2,
      10,
      8,
      14,
      12,
      2,
      10,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.222,
      "hellaswag": 0.369946225851424,
      "boolq": 0.48073394495412847,
      "arc_challenge": 0.24744027303754265,
      "arc_easy": 0.44402356902356904,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      4,
      2,
      14,
      4,
      8,
      2,
      4,
      16,
      10,
      10,
      8,
      14,
      8,
      4,
      6,
      16,
      14,
      8,
      8,
      16,
      16,
      8,
      14,
      6,
      4,
      8,
      6,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4363914373088685,
      "openbookqa": 0.214,
      "arc_easy": 0.4414983164983165,
      "piqa": 0.6887921653971708,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.3695478988249353,
      "arc_challenge": 0.2551194539249147
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      16,
      6,
      12,
      2,
      8,
      8,
      8,
      6,
      8,
      8,
      14,
      12,
      10,
      12,
      2,
      10,
      10,
      16,
      16,
      2,
      16,
      16,
      12,
      10,
      4,
      8,
      6,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4452861952861953,
      "openbookqa": 0.216,
      "hellaswag": 0.3684524995020912,
      "winogrande": 0.526440410418311,
      "boolq": 0.454434250764526,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.24658703071672355
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      8,
      16,
      6,
      6,
      16,
      8,
      10,
      2,
      4,
      2,
      8,
      16,
      16,
      4,
      2,
      8,
      14,
      8,
      12,
      14,
      2,
      14,
      14,
      10,
      8,
      4,
      6,
      16,
      4,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4253822629969419,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.216,
      "arc_easy": 0.44234006734006737,
      "hellaswag": 0.369946225851424,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.25426621160409557
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      6,
      6,
      16,
      4,
      12,
      2,
      16,
      2,
      12,
      6,
      12,
      6,
      8,
      14,
      16,
      2,
      10,
      10,
      6,
      12,
      2,
      16,
      2,
      10,
      12,
      6,
      6,
      16,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3701453893646684,
      "piqa": 0.6860718171926007,
      "boolq": 0.4892966360856269,
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.25426621160409557,
      "openbookqa": 0.22,
      "arc_easy": 0.4398148148148148
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      2,
      8,
      6,
      12,
      10,
      8,
      10,
      12,
      2,
      2,
      8,
      4,
      10,
      8,
      12,
      12,
      14,
      8,
      10,
      8,
      16,
      6,
      16,
      2,
      12,
      10,
      2,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "arc_challenge": 0.2525597269624573,
      "piqa": 0.6664853101196954,
      "boolq": 0.5908256880733945,
      "openbookqa": 0.226,
      "hellaswag": 0.36008763194582755,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      8,
      16,
      14,
      10,
      14,
      6,
      8,
      12,
      8,
      2,
      10,
      12,
      2,
      6,
      4,
      16,
      6,
      10,
      12,
      8,
      8,
      12,
      6,
      16,
      6,
      14,
      12,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.526440410418311,
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.228,
      "boolq": 0.5785932721712538,
      "hellaswag": 0.36068512248556067,
      "arc_challenge": 0.2440273037542662,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      10,
      14,
      6,
      4,
      10,
      6,
      14,
      10,
      6,
      16,
      4,
      6,
      2,
      6,
      12,
      10,
      12,
      12,
      10,
      16,
      16,
      8,
      12,
      4,
      12,
      14,
      2,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5743119266055046,
      "hellaswag": 0.359788886675961,
      "piqa": 0.6746463547334058,
      "arc_easy": 0.48737373737373735,
      "arc_challenge": 0.2431740614334471,
      "openbookqa": 0.224,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      10,
      4,
      6,
      16,
      10,
      14,
      14,
      8,
      14,
      10,
      2,
      8,
      12,
      4,
      2,
      10,
      2,
      10,
      8,
      6,
      12,
      8,
      12,
      12,
      8,
      2,
      10,
      4,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.3721370244971121,
      "boolq": 0.427217125382263,
      "openbookqa": 0.218,
      "arc_easy": 0.4541245791245791,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      12,
      6,
      8,
      6,
      8,
      12,
      12,
      6,
      6,
      16,
      14,
      12,
      8,
      2,
      2,
      16,
      14,
      14,
      16,
      8,
      8,
      16,
      12,
      14,
      16,
      14,
      10,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4511784511784512,
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5209155485398579,
      "hellaswag": 0.37054371639115713,
      "openbookqa": 0.22,
      "boolq": 0.46238532110091746,
      "piqa": 0.691512513601741
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      4,
      6,
      6,
      6,
      16,
      16,
      4,
      2,
      8,
      12,
      6,
      14,
      4,
      4,
      16,
      6,
      10,
      6,
      2,
      14,
      10,
      6,
      10,
      6,
      4,
      14,
      2,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "openbookqa": 0.226,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6708378672470077,
      "boolq": 0.5660550458715596,
      "arc_challenge": 0.23976109215017063,
      "hellaswag": 0.3586934873531169
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      10,
      16,
      10,
      6,
      2,
      2,
      14,
      12,
      10,
      4,
      4,
      4,
      4,
      14,
      12,
      6,
      6,
      4,
      8,
      10,
      8,
      14,
      14,
      16,
      16,
      4,
      6,
      2,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6926006528835691,
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.37054371639115713,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.40886850152905196,
      "openbookqa": 0.214,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      16,
      4,
      2,
      4,
      14,
      12,
      6,
      10,
      4,
      4,
      10,
      8,
      10,
      12,
      4,
      14,
      12,
      2,
      4,
      2,
      6,
      10,
      14,
      14,
      12,
      10,
      8,
      12,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "arc_easy": 0.44486531986531985,
      "hellaswag": 0.369946225851424,
      "boolq": 0.44954128440366975,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5193370165745856,
      "openbookqa": 0.212
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      6,
      10,
      2,
      2,
      4,
      4,
      6,
      4,
      2,
      4,
      10,
      8,
      10,
      10,
      8,
      4,
      8,
      6,
      10,
      12,
      6,
      10,
      2,
      10,
      8,
      10,
      14,
      14,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.232,
      "piqa": 0.6724700761697497,
      "arc_easy": 0.4861111111111111,
      "hellaswag": 0.3584943238398725,
      "arc_challenge": 0.24488054607508533,
      "boolq": 0.5990825688073395
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      6,
      10,
      10,
      4,
      8,
      14,
      12,
      12,
      4,
      12,
      12,
      10,
      14,
      10,
      12,
      12,
      6,
      6,
      16,
      8,
      16,
      8,
      6,
      2,
      14,
      2,
      12,
      16,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3577972515435172,
      "piqa": 0.6784548422198041,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.48484848484848486,
      "arc_challenge": 0.24146757679180889,
      "boolq": 0.5792048929663609,
      "openbookqa": 0.236
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      8,
      12,
      6,
      10,
      16,
      6,
      4,
      12,
      8,
      2,
      2,
      6,
      14,
      16,
      2,
      14,
      12,
      14,
      2,
      16,
      12,
      2,
      16,
      8,
      14,
      12,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5516819571865443,
      "winogrande": 0.5232833464877664,
      "piqa": 0.6746463547334058,
      "openbookqa": 0.236,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.4877946127946128,
      "hellaswag": 0.35829516032662817
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      16,
      8,
      6,
      10,
      6,
      14,
      8,
      12,
      4,
      4,
      14,
      6,
      14,
      16,
      16,
      14,
      2,
      12,
      14,
      12,
      4,
      10,
      16,
      6,
      10,
      8,
      8,
      6,
      14,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "hellaswag": 0.3708424616610237,
      "boolq": 0.4363914373088685,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.2525597269624573,
      "openbookqa": 0.216,
      "arc_easy": 0.4515993265993266
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      10,
      8,
      8,
      16,
      16,
      16,
      2,
      14,
      14,
      8,
      4,
      6,
      10,
      6,
      6,
      12,
      16,
      8,
      6,
      10,
      2,
      6,
      6,
      14,
      2,
      12,
      2,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.4730886850152905,
      "hellaswag": 0.37044413463453496,
      "arc_challenge": 0.24829351535836178,
      "arc_easy": 0.44612794612794615,
      "winogrande": 0.5098658247829518,
      "openbookqa": 0.222
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      6,
      6,
      14,
      8,
      8,
      12,
      16,
      6,
      12,
      14,
      8,
      14,
      10,
      4,
      16,
      16,
      6,
      16,
      6,
      2,
      16,
      6,
      12,
      14,
      10,
      8,
      8,
      2,
      16,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.24573378839590443,
      "boolq": 0.5886850152905199,
      "openbookqa": 0.232,
      "hellaswag": 0.35879306910973907,
      "arc_easy": 0.47769360269360267,
      "piqa": 0.6773667029379761
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      12,
      2,
      12,
      12,
      16,
      12,
      2,
      2,
      14,
      16,
      8,
      4,
      16,
      8,
      12,
      2,
      4,
      12,
      16,
      10,
      12,
      4,
      14,
      10,
      10,
      2,
      2,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.359788886675961,
      "winogrande": 0.5153906866614049,
      "arc_challenge": 0.25,
      "piqa": 0.6730141458106638,
      "openbookqa": 0.224,
      "arc_easy": 0.4819023569023569,
      "boolq": 0.6018348623853211
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      8,
      4,
      12,
      16,
      8,
      6,
      2,
      16,
      14,
      14,
      4,
      12,
      2,
      6,
      6,
      8,
      6,
      10,
      2,
      6,
      14,
      14,
      10,
      8,
      12,
      6,
      12,
      6,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35859390559649473,
      "arc_easy": 0.4802188552188552,
      "boolq": 0.5571865443425077,
      "piqa": 0.676278563656148,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.228,
      "arc_challenge": 0.24488054607508533
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      8,
      2,
      16,
      8,
      12,
      16,
      14,
      4,
      8,
      4,
      14,
      6,
      2,
      14,
      14,
      8,
      2,
      14,
      2,
      6,
      2,
      2,
      14,
      4,
      8,
      4,
      16,
      2,
      10,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "winogrande": 0.5177584846093133,
      "boolq": 0.555045871559633,
      "arc_challenge": 0.2568259385665529,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.35769766978689504,
      "arc_easy": 0.4911616161616162
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      16,
      8,
      12,
      10,
      6,
      16,
      14,
      14,
      10,
      12,
      2,
      4,
      10,
      6,
      10,
      4,
      4,
      12,
      8,
      4,
      14,
      4,
      8,
      16,
      10,
      4,
      16,
      2,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_easy": 0.44654882154882153,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.36885082652858,
      "openbookqa": 0.22,
      "boolq": 0.4529051987767584,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      10,
      4,
      4,
      6,
      12,
      6,
      10,
      2,
      12,
      2,
      14,
      16,
      8,
      2,
      10,
      6,
      6,
      6,
      4,
      8,
      16,
      12,
      10,
      8,
      12,
      2,
      6,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.3701453893646684,
      "winogrande": 0.5240726124704025,
      "boolq": 0.42782874617737005,
      "openbookqa": 0.208,
      "piqa": 0.691512513601741,
      "arc_challenge": 0.25170648464163825
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      8,
      8,
      8,
      2,
      16,
      4,
      2,
      10,
      6,
      16,
      8,
      4,
      2,
      16,
      14,
      8,
      16,
      6,
      8,
      2,
      8,
      16,
      6,
      6,
      14,
      6,
      16,
      10,
      10,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25,
      "arc_easy": 0.44065656565656564,
      "piqa": 0.690424374319913,
      "openbookqa": 0.22,
      "winogrande": 0.5311760063141279,
      "boolq": 0.47370030581039757,
      "hellaswag": 0.369946225851424
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      4,
      2,
      12,
      4,
      4,
      8,
      16,
      2,
      6,
      8,
      4,
      6,
      14,
      12,
      6,
      10,
      4,
      8,
      4,
      8,
      2,
      10,
      4,
      4,
      2,
      16,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6855277475516867,
      "boolq": 0.4685015290519878,
      "arc_easy": 0.45202020202020204,
      "arc_challenge": 0.25426621160409557,
      "winogrande": 0.5090765588003157,
      "openbookqa": 0.222,
      "hellaswag": 0.36895040828520215
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      16,
      8,
      2,
      6,
      2,
      16,
      8,
      2,
      8,
      12,
      4,
      14,
      10,
      10,
      8,
      2,
      12,
      4,
      16,
      12,
      4,
      4,
      10,
      10,
      16,
      16,
      12,
      14,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45202020202020204,
      "boolq": 0.40275229357798165,
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.37183827922724555,
      "piqa": 0.6920565832426551,
      "openbookqa": 0.216
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      16,
      8,
      16,
      8,
      2,
      8,
      4,
      14,
      4,
      8,
      2,
      16,
      10,
      6,
      2,
      2,
      2,
      16,
      4,
      2,
      6,
      10,
      16,
      10,
      12,
      10,
      2,
      10,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "piqa": 0.6838955386289445,
      "openbookqa": 0.22,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.24914675767918087,
      "boolq": 0.4363914373088685,
      "hellaswag": 0.37134037044413465
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      12,
      10,
      16,
      16,
      12,
      6,
      8,
      8,
      6,
      12,
      10,
      16,
      6,
      8,
      8,
      2,
      2,
      4,
      14,
      8,
      6,
      6,
      8,
      14,
      12,
      14,
      2,
      6,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.42691131498470947,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.222,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44402356902356904,
      "hellaswag": 0.37024497112129057,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      12,
      10,
      14,
      14,
      8,
      16,
      16,
      4,
      6,
      4,
      2,
      2,
      2,
      16,
      14,
      6,
      10,
      16,
      10,
      8,
      2,
      14,
      4,
      10,
      12,
      14,
      12,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4537037037037037,
      "hellaswag": 0.3703445528779128,
      "boolq": 0.45137614678899085,
      "arc_challenge": 0.2508532423208191,
      "openbookqa": 0.224,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      2,
      6,
      12,
      14,
      2,
      16,
      16,
      16,
      8,
      2,
      4,
      12,
      2,
      2,
      4,
      14,
      6,
      6,
      6,
      16,
      10,
      2,
      6,
      14,
      4,
      8,
      8,
      6,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45075757575757575,
      "hellaswag": 0.3708424616610237,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.218,
      "arc_challenge": 0.2525597269624573,
      "piqa": 0.6877040261153428,
      "boolq": 0.43700305810397555
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      12,
      6,
      4,
      12,
      16,
      8,
      16,
      4,
      2,
      16,
      10,
      8,
      16,
      6,
      6,
      8,
      12,
      6,
      12,
      10,
      6,
      16,
      8,
      4,
      4,
      16,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "openbookqa": 0.232,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.24744027303754265,
      "hellaswag": 0.3580959968133838,
      "winogrande": 0.5201262825572218,
      "boolq": 0.5629969418960244
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      10,
      10,
      16,
      2,
      8,
      12,
      12,
      14,
      8,
      2,
      4,
      8,
      14,
      10,
      16,
      2,
      2,
      6,
      4,
      4,
      12,
      12,
      12,
      8,
      4,
      14,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5090765588003157,
      "boolq": 0.5862385321100917,
      "arc_challenge": 0.24658703071672355,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.228,
      "hellaswag": 0.3623780123481378,
      "arc_easy": 0.4852693602693603
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      10,
      4,
      10,
      14,
      6,
      8,
      12,
      12,
      10,
      16,
      16,
      6,
      4,
      10,
      12,
      6,
      14,
      16,
      6,
      2,
      16,
      12,
      4,
      16,
      16,
      10,
      2,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.218,
      "piqa": 0.690424374319913,
      "hellaswag": 0.36895040828520215,
      "boolq": 0.45902140672782876,
      "arc_challenge": 0.24658703071672355
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      2,
      8,
      12,
      12,
      8,
      8,
      2,
      2,
      12,
      14,
      6,
      8,
      14,
      10,
      2,
      2,
      8,
      12,
      10,
      4,
      2,
      4,
      2,
      10,
      4,
      2,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.228,
      "arc_challenge": 0.2568259385665529,
      "hellaswag": 0.37064329814777935,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6887921653971708,
      "arc_easy": 0.45580808080808083,
      "boolq": 0.5058103975535169
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      6,
      8,
      6,
      16,
      4,
      12,
      10,
      14,
      10,
      12,
      2,
      2,
      12,
      14,
      2,
      12,
      8,
      16,
      2,
      4,
      6,
      2,
      14,
      4,
      14,
      16,
      14,
      14,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "arc_easy": 0.44654882154882153,
      "piqa": 0.6882480957562568,
      "boolq": 0.42324159021406726,
      "hellaswag": 0.37044413463453496,
      "arc_challenge": 0.23890784982935154,
      "winogrande": 0.5138121546961326
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      4,
      4,
      14,
      8,
      6,
      2,
      14,
      10,
      10,
      10,
      6,
      10,
      14,
      10,
      12,
      8,
      10,
      16,
      2,
      4,
      16,
      8,
      2,
      10,
      14,
      16,
      16,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37024497112129057,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.222,
      "arc_easy": 0.4414983164983165,
      "arc_challenge": 0.2568259385665529,
      "boolq": 0.4492354740061162,
      "piqa": 0.6898803046789989
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      16,
      6,
      16,
      12,
      10,
      4,
      14,
      4,
      14,
      12,
      16,
      2,
      4,
      4,
      6,
      14,
      14,
      4,
      16,
      12,
      4,
      14,
      2,
      8,
      10,
      12,
      6,
      12,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25597269624573377,
      "openbookqa": 0.21,
      "arc_easy": 0.4524410774410774,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.369946225851424,
      "boolq": 0.4675840978593272,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      16,
      2,
      12,
      14,
      8,
      4,
      14,
      16,
      8,
      8,
      2,
      8,
      10,
      8,
      16,
      2,
      4,
      16,
      6,
      8,
      12,
      14,
      6,
      10,
      16,
      12,
      2,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "hellaswag": 0.3701453893646684,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.25,
      "boolq": 0.45321100917431195,
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.4444444444444444
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      8,
      2,
      12,
      8,
      4,
      6,
      8,
      10,
      16,
      6,
      2,
      16,
      8,
      16,
      14,
      12,
      6,
      10,
      10,
      16,
      2,
      16,
      6,
      14,
      4,
      2,
      14,
      4,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5130228887134964,
      "arc_challenge": 0.2551194539249147,
      "openbookqa": 0.22,
      "arc_easy": 0.4452861952861953,
      "hellaswag": 0.3708424616610237,
      "piqa": 0.6898803046789989,
      "boolq": 0.47889908256880737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      8,
      16,
      4,
      8,
      6,
      16,
      6,
      2,
      2,
      6,
      14,
      10,
      14,
      2,
      10,
      16,
      8,
      2,
      8,
      6,
      2,
      6,
      6,
      12,
      14,
      12,
      14,
      14,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.47155963302752296,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.37054371639115713,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2551194539249147,
      "openbookqa": 0.22,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      10,
      6,
      14,
      6,
      2,
      10,
      4,
      8,
      2,
      14,
      10,
      16,
      14,
      4,
      2,
      4,
      16,
      14,
      6,
      6,
      14,
      10,
      16,
      4,
      10,
      2,
      4,
      4,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4436026936026936,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.37054371639115713,
      "openbookqa": 0.216,
      "boolq": 0.45902140672782876,
      "arc_challenge": 0.24914675767918087
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      10,
      12,
      16,
      8,
      14,
      10,
      4,
      6,
      14,
      8,
      8,
      14,
      8,
      10,
      8,
      2,
      12,
      6,
      8,
      16,
      8,
      8,
      6,
      4,
      10,
      12,
      12,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6702937976060935,
      "boolq": 0.6015290519877676,
      "arc_easy": 0.48947811447811446,
      "hellaswag": 0.3601872137024497,
      "arc_challenge": 0.24573378839590443,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.236
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      4,
      10,
      14,
      2,
      16,
      8,
      12,
      4,
      10,
      14,
      2,
      10,
      10,
      10,
      10,
      16,
      10,
      4,
      8,
      6,
      6,
      4,
      10,
      10,
      12,
      4,
      10,
      14,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.691512513601741,
      "boolq": 0.4581039755351682,
      "arc_easy": 0.45075757575757575,
      "arc_challenge": 0.2593856655290102,
      "openbookqa": 0.218,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.37094204341764586
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      12,
      14,
      14,
      10,
      6,
      14,
      4,
      10,
      2,
      16,
      8,
      4,
      10,
      14,
      14,
      4,
      8,
      12,
      12,
      2,
      8,
      10,
      4,
      10,
      2,
      8,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4740061162079511,
      "arc_easy": 0.43897306397306396,
      "openbookqa": 0.218,
      "hellaswag": 0.36964748058155744,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6860718171926007,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      12,
      16,
      8,
      8,
      14,
      10,
      8,
      8,
      16,
      14,
      6,
      16,
      2,
      12,
      4,
      10,
      10,
      6,
      16,
      4,
      16,
      4,
      12,
      12,
      4,
      6,
      2,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24573378839590443,
      "boolq": 0.5541284403669725,
      "openbookqa": 0.24,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.48653198653198654,
      "hellaswag": 0.36168094005178253
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      16,
      10,
      2,
      6,
      6,
      4,
      14,
      14,
      2,
      6,
      10,
      12,
      16,
      12,
      12,
      2,
      10,
      2,
      14,
      2,
      16,
      2,
      10,
      4,
      8,
      4,
      8,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "arc_challenge": 0.25,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.47853535353535354,
      "boolq": 0.5902140672782875,
      "hellaswag": 0.35968930491933876
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      8,
      14,
      16,
      12,
      10,
      12,
      8,
      2,
      8,
      2,
      6,
      12,
      6,
      10,
      10,
      12,
      6,
      10,
      14,
      16,
      14,
      10,
      10,
      6,
      12,
      8,
      16,
      4,
      2,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5130228887134964,
      "arc_challenge": 0.24061433447098976,
      "boolq": 0.5996941896024465,
      "hellaswag": 0.35909181437960563,
      "openbookqa": 0.234
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      10,
      10,
      4,
      2,
      12,
      10,
      16,
      4,
      14,
      16,
      6,
      10,
      12,
      14,
      12,
      8,
      2,
      8,
      10,
      8,
      4,
      2,
      6,
      6,
      2,
      16,
      12,
      10,
      4,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "arc_challenge": 0.2440273037542662,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.3572993427604063,
      "boolq": 0.5654434250764526,
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6659412404787813
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      12,
      10,
      16,
      10,
      2,
      6,
      16,
      12,
      4,
      10,
      8,
      4,
      4,
      14,
      10,
      2,
      12,
      2,
      16,
      16,
      12,
      10,
      2,
      10,
      16,
      16,
      4,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2551194539249147,
      "piqa": 0.690424374319913,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4457070707070707,
      "boolq": 0.44311926605504587,
      "openbookqa": 0.216,
      "hellaswag": 0.3701453893646684
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      4,
      16,
      16,
      14,
      10,
      10,
      2,
      2,
      8,
      6,
      14,
      8,
      14,
      4,
      10,
      14,
      16,
      12,
      12,
      16,
      14,
      12,
      14,
      14,
      16,
      6,
      10,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4819571865443425,
      "arc_easy": 0.4473905723905724,
      "hellaswag": 0.369946225851424,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6877040261153428,
      "openbookqa": 0.222,
      "arc_challenge": 0.2525597269624573
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      4,
      14,
      8,
      10,
      2,
      10,
      12,
      2,
      8,
      10,
      10,
      8,
      10,
      8,
      6,
      2,
      14,
      12,
      2,
      6,
      8,
      12,
      6,
      4,
      12,
      4,
      14,
      6,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44107744107744107,
      "boolq": 0.4666666666666667,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.224,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.36974706233817967
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      6,
      6,
      16,
      16,
      2,
      14,
      8,
      16,
      10,
      4,
      10,
      8,
      14,
      12,
      8,
      2,
      4,
      16,
      8,
      10,
      10,
      4,
      14,
      16,
      6,
      2,
      12,
      12,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.3573989245170285,
      "arc_challenge": 0.24488054607508533,
      "openbookqa": 0.232,
      "piqa": 0.6779107725788901,
      "boolq": 0.5871559633027523
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      8,
      8,
      6,
      16,
      10,
      8,
      4,
      2,
      10,
      14,
      10,
      8,
      8,
      4,
      6,
      2,
      2,
      2,
      14,
      10,
      16,
      10,
      14,
      14,
      8,
      16,
      12,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4810606060606061,
      "arc_challenge": 0.24658703071672355,
      "hellaswag": 0.35968930491933876,
      "openbookqa": 0.23,
      "winogrande": 0.5185477505919495,
      "boolq": 0.6048929663608563,
      "piqa": 0.6730141458106638
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      8,
      10,
      2,
      4,
      10,
      14,
      8,
      16,
      4,
      12,
      4,
      6,
      12,
      10,
      6,
      12,
      8,
      8,
      14,
      2,
      16,
      2,
      6,
      4,
      2,
      6,
      16,
      12,
      6,
      2,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.24,
      "piqa": 0.6719260065288357,
      "arc_challenge": 0.2440273037542662,
      "boolq": 0.5626911314984709,
      "winogrande": 0.510655090765588,
      "arc_easy": 0.48569023569023567,
      "hellaswag": 0.358195578570006
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      8,
      12,
      12,
      6,
      4,
      10,
      16,
      14,
      16,
      16,
      10,
      4,
      10,
      10,
      10,
      4,
      16,
      14,
      4,
      6,
      8,
      8,
      8,
      10,
      4,
      12,
      16,
      2,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "arc_easy": 0.4473905723905724,
      "boolq": 0.4724770642201835,
      "piqa": 0.6877040261153428,
      "hellaswag": 0.371539533957379,
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      16,
      6,
      12,
      16,
      8,
      6,
      8,
      4,
      12,
      6,
      14,
      10,
      12,
      12,
      12,
      2,
      8,
      12,
      14,
      8,
      2,
      10,
      10,
      14,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4782874617737003,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.690424374319913,
      "openbookqa": 0.22,
      "hellaswag": 0.3701453893646684,
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.4524410774410774
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      8,
      4,
      12,
      16,
      2,
      16,
      10,
      2,
      8,
      4,
      4,
      8,
      8,
      2,
      6,
      10,
      14,
      14,
      8,
      6,
      4,
      12,
      6,
      16,
      4,
      6,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44612794612794615,
      "piqa": 0.6849836779107725,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.3695478988249353,
      "openbookqa": 0.214,
      "boolq": 0.42660550458715596,
      "arc_challenge": 0.24146757679180889
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      8,
      10,
      14,
      2,
      4,
      6,
      14,
      6,
      12,
      8,
      12,
      4,
      10,
      14,
      12,
      2,
      14,
      10,
      6,
      4,
      10,
      12,
      12,
      16,
      16,
      6,
      6,
      12,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.4503367003367003,
      "boolq": 0.4363914373088685,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.2619453924914676,
      "hellaswag": 0.3716391157140012,
      "openbookqa": 0.218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      6,
      12,
      8,
      10,
      14,
      6,
      12,
      6,
      12,
      16,
      14,
      16,
      8,
      10,
      14,
      10,
      16,
      16,
      2,
      12,
      12,
      4,
      16,
      2,
      16,
      4,
      14,
      2,
      10,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2440273037542662,
      "piqa": 0.6686615886833515,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.3579964150567616,
      "boolq": 0.591743119266055,
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.23
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      10,
      14,
      2,
      6,
      2,
      16,
      12,
      4,
      16,
      10,
      4,
      4,
      16,
      12,
      2,
      6,
      10,
      16,
      4,
      12,
      16,
      14,
      2,
      2,
      16,
      2,
      8,
      6,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "boolq": 0.4400611620795107,
      "hellaswag": 0.3714399522007568,
      "openbookqa": 0.216,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.690968443960827,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      12,
      6,
      12,
      10,
      14,
      4,
      2,
      6,
      2,
      16,
      16,
      4,
      4,
      16,
      2,
      2,
      2,
      4,
      10,
      12,
      8,
      14,
      4,
      2,
      4,
      2,
      2,
      4,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.23,
      "hellaswag": 0.3593905596494722,
      "winogrande": 0.5153906866614049,
      "arc_challenge": 0.24658703071672355,
      "boolq": 0.5694189602446483,
      "piqa": 0.676822633297062,
      "arc_easy": 0.48442760942760943
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      14,
      10,
      4,
      6,
      8,
      2,
      2,
      8,
      16,
      2,
      12,
      4,
      10,
      16,
      6,
      2,
      12,
      8,
      16,
      16,
      8,
      10,
      16,
      16,
      8,
      14,
      16,
      12,
      10,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "piqa": 0.6860718171926007,
      "hellaswag": 0.3712407886875124,
      "boolq": 0.4602446483180428,
      "arc_easy": 0.4473905723905724,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.214
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      8,
      14,
      2,
      4,
      10,
      14,
      14,
      12,
      16,
      8,
      10,
      14,
      14,
      16,
      2,
      2,
      16,
      4,
      10,
      12,
      6,
      8,
      12,
      2,
      6,
      16,
      10,
      6,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.359788886675961,
      "boolq": 0.5871559633027523,
      "arc_easy": 0.4898989898989899,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.232
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      12,
      10,
      2,
      6,
      8,
      6,
      14,
      16,
      12,
      14,
      2,
      10,
      14,
      6,
      14,
      10,
      16,
      2,
      10,
      4,
      6,
      12,
      14,
      8,
      14,
      12,
      2,
      8,
      12,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.47769360269360267,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.360884285998805,
      "arc_challenge": 0.24658703071672355,
      "boolq": 0.5868501529051988,
      "openbookqa": 0.222,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      10,
      8,
      8,
      12,
      10,
      6,
      8,
      12,
      4,
      12,
      6,
      8,
      6,
      4,
      10,
      16,
      2,
      6,
      2,
      2,
      4,
      4,
      6,
      10,
      14,
      10,
      10,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.23,
      "winogrande": 0.5240726124704025,
      "hellaswag": 0.3599880501892053,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.4810606060606061,
      "piqa": 0.6686615886833515,
      "boolq": 0.5605504587155963
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      6,
      2,
      12,
      8,
      16,
      12,
      10,
      4,
      2,
      16,
      10,
      16,
      12,
      14,
      8,
      8,
      12,
      12,
      8,
      2,
      4,
      6,
      14,
      8,
      16,
      4,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3692491535550687,
      "boolq": 0.43149847094801225,
      "openbookqa": 0.222,
      "arc_easy": 0.44065656565656564,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6926006528835691
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      2,
      8,
      2,
      10,
      6,
      4,
      16,
      2,
      12,
      8,
      8,
      12,
      2,
      6,
      6,
      4,
      2,
      14,
      6,
      2,
      2,
      8,
      4,
      4,
      10,
      10,
      14,
      6,
      10,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4351851851851852,
      "boolq": 0.4892966360856269,
      "openbookqa": 0.22,
      "winogrande": 0.5335438042620363,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.37024497112129057
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      12,
      16,
      12,
      6,
      8,
      10,
      12,
      14,
      4,
      16,
      4,
      16,
      2,
      4,
      10,
      16,
      8,
      8,
      14,
      10,
      14,
      16,
      6,
      10,
      16,
      8,
      14,
      2,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45580808080808083,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.691512513601741,
      "hellaswag": 0.37094204341764586,
      "boolq": 0.4685015290519878,
      "winogrande": 0.5138121546961326,
      "openbookqa": 0.214
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      8,
      12,
      12,
      16,
      10,
      6,
      12,
      4,
      12,
      8,
      8,
      6,
      10,
      10,
      8,
      2,
      8,
      16,
      4,
      4,
      6,
      10,
      12,
      14,
      6,
      10,
      10,
      10,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37044413463453496,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.42232415902140674,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6844396082698585,
      "openbookqa": 0.208,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      2,
      10,
      8,
      2,
      10,
      14,
      10,
      4,
      2,
      12,
      2,
      12,
      16,
      12,
      12,
      8,
      4,
      14,
      14,
      14,
      4,
      12,
      14,
      2,
      10,
      8,
      2,
      8,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6697497279651795,
      "arc_challenge": 0.2551194539249147,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.244,
      "boolq": 0.581651376146789,
      "arc_easy": 0.48653198653198654,
      "hellaswag": 0.36058554072893845
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      4,
      16,
      2,
      12,
      10,
      8,
      10,
      14,
      12,
      14,
      8,
      14,
      10,
      2,
      8,
      16,
      8,
      8,
      10,
      10,
      8,
      10,
      10,
      8,
      2,
      6,
      4,
      14,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5193370165745856,
      "boolq": 0.45504587155963305,
      "openbookqa": 0.216,
      "piqa": 0.6871599564744287,
      "arc_easy": 0.44065656565656564,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.3693487353116909
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      2,
      12,
      6,
      4,
      12,
      14,
      14,
      6,
      12,
      10,
      16,
      12,
      4,
      14,
      10,
      4,
      14,
      4,
      12,
      8,
      10,
      2,
      8,
      12,
      6,
      6,
      6,
      6,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37183827922724555,
      "arc_easy": 0.44276094276094274,
      "boolq": 0.41834862385321103,
      "openbookqa": 0.216,
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5240726124704025,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      6,
      2,
      14,
      16,
      4,
      2,
      14,
      16,
      4,
      16,
      6,
      14,
      12,
      10,
      2,
      10,
      8,
      12,
      8,
      10,
      10,
      2,
      14,
      4,
      2,
      2,
      2,
      4,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.2568259385665529,
      "boolq": 0.45382262996941897,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.3703445528779128
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      8,
      10,
      6,
      16,
      8,
      8,
      14,
      2,
      10,
      6,
      8,
      12,
      6,
      16,
      2,
      8,
      8,
      12,
      10,
      16,
      10,
      16,
      16,
      4,
      14,
      12,
      4,
      8,
      10,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.43486238532110094,
      "hellaswag": 0.3693487353116909,
      "arc_challenge": 0.24829351535836178,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.222,
      "piqa": 0.6871599564744287,
      "arc_easy": 0.43476430976430974
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      6,
      4,
      2,
      16,
      8,
      4,
      6,
      16,
      6,
      10,
      2,
      4,
      4,
      2,
      16,
      2,
      10,
      2,
      6,
      8,
      10,
      16,
      4,
      14,
      16,
      4,
      6,
      12,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36885082652858,
      "openbookqa": 0.22,
      "arc_challenge": 0.24488054607508533,
      "piqa": 0.6882480957562568,
      "arc_easy": 0.4452861952861953,
      "winogrande": 0.5217048145224941,
      "boolq": 0.463914373088685
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      8,
      2,
      16,
      2,
      2,
      2,
      16,
      16,
      12,
      8,
      8,
      16,
      10,
      10,
      16,
      14,
      8,
      6,
      14,
      10,
      14,
      16,
      10,
      8,
      8,
      2,
      4,
      12,
      2,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.516179952644041,
      "piqa": 0.6708378672470077,
      "openbookqa": 0.23,
      "hellaswag": 0.3588926508663613,
      "boolq": 0.5788990825688073,
      "arc_easy": 0.48442760942760943
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      6,
      12,
      2,
      10,
      14,
      16,
      16,
      10,
      12,
      12,
      12,
      8,
      2,
      4,
      14,
      10,
      10,
      4,
      10,
      16,
      6,
      4,
      2,
      16,
      12,
      12,
      8,
      12,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5224940805051302,
      "arc_challenge": 0.24488054607508533,
      "boolq": 0.5229357798165137,
      "hellaswag": 0.3571997610037841,
      "openbookqa": 0.23,
      "arc_easy": 0.4823232323232323,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      16,
      16,
      2,
      2,
      6,
      10,
      10,
      2,
      12,
      6,
      14,
      16,
      6,
      4,
      4,
      8,
      6,
      14,
      14,
      4,
      2,
      12,
      8,
      16,
      6,
      16,
      2,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4397553516819572,
      "piqa": 0.6898803046789989,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.22,
      "hellaswag": 0.36964748058155744,
      "arc_challenge": 0.24488054607508533,
      "arc_easy": 0.4444444444444444
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      8,
      16,
      14,
      2,
      4,
      14,
      4,
      8,
      16,
      6,
      8,
      6,
      2,
      14,
      4,
      2,
      10,
      8,
      16,
      4,
      10,
      10,
      4,
      2,
      14,
      6,
      10,
      14,
      6,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3708424616610237,
      "arc_easy": 0.4494949494949495,
      "openbookqa": 0.222,
      "winogrande": 0.516179952644041,
      "piqa": 0.691512513601741,
      "arc_challenge": 0.25853242320819114,
      "boolq": 0.42813455657492355
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      12,
      10,
      14,
      10,
      6,
      10,
      4,
      8,
      16,
      6,
      4,
      2,
      4,
      10,
      16,
      14,
      2,
      2,
      8,
      6,
      10,
      4,
      8,
      10,
      10,
      10,
      6,
      8,
      8,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35879306910973907,
      "openbookqa": 0.236,
      "winogrande": 0.5217048145224941,
      "arc_challenge": 0.24658703071672355,
      "boolq": 0.5850152905198777,
      "arc_easy": 0.48863636363636365,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      8,
      12,
      6,
      12,
      16,
      2,
      8,
      14,
      14,
      8,
      6,
      2,
      16,
      4,
      4,
      4,
      12,
      10,
      8,
      10,
      6,
      8,
      14,
      4,
      10,
      12,
      4,
      10,
      8,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5240726124704025,
      "arc_easy": 0.484006734006734,
      "openbookqa": 0.24,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3584943238398725,
      "boolq": 0.5935779816513761,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      16,
      6,
      6,
      14,
      2,
      8,
      2,
      4,
      14,
      8,
      6,
      10,
      6,
      12,
      6,
      14,
      12,
      8,
      2,
      12,
      4,
      2,
      8,
      16,
      16,
      8,
      10,
      8,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4831649831649832,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5694189602446483,
      "hellaswag": 0.35988846843258315,
      "arc_challenge": 0.2431740614334471,
      "openbookqa": 0.232,
      "piqa": 0.6692056583242655
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      16,
      14,
      14,
      12,
      10,
      16,
      14,
      8,
      2,
      14,
      10,
      12,
      6,
      6,
      14,
      16,
      8,
      12,
      8,
      16,
      4,
      12,
      6,
      12,
      10,
      10,
      16,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25426621160409557,
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.232,
      "piqa": 0.6708378672470077,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5761467889908257,
      "hellaswag": 0.359788886675961
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      12,
      16,
      2,
      16,
      8,
      10,
      12,
      14,
      14,
      10,
      2,
      8,
      12,
      10,
      4,
      2,
      2,
      6,
      10,
      8,
      16,
      2,
      14,
      16,
      6,
      12,
      14,
      14,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25,
      "boolq": 0.48256880733944957,
      "piqa": 0.6887921653971708,
      "winogrande": 0.510655090765588,
      "hellaswag": 0.369946225851424,
      "openbookqa": 0.22,
      "arc_easy": 0.4377104377104377
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      12,
      4,
      6,
      4,
      8,
      16,
      6,
      12,
      8,
      10,
      16,
      6,
      12,
      6,
      12,
      14,
      2,
      16,
      2,
      12,
      16,
      4,
      2,
      4,
      14,
      16,
      2,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4507645259938838,
      "winogrande": 0.5193370165745856,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.24658703071672355,
      "hellaswag": 0.37024497112129057,
      "openbookqa": 0.218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      6,
      4,
      12,
      14,
      10,
      10,
      2,
      8,
      10,
      8,
      16,
      6,
      6,
      4,
      12,
      8,
      4,
      8,
      4,
      14,
      10,
      10,
      6,
      16,
      6,
      8,
      4,
      14,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.3577972515435172,
      "openbookqa": 0.23,
      "winogrande": 0.5201262825572218,
      "boolq": 0.5764525993883792
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      2,
      16,
      16,
      6,
      12,
      12,
      12,
      10,
      12,
      4,
      12,
      2,
      14,
      2,
      6,
      4,
      16,
      16,
      12,
      14,
      12,
      8,
      12,
      2,
      10,
      8,
      8,
      16,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.492003367003367,
      "boolq": 0.5694189602446483,
      "openbookqa": 0.232,
      "arc_challenge": 0.24573378839590443,
      "piqa": 0.675734494015234,
      "winogrande": 0.5019731649565904,
      "hellaswag": 0.35879306910973907
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      16,
      16,
      14,
      16,
      8,
      10,
      6,
      16,
      12,
      10,
      12,
      16,
      12,
      6,
      12,
      14,
      4,
      12,
      10,
      6,
      8,
      10,
      2,
      16,
      4,
      8,
      4,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "piqa": 0.6877040261153428,
      "boolq": 0.42324159021406726,
      "hellaswag": 0.3701453893646684,
      "openbookqa": 0.21,
      "arc_easy": 0.44191919191919193,
      "arc_challenge": 0.2525597269624573
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      8,
      12,
      2,
      16,
      16,
      4,
      14,
      4,
      6,
      4,
      16,
      10,
      4,
      8,
      4,
      14,
      8,
      14,
      6,
      8,
      6,
      12,
      14,
      12,
      14,
      16,
      4,
      16,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.37024497112129057,
      "boolq": 0.48990825688073397,
      "piqa": 0.691512513601741,
      "arc_easy": 0.44991582491582494,
      "arc_challenge": 0.2431740614334471,
      "openbookqa": 0.226
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      10,
      4,
      2,
      2,
      10,
      2,
      16,
      12,
      4,
      2,
      14,
      12,
      6,
      8,
      4,
      12,
      10,
      6,
      8,
      14,
      4,
      2,
      12,
      2,
      4,
      14,
      10,
      12,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.45198776758409787,
      "arc_challenge": 0.24658703071672355,
      "piqa": 0.6882480957562568,
      "openbookqa": 0.22,
      "arc_easy": 0.44486531986531985,
      "winogrande": 0.5138121546961326,
      "hellaswag": 0.37024497112129057
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      14,
      4,
      14,
      2,
      16,
      10,
      8,
      6,
      6,
      8,
      12,
      16,
      6,
      4,
      10,
      10,
      2,
      2,
      4,
      16,
      14,
      16,
      4,
      10,
      16,
      14,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35899223262298346,
      "arc_challenge": 0.25341296928327645,
      "openbookqa": 0.238,
      "winogrande": 0.5177584846093133,
      "arc_easy": 0.4861111111111111,
      "boolq": 0.57217125382263,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      8,
      2,
      16,
      6,
      2,
      6,
      2,
      2,
      6,
      2,
      12,
      16,
      16,
      16,
      6,
      2,
      16,
      2,
      16,
      2,
      2,
      14,
      8,
      8,
      6,
      12,
      12,
      16,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24829351535836178,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6866158868335147,
      "openbookqa": 0.214,
      "hellaswag": 0.3685520812587134,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4666666666666667
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      16,
      10,
      6,
      4,
      14,
      16,
      2,
      16,
      12,
      12,
      4,
      12,
      12,
      14,
      6,
      16,
      8,
      6,
      2,
      14,
      4,
      12,
      6,
      4,
      14,
      14,
      8,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3695478988249353,
      "boolq": 0.45351681957186546,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4393939393939394,
      "openbookqa": 0.22,
      "arc_challenge": 0.24658703071672355
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      4,
      2,
      16,
      10,
      12,
      8,
      6,
      6,
      10,
      8,
      12,
      6,
      8,
      4,
      6,
      8,
      4,
      6,
      16,
      8,
      6,
      16,
      12,
      6,
      4,
      4,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25426621160409557,
      "hellaswag": 0.3716391157140012,
      "arc_easy": 0.45075757575757575,
      "boolq": 0.42415902140672784,
      "openbookqa": 0.218,
      "winogrande": 0.5193370165745856,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      2,
      16,
      12,
      2,
      6,
      2,
      14,
      4,
      14,
      4,
      16,
      14,
      6,
      8,
      2,
      12,
      8,
      16,
      14,
      14,
      10,
      12,
      4,
      8,
      16,
      16,
      8,
      8,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.24,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.36078470424218284,
      "winogrande": 0.5082872928176796,
      "arc_easy": 0.48695286195286197,
      "boolq": 0.5724770642201835
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      2,
      14,
      16,
      6,
      10,
      6,
      12,
      6,
      4,
      14,
      14,
      10,
      14,
      8,
      12,
      14,
      6,
      8,
      6,
      6,
      2,
      6,
      16,
      10,
      2,
      16,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "arc_easy": 0.43813131313131315,
      "openbookqa": 0.216,
      "arc_challenge": 0.2551194539249147,
      "hellaswag": 0.37054371639115713,
      "boolq": 0.45902140672782876,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      16,
      4,
      14,
      6,
      6,
      2,
      10,
      2,
      4,
      14,
      6,
      12,
      4,
      12,
      2,
      14,
      10,
      8,
      2,
      14,
      6,
      8,
      6,
      10,
      10,
      6,
      4,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4691131498470948,
      "hellaswag": 0.36825333598884685,
      "arc_challenge": 0.24829351535836178,
      "arc_easy": 0.44696969696969696,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6893362350380848,
      "openbookqa": 0.224
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      2,
      8,
      12,
      6,
      10,
      6,
      2,
      14,
      10,
      8,
      16,
      6,
      16,
      16,
      16,
      6,
      12,
      8,
      10,
      16,
      14,
      4,
      2,
      8,
      10,
      12,
      12,
      12,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24914675767918087,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5232415902140672,
      "openbookqa": 0.214,
      "winogrande": 0.5122336227308603,
      "hellaswag": 0.3694483170683131,
      "piqa": 0.6866158868335147
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      14,
      6,
      16,
      8,
      10,
      4,
      12,
      16,
      6,
      2,
      10,
      12,
      8,
      8,
      2,
      16,
      12,
      16,
      2,
      10,
      14,
      4,
      14,
      14,
      8,
      10,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6719260065288357,
      "boolq": 0.5752293577981651,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3579964150567616
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      10,
      6,
      14,
      14,
      12,
      14,
      2,
      4,
      2,
      14,
      8,
      10,
      6,
      4,
      12,
      14,
      10,
      8,
      10,
      6,
      16,
      4,
      2,
      6,
      12,
      16,
      4,
      6,
      4,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690968443960827,
      "winogrande": 0.5185477505919495,
      "boolq": 0.44678899082568807,
      "arc_challenge": 0.24658703071672355,
      "openbookqa": 0.216,
      "arc_easy": 0.4524410774410774,
      "hellaswag": 0.37054371639115713
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      8,
      12,
      16,
      14,
      10,
      12,
      16,
      14,
      16,
      8,
      2,
      10,
      12,
      2,
      10,
      10,
      6,
      4,
      14,
      16,
      12,
      12,
      10,
      14,
      4,
      10,
      6,
      12,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5908256880733945,
      "arc_challenge": 0.24829351535836178,
      "openbookqa": 0.232,
      "piqa": 0.6692056583242655,
      "hellaswag": 0.36078470424218284
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      16,
      14,
      14,
      2,
      16,
      2,
      16,
      12,
      16,
      6,
      2,
      14,
      4,
      2,
      14,
      6,
      12,
      12,
      12,
      12,
      4,
      8,
      14,
      4,
      10,
      10,
      10,
      4,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.23,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6692056583242655,
      "hellaswag": 0.3594901414060944,
      "arc_easy": 0.47853535353535354,
      "arc_challenge": 0.24573378839590443,
      "boolq": 0.5865443425076453
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      12,
      14,
      2,
      6,
      2,
      4,
      2,
      12,
      4,
      8,
      14,
      4,
      12,
      16,
      16,
      16,
      10,
      6,
      8,
      16,
      8,
      10,
      6,
      6,
      12,
      2,
      2,
      16,
      8,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4474006116207951,
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.3716391157140012,
      "arc_challenge": 0.24658703071672355,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4494949494949495,
      "openbookqa": 0.216
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      4,
      14,
      4,
      12,
      6,
      2,
      2,
      16,
      2,
      12,
      14,
      10,
      8,
      6,
      8,
      10,
      10,
      2,
      4,
      2,
      10,
      4,
      14,
      12,
      6,
      12,
      6,
      8,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.224,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.36974706233817967,
      "arc_challenge": 0.25170648464163825,
      "boolq": 0.5061162079510704,
      "arc_easy": 0.44823232323232326,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      2,
      10,
      12,
      14,
      2,
      8,
      12,
      2,
      16,
      8,
      8,
      4,
      6,
      4,
      8,
      8,
      16,
      6,
      16,
      8,
      2,
      14,
      4,
      4,
      6,
      16,
      10,
      4,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "arc_challenge": 0.2551194539249147,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.214,
      "hellaswag": 0.37054371639115713,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.42171253822629967
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      2,
      4,
      8,
      12,
      10,
      6,
      14,
      6,
      14,
      14,
      10,
      4,
      4,
      6,
      6,
      2,
      14,
      12,
      2,
      4,
      2,
      4,
      12,
      12,
      16,
      12,
      2,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4596330275229358,
      "arc_easy": 0.4574915824915825,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.3701453893646684,
      "arc_challenge": 0.2593856655290102,
      "openbookqa": 0.226,
      "piqa": 0.6931447225244831
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      8,
      8,
      12,
      16,
      14,
      8,
      8,
      14,
      6,
      10,
      4,
      6,
      10,
      2,
      6,
      2,
      8,
      14,
      8,
      2,
      10,
      4,
      8,
      14,
      12,
      16,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4599388379204893,
      "openbookqa": 0.218,
      "arc_easy": 0.4524410774410774,
      "piqa": 0.6849836779107725,
      "arc_challenge": 0.24488054607508533,
      "hellaswag": 0.3694483170683131,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      2,
      14,
      4,
      14,
      8,
      6,
      4,
      14,
      6,
      4,
      6,
      4,
      4,
      16,
      2,
      8,
      10,
      14,
      2,
      2,
      4,
      12,
      8,
      16,
      8,
      12,
      10,
      2,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "boolq": 0.43425076452599387,
      "arc_easy": 0.4562289562289562,
      "openbookqa": 0.212,
      "piqa": 0.691512513601741,
      "hellaswag": 0.3710416251742681,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      16,
      12,
      6,
      10,
      10,
      10,
      12,
      16,
      8,
      8,
      8,
      16,
      2,
      2,
      16,
      14,
      14,
      6,
      12,
      12,
      14,
      14,
      4,
      2,
      12,
      2,
      14,
      8,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5098658247829518,
      "hellaswag": 0.3708424616610237,
      "arc_easy": 0.44486531986531985,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6855277475516867,
      "boolq": 0.43547400611620796,
      "openbookqa": 0.212
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      6,
      16,
      4,
      8,
      14,
      2,
      10,
      14,
      4,
      10,
      12,
      12,
      12,
      8,
      12,
      8,
      4,
      14,
      4,
      4,
      10,
      4,
      4,
      8,
      10,
      12,
      4,
      10,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4503367003367003,
      "boolq": 0.5266055045871559,
      "hellaswag": 0.37114120693089026,
      "winogrande": 0.5240726124704025,
      "openbookqa": 0.226,
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.2636518771331058
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      12,
      2,
      8,
      6,
      2,
      14,
      14,
      8,
      14,
      16,
      14,
      12,
      12,
      14,
      2,
      12,
      2,
      6,
      10,
      12,
      10,
      14,
      6,
      12,
      14,
      12,
      16,
      14,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5043409629044988,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.6064220183486239,
      "openbookqa": 0.236,
      "hellaswag": 0.3584943238398725,
      "piqa": 0.676822633297062
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      10,
      4,
      8,
      10,
      2,
      6,
      16,
      4,
      10,
      12,
      4,
      6,
      8,
      12,
      16,
      10,
      4,
      10,
      4,
      6,
      4,
      4,
      14,
      8,
      16,
      8,
      2,
      2,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24232081911262798,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.4739057239057239,
      "openbookqa": 0.226,
      "boolq": 0.6064220183486239,
      "hellaswag": 0.36008763194582755,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      8,
      4,
      4,
      2,
      6,
      2,
      10,
      4,
      2,
      8,
      12,
      2,
      14,
      6,
      6,
      10,
      6,
      8,
      16,
      14,
      8,
      4,
      16,
      14,
      12,
      4,
      4,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.236,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24829351535836178,
      "arc_easy": 0.48358585858585856,
      "hellaswag": 0.3571997610037841,
      "boolq": 0.5608562691131499,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      2,
      12,
      12,
      16,
      14,
      2,
      16,
      8,
      10,
      4,
      14,
      4,
      6,
      4,
      2,
      4,
      12,
      6,
      16,
      2,
      8,
      4,
      4,
      16,
      2,
      12,
      10,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35879306910973907,
      "arc_easy": 0.484006734006734,
      "boolq": 0.5801223241590214,
      "openbookqa": 0.234,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.24658703071672355,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      12,
      4,
      14,
      12,
      10,
      12,
      14,
      10,
      12,
      14,
      14,
      16,
      4,
      4,
      6,
      2,
      12,
      14,
      14,
      14,
      16,
      2,
      10,
      16,
      16,
      16,
      6,
      8,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44865319865319864,
      "boolq": 0.4504587155963303,
      "hellaswag": 0.3714399522007568,
      "winogrande": 0.5177584846093133,
      "arc_challenge": 0.25426621160409557,
      "piqa": 0.6887921653971708,
      "openbookqa": 0.222
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      6,
      4,
      4,
      10,
      12,
      16,
      14,
      14,
      6,
      10,
      8,
      4,
      16,
      2,
      16,
      4,
      10,
      16,
      10,
      6,
      16,
      4,
      8,
      10,
      8,
      4,
      2,
      10,
      4,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.5185477505919495,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.222,
      "boolq": 0.5840978593272171,
      "hellaswag": 0.35769766978689504
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      2,
      12,
      12,
      2,
      14,
      2,
      12,
      16,
      8,
      10,
      6,
      6,
      2,
      4,
      10,
      12,
      2,
      6,
      6,
      2,
      16,
      16,
      8,
      8,
      2,
      14,
      8,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676278563656148,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.49158249158249157,
      "boolq": 0.5844036697247706,
      "hellaswag": 0.35988846843258315,
      "openbookqa": 0.224,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      12,
      12,
      12,
      2,
      14,
      6,
      2,
      14,
      8,
      6,
      16,
      16,
      12,
      8,
      10,
      16,
      4,
      16,
      16,
      8,
      8,
      6,
      12,
      8,
      2,
      10,
      4,
      12,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "arc_easy": 0.48148148148148145,
      "arc_challenge": 0.24744027303754265,
      "boolq": 0.5608562691131499,
      "hellaswag": 0.3588926508663613,
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.226
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      8,
      16,
      10,
      6,
      2,
      10,
      14,
      2,
      4,
      6,
      8,
      16,
      2,
      12,
      12,
      14,
      2,
      6,
      6,
      4,
      14,
      4,
      12,
      14,
      10,
      12,
      4,
      16,
      10,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4890572390572391,
      "arc_challenge": 0.25,
      "hellaswag": 0.36068512248556067,
      "piqa": 0.6708378672470077,
      "boolq": 0.5418960244648318,
      "openbookqa": 0.226,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      16,
      8,
      14,
      8,
      4,
      6,
      10,
      12,
      10,
      10,
      4,
      12,
      16,
      16,
      12,
      8,
      8,
      4,
      14,
      14,
      16,
      16,
      2,
      14,
      14,
      12,
      10,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.368352917745469,
      "piqa": 0.6877040261153428,
      "openbookqa": 0.212,
      "winogrande": 0.5098658247829518,
      "arc_challenge": 0.2508532423208191,
      "arc_easy": 0.4398148148148148,
      "boolq": 0.47889908256880737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      10,
      8,
      6,
      4,
      2,
      14,
      8,
      8,
      12,
      14,
      6,
      12,
      4,
      4,
      14,
      4,
      4,
      4,
      6,
      4,
      4,
      14,
      2,
      2,
      4,
      8,
      2,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44865319865319864,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.25426621160409557,
      "boolq": 0.46055045871559636,
      "openbookqa": 0.222,
      "piqa": 0.6920565832426551,
      "hellaswag": 0.3712407886875124
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      14,
      14,
      6,
      10,
      6,
      14,
      10,
      10,
      6,
      12,
      4,
      6,
      12,
      8,
      6,
      4,
      12,
      14,
      8,
      8,
      16,
      6,
      2,
      8,
      10,
      4,
      10,
      16,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.484006734006734,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.516179952644041,
      "boolq": 0.5425076452599389,
      "openbookqa": 0.228,
      "hellaswag": 0.35919139613622786,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      8,
      8,
      12,
      16,
      4,
      8,
      16,
      16,
      6,
      6,
      16,
      4,
      6,
      4,
      6,
      8,
      8,
      6,
      2,
      14,
      14,
      16,
      10,
      8,
      10,
      8,
      10,
      12,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5712538226299694,
      "hellaswag": 0.35789683330013944,
      "openbookqa": 0.228,
      "arc_challenge": 0.2508532423208191,
      "arc_easy": 0.4764309764309764,
      "winogrande": 0.5146014206787688,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      12,
      10,
      10,
      2,
      6,
      8,
      16,
      2,
      6,
      4,
      16,
      4,
      2,
      2,
      14,
      14,
      14,
      8,
      6,
      14,
      16,
      12,
      10,
      12,
      16,
      6,
      8,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "winogrande": 0.5130228887134964,
      "piqa": 0.6887921653971708,
      "boolq": 0.4795107033639144,
      "arc_easy": 0.44654882154882153,
      "hellaswag": 0.37183827922724555,
      "arc_challenge": 0.25426621160409557
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      8,
      14,
      10,
      10,
      2,
      14,
      12,
      2,
      16,
      16,
      10,
      2,
      16,
      12,
      8,
      8,
      8,
      16,
      10,
      6,
      4,
      14,
      16,
      4,
      4,
      14,
      14,
      16,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25853242320819114,
      "boolq": 0.4581039755351682,
      "piqa": 0.6866158868335147,
      "arc_easy": 0.44276094276094274,
      "openbookqa": 0.22,
      "hellaswag": 0.3695478988249353,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      16,
      8,
      4,
      4,
      6,
      8,
      8,
      16,
      16,
      12,
      8,
      12,
      10,
      14,
      8,
      12,
      16,
      2,
      8,
      16,
      2,
      6,
      6,
      6,
      8,
      2,
      10,
      14,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3693487353116909,
      "arc_challenge": 0.25597269624573377,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.44654882154882153,
      "boolq": 0.4510703363914373,
      "piqa": 0.690968443960827,
      "openbookqa": 0.216
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      12,
      8,
      16,
      16,
      10,
      12,
      2,
      16,
      6,
      8,
      10,
      12,
      14,
      10,
      14,
      14,
      8,
      4,
      6,
      16,
      10,
      4,
      10,
      2,
      12,
      8,
      12,
      12,
      16,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.44617737003058106,
      "openbookqa": 0.226,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.3707428799044015,
      "arc_easy": 0.4414983164983165
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      16,
      2,
      4,
      4,
      14,
      2,
      8,
      6,
      16,
      8,
      16,
      14,
      16,
      10,
      2,
      4,
      16,
      10,
      6,
      10,
      4,
      14,
      12,
      16,
      16,
      14,
      12,
      2,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.257679180887372,
      "arc_easy": 0.44696969696969696,
      "boolq": 0.4620795107033639,
      "openbookqa": 0.216,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.3684524995020912
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      10,
      8,
      2,
      6,
      2,
      10,
      8,
      10,
      2,
      16,
      14,
      2,
      16,
      12,
      2,
      16,
      14,
      14,
      12,
      16,
      2,
      8,
      10,
      12,
      8,
      6,
      4,
      10,
      16,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.45454545454545453,
      "hellaswag": 0.37094204341764586,
      "arc_challenge": 0.2525597269624573,
      "piqa": 0.6931447225244831,
      "winogrande": 0.5209155485398579,
      "boolq": 0.48807339449541287,
      "openbookqa": 0.216
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      10,
      16,
      6,
      16,
      6,
      16,
      16,
      8,
      12,
      2,
      10,
      12,
      12,
      6,
      8,
      4,
      12,
      8,
      16,
      14,
      2,
      16,
      16,
      2,
      10,
      14,
      8,
      14,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "arc_challenge": 0.24914675767918087,
      "boolq": 0.5504587155963303,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.48274410774410775,
      "hellaswag": 0.35769766978689504
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      10,
      14,
      10,
      6,
      14,
      14,
      6,
      12,
      8,
      12,
      4,
      4,
      10,
      8,
      6,
      16,
      2,
      6,
      10,
      12,
      8,
      14,
      2,
      10,
      16,
      12,
      6,
      14,
      4,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5767584097859327,
      "hellaswag": 0.35909181437960563,
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.2431740614334471,
      "piqa": 0.6735582154515778
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      16,
      16,
      8,
      10,
      8,
      16,
      16,
      2,
      10,
      12,
      4,
      12,
      8,
      8,
      8,
      16,
      8,
      10,
      14,
      6,
      6,
      12,
      8,
      6,
      10,
      4,
      12,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "boolq": 0.5966360856269113,
      "piqa": 0.6708378672470077,
      "hellaswag": 0.360884285998805,
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.48653198653198654,
      "arc_challenge": 0.24744027303754265
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      12,
      12,
      14,
      12,
      2,
      12,
      12,
      2,
      14,
      12,
      4,
      16,
      2,
      16,
      12,
      16,
      14,
      12,
      6,
      16,
      16,
      14,
      16,
      16,
      12,
      10,
      12,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44991582491582494,
      "openbookqa": 0.22,
      "boolq": 0.4914373088685015,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.37064329814777935,
      "arc_challenge": 0.2551194539249147,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      10,
      4,
      10,
      16,
      12,
      8,
      6,
      4,
      4,
      14,
      14,
      10,
      10,
      8,
      16,
      10,
      4,
      16,
      10,
      14,
      14,
      4,
      4,
      4,
      14,
      2,
      10,
      16,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6789989118607181,
      "winogrande": 0.516179952644041,
      "arc_challenge": 0.24829351535836178,
      "boolq": 0.5672782874617737,
      "hellaswag": 0.3575980880302729,
      "arc_easy": 0.48484848484848486,
      "openbookqa": 0.226
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      4,
      12,
      8,
      6,
      16,
      16,
      8,
      8,
      16,
      12,
      16,
      10,
      2,
      6,
      16,
      10,
      2,
      14,
      4,
      8,
      2,
      6,
      14,
      12,
      4,
      4,
      2,
      4,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "boolq": 0.6033639143730887,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6735582154515778,
      "hellaswag": 0.36148177653853814,
      "winogrande": 0.5059194948697711,
      "arc_challenge": 0.2431740614334471
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      2,
      12,
      6,
      12,
      6,
      4,
      4,
      10,
      12,
      4,
      2,
      14,
      10,
      6,
      8,
      6,
      2,
      6,
      14,
      6,
      12,
      10,
      12,
      16,
      14,
      16,
      14,
      10,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "boolq": 0.4819571865443425,
      "arc_challenge": 0.24573378839590443,
      "arc_easy": 0.44486531986531985,
      "piqa": 0.6838955386289445,
      "openbookqa": 0.218,
      "hellaswag": 0.37054371639115713
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      6,
      2,
      2,
      4,
      2,
      6,
      2,
      4,
      14,
      16,
      16,
      12,
      14,
      14,
      12,
      4,
      12,
      12,
      14,
      14,
      8,
      4,
      2,
      8,
      8,
      4,
      10,
      2,
      6,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5244648318042814,
      "arc_easy": 0.44865319865319864,
      "openbookqa": 0.222,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6953210010881393,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.3707428799044015
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      4,
      8,
      12,
      4,
      12,
      10,
      12,
      14,
      16,
      12,
      4,
      4,
      12,
      2,
      2,
      6,
      12,
      14,
      6,
      6,
      6,
      2,
      8,
      10,
      8,
      14,
      6,
      6,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "winogrande": 0.5177584846093133,
      "hellaswag": 0.3617805218084047,
      "boolq": 0.5847094801223242,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.24573378839590443,
      "openbookqa": 0.23
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      14,
      10,
      10,
      12,
      4,
      6,
      4,
      14,
      10,
      4,
      14,
      14,
      2,
      12,
      8,
      10,
      2,
      14,
      10,
      4,
      2,
      10,
      16,
      14,
      4,
      10,
      8,
      4,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4308868501529052,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6936887921653971,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5074980268350434,
      "hellaswag": 0.3692491535550687,
      "openbookqa": 0.22
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      2,
      6,
      8,
      12,
      14,
      14,
      2,
      4,
      12,
      14,
      6,
      10,
      14,
      10,
      12,
      6,
      4,
      8,
      16,
      16,
      6,
      14,
      16,
      14,
      12,
      2,
      2,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6936887921653971,
      "openbookqa": 0.222,
      "hellaswag": 0.37114120693089026,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.43700305810397555,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5193370165745856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      16,
      8,
      12,
      6,
      8,
      8,
      6,
      4,
      14,
      8,
      8,
      4,
      16,
      6,
      14,
      16,
      2,
      4,
      12,
      2,
      10,
      4,
      2,
      16,
      14,
      12,
      6,
      12,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5935779816513761,
      "piqa": 0.6751904243743199,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.4823232323232323,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.224,
      "hellaswag": 0.36058554072893845
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      6,
      14,
      10,
      4,
      8,
      2,
      14,
      14,
      14,
      6,
      6,
      12,
      6,
      14,
      4,
      16,
      16,
      16,
      14,
      16,
      8,
      8,
      12,
      16,
      12,
      10,
      4,
      6,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.226,
      "boolq": 0.4908256880733945,
      "arc_challenge": 0.25170648464163825,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.4431818181818182,
      "hellaswag": 0.37024497112129057,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      4,
      6,
      2,
      4,
      12,
      10,
      2,
      10,
      2,
      2,
      14,
      12,
      4,
      4,
      10,
      6,
      12,
      6,
      10,
      16,
      8,
      8,
      4,
      4,
      12,
      14,
      16,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "winogrande": 0.5217048145224941,
      "piqa": 0.6887921653971708,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.37004580760804623,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.47186544342507647
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      12,
      12,
      6,
      12,
      16,
      12,
      2,
      4,
      16,
      2,
      14,
      8,
      10,
      14,
      4,
      4,
      8,
      8,
      6,
      10,
      14,
      16,
      8,
      4,
      8,
      4,
      2,
      12,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6681175190424374,
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.23,
      "hellaswag": 0.3599880501892053,
      "arc_easy": 0.49284511784511786,
      "boolq": 0.5807339449541284,
      "arc_challenge": 0.24914675767918087
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      4,
      12,
      14,
      14,
      8,
      4,
      8,
      10,
      8,
      14,
      8,
      16,
      6,
      6,
      14,
      6,
      10,
      12,
      10,
      8,
      6,
      14,
      10,
      16,
      14,
      2,
      12,
      2,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44991582491582494,
      "openbookqa": 0.216,
      "boolq": 0.499388379204893,
      "arc_challenge": 0.25,
      "hellaswag": 0.3707428799044015,
      "piqa": 0.6849836779107725,
      "winogrande": 0.5130228887134964
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      2,
      6,
      2,
      6,
      2,
      2,
      10,
      12,
      12,
      8,
      10,
      14,
      4,
      8,
      2,
      14,
      4,
      12,
      6,
      8,
      12,
      12,
      16,
      2,
      14,
      4,
      12,
      8,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5938837920489297,
      "hellaswag": 0.3584943238398725,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.24232081911262798,
      "openbookqa": 0.232,
      "arc_easy": 0.48484848484848486,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      8,
      2,
      10,
      12,
      12,
      12,
      10,
      12,
      2,
      10,
      6,
      16,
      12,
      8,
      10,
      14,
      4,
      16,
      4,
      12,
      8,
      10,
      8,
      4,
      8,
      6,
      6,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35829516032662817,
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.226,
      "piqa": 0.676822633297062,
      "arc_easy": 0.4797979797979798,
      "boolq": 0.563302752293578
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      4,
      14,
      16,
      4,
      10,
      4,
      16,
      4,
      2,
      6,
      14,
      4,
      6,
      12,
      12,
      14,
      14,
      14,
      6,
      4,
      10,
      2,
      10,
      16,
      6,
      6,
      10,
      6,
      6,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5709480122324159,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.4831649831649832,
      "openbookqa": 0.232,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.35839474208325034
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      12,
      2,
      6,
      2,
      10,
      8,
      6,
      12,
      16,
      4,
      14,
      4,
      14,
      16,
      8,
      4,
      6,
      12,
      2,
      2,
      14,
      2,
      12,
      8,
      8,
      16,
      12,
      12,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "hellaswag": 0.36008763194582755,
      "boolq": 0.5850152905198777,
      "openbookqa": 0.236,
      "piqa": 0.6741022850924918,
      "arc_challenge": 0.2508532423208191,
      "arc_easy": 0.48358585858585856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      8,
      10,
      12,
      8,
      10,
      16,
      16,
      16,
      6,
      14,
      6,
      16,
      10,
      16,
      16,
      10,
      6,
      2,
      10,
      16,
      4,
      8,
      12,
      16,
      4,
      10,
      14,
      4,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6773667029379761,
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.234,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.35988846843258315,
      "arc_challenge": 0.2525597269624573,
      "boolq": 0.5896024464831804
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      16,
      12,
      10,
      12,
      12,
      14,
      8,
      6,
      12,
      6,
      4,
      4,
      4,
      8,
      8,
      8,
      8,
      10,
      14,
      16,
      4,
      12,
      2,
      16,
      14,
      10,
      2,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4903198653198653,
      "arc_challenge": 0.24573378839590443,
      "openbookqa": 0.234,
      "boolq": 0.6003058103975535,
      "hellaswag": 0.35829516032662817,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      16,
      16,
      4,
      6,
      12,
      2,
      8,
      8,
      6,
      14,
      10,
      2,
      8,
      10,
      6,
      16,
      10,
      10,
      2,
      12,
      16,
      16,
      2,
      12,
      12,
      12,
      4,
      10,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.24829351535836178,
      "piqa": 0.6708378672470077,
      "boolq": 0.5697247706422018,
      "hellaswag": 0.3569010157339175,
      "openbookqa": 0.23,
      "arc_easy": 0.4903198653198653
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      14,
      4,
      14,
      4,
      8,
      8,
      14,
      2,
      6,
      14,
      10,
      4,
      4,
      14,
      12,
      6,
      8,
      10,
      14,
      12,
      16,
      8,
      16,
      4,
      16,
      2,
      16,
      6,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.3584943238398725,
      "arc_easy": 0.4810606060606061,
      "openbookqa": 0.222,
      "boolq": 0.5749235474006116
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      8,
      14,
      6,
      8,
      8,
      14,
      10,
      12,
      12,
      2,
      4,
      12,
      16,
      12,
      4,
      10,
      10,
      8,
      14,
      2,
      8,
      14,
      14,
      6,
      6,
      8,
      16,
      14,
      8,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4541284403669725,
      "hellaswag": 0.37054371639115713,
      "arc_easy": 0.44234006734006737,
      "winogrande": 0.5232833464877664,
      "piqa": 0.690968443960827,
      "openbookqa": 0.216,
      "arc_challenge": 0.2593856655290102
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      14,
      8,
      6,
      6,
      10,
      12,
      10,
      2,
      6,
      16,
      2,
      12,
      2,
      16,
      2,
      16,
      12,
      8,
      4,
      12,
      12,
      2,
      6,
      8,
      6,
      2,
      16,
      16,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.43027522935779816,
      "hellaswag": 0.3690499900418243,
      "arc_easy": 0.44907407407407407,
      "piqa": 0.690424374319913,
      "winogrande": 0.5177584846093133,
      "arc_challenge": 0.25426621160409557,
      "openbookqa": 0.22
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      2,
      4,
      10,
      2,
      12,
      12,
      12,
      14,
      6,
      14,
      12,
      16,
      16,
      16,
      14,
      14,
      10,
      12,
      4,
      4,
      4,
      10,
      12,
      8,
      4,
      12,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "openbookqa": 0.228,
      "boolq": 0.5697247706422018,
      "hellaswag": 0.3595897231627166,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.48653198653198654
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      6,
      6,
      14,
      10,
      6,
      14,
      12,
      12,
      4,
      6,
      12,
      6,
      4,
      16,
      16,
      8,
      10,
      6,
      14,
      14,
      14,
      12,
      16,
      12,
      14,
      4,
      8,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5003058103975535,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.3723361880103565,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      14,
      8,
      6,
      4,
      16,
      16,
      2,
      4,
      6,
      10,
      12,
      16,
      10,
      14,
      8,
      2,
      14,
      16,
      8,
      16,
      4,
      4,
      10,
      8,
      12,
      14,
      2,
      2,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6898803046789989,
      "boolq": 0.41162079510703364,
      "openbookqa": 0.226,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.37004580760804623
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      12,
      14,
      10,
      2,
      2,
      2,
      10,
      12,
      8,
      16,
      16,
      8,
      14,
      4,
      12,
      14,
      12,
      12,
      8,
      14,
      2,
      16,
      16,
      4,
      8,
      2,
      14,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.212,
      "arc_easy": 0.44612794612794615,
      "boolq": 0.4529051987767584,
      "arc_challenge": 0.25426621160409557,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.3708424616610237
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      10,
      14,
      14,
      12,
      2,
      16,
      14,
      16,
      6,
      14,
      2,
      4,
      6,
      14,
      6,
      2,
      12,
      12,
      14,
      4,
      2,
      16,
      4,
      2,
      14,
      4,
      4,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4478114478114478,
      "openbookqa": 0.222,
      "boolq": 0.42171253822629967,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.3694483170683131,
      "piqa": 0.6893362350380848,
      "arc_challenge": 0.2440273037542662
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      2,
      12,
      2,
      2,
      14,
      16,
      4,
      12,
      4,
      16,
      6,
      2,
      6,
      4,
      10,
      16,
      14,
      8,
      4,
      8,
      14,
      2,
      6,
      14,
      10,
      2,
      16,
      14,
      2,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35968930491933876,
      "boolq": 0.5311926605504587,
      "openbookqa": 0.236,
      "arc_easy": 0.48442760942760943,
      "piqa": 0.6702937976060935,
      "winogrande": 0.5248618784530387,
      "arc_challenge": 0.2440273037542662
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      4,
      12,
      2,
      10,
      8,
      10,
      10,
      14,
      16,
      2,
      10,
      8,
      4,
      12,
      12,
      16,
      16,
      12,
      10,
      4,
      10,
      2,
      4,
      8,
      14,
      6,
      2,
      12,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36058554072893845,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6713819368879217,
      "boolq": 0.590519877675841,
      "openbookqa": 0.23,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5217048145224941
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      12,
      6,
      16,
      6,
      12,
      6,
      16,
      4,
      14,
      4,
      4,
      6,
      2,
      10,
      16,
      14,
      14,
      4,
      6,
      6,
      10,
      14,
      16,
      14,
      6,
      16,
      2,
      8,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.40489296636085625,
      "winogrande": 0.5114443567482242,
      "hellaswag": 0.37054371639115713,
      "openbookqa": 0.224,
      "piqa": 0.6855277475516867,
      "arc_challenge": 0.25341296928327645,
      "arc_easy": 0.44107744107744107
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      2,
      4,
      12,
      4,
      2,
      8,
      14,
      10,
      12,
      16,
      10,
      8,
      14,
      16,
      2,
      12,
      14,
      6,
      8,
      4,
      14,
      8,
      10,
      4,
      2,
      6,
      8,
      10,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5090765588003157,
      "hellaswag": 0.35859390559649473,
      "arc_easy": 0.48484848484848486,
      "piqa": 0.6724700761697497,
      "arc_challenge": 0.2525597269624573,
      "boolq": 0.5941896024464832,
      "openbookqa": 0.238
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      14,
      2,
      6,
      14,
      4,
      12,
      12,
      4,
      12,
      2,
      14,
      12,
      6,
      14,
      12,
      2,
      8,
      14,
      2,
      6,
      4,
      8,
      2,
      6,
      8,
      4,
      10,
      14,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "winogrande": 0.5114443567482242,
      "arc_easy": 0.49284511784511786,
      "openbookqa": 0.228,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.3609838677554272,
      "boolq": 0.5715596330275229
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      4,
      2,
      12,
      12,
      16,
      16,
      12,
      8,
      2,
      16,
      16,
      6,
      2,
      6,
      12,
      2,
      16,
      2,
      2,
      10,
      6,
      8,
      6,
      4,
      4,
      6,
      8,
      2,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5138121546961326,
      "arc_easy": 0.48358585858585856,
      "boolq": 0.5883792048929664,
      "piqa": 0.6730141458106638,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.234,
      "hellaswag": 0.35879306910973907
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      6,
      2,
      16,
      10,
      12,
      12,
      10,
      8,
      12,
      16,
      14,
      8,
      10,
      14,
      2,
      8,
      8,
      8,
      2,
      2,
      16,
      8,
      14,
      4,
      4,
      10,
      6,
      10,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25341296928327645,
      "boolq": 0.4379204892966361,
      "hellaswag": 0.3703445528779128,
      "arc_easy": 0.4457070707070707,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.21
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      4,
      16,
      8,
      8,
      12,
      14,
      8,
      10,
      10,
      8,
      16,
      4,
      16,
      6,
      12,
      14,
      4,
      6,
      2,
      2,
      2,
      4,
      14,
      10,
      14,
      6,
      4,
      4,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6871599564744287,
      "openbookqa": 0.218,
      "boolq": 0.4834862385321101,
      "hellaswag": 0.37054371639115713,
      "arc_easy": 0.4414983164983165,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      14,
      16,
      16,
      16,
      8,
      14,
      10,
      10,
      14,
      16,
      16,
      8,
      14,
      6,
      2,
      14,
      12,
      12,
      8,
      12,
      16,
      12,
      12,
      16,
      10,
      8,
      16,
      2,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5177584846093133,
      "boolq": 0.45504587155963305,
      "hellaswag": 0.36984664409480184,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4377104377104377
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      10,
      10,
      12,
      16,
      2,
      6,
      2,
      16,
      6,
      10,
      10,
      2,
      12,
      12,
      2,
      6,
      10,
      12,
      14,
      16,
      2,
      12,
      10,
      16,
      4,
      8,
      16,
      12,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.460016835016835,
      "openbookqa": 0.214,
      "piqa": 0.6893362350380848,
      "winogrande": 0.5295974743488555,
      "hellaswag": 0.3708424616610237,
      "arc_challenge": 0.24744027303754265,
      "boolq": 0.44801223241590216
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      8,
      14,
      10,
      6,
      10,
      16,
      4,
      16,
      8,
      4,
      4,
      2,
      12,
      4,
      8,
      14,
      12,
      8,
      4,
      16,
      10,
      6,
      8,
      14,
      4,
      4,
      8,
      8,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3603863772156941,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.5886850152905199,
      "arc_challenge": 0.25341296928327645,
      "winogrande": 0.5059194948697711,
      "openbookqa": 0.228,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      8,
      16,
      16,
      14,
      12,
      8,
      14,
      16,
      12,
      16,
      4,
      4,
      10,
      6,
      4,
      2,
      12,
      2,
      14,
      12,
      2,
      6,
      10,
      10,
      14,
      14,
      10,
      12,
      16,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "winogrande": 0.5059194948697711,
      "arc_challenge": 0.24573378839590443,
      "hellaswag": 0.35988846843258315,
      "boolq": 0.590519877675841,
      "openbookqa": 0.23,
      "arc_easy": 0.48484848484848486
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      2,
      16,
      4,
      8,
      8,
      6,
      6,
      12,
      12,
      8,
      14,
      16,
      10,
      12,
      12,
      16,
      2,
      6,
      14,
      10,
      8,
      14,
      6,
      4,
      6,
      6,
      12,
      10,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25426621160409557,
      "openbookqa": 0.228,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.37054371639115713,
      "piqa": 0.6936887921653971,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.5103975535168196
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      4,
      10,
      6,
      8,
      16,
      14,
      14,
      12,
      14,
      10,
      8,
      12,
      6,
      4,
      10,
      2,
      6,
      8,
      14,
      14,
      4,
      12,
      4,
      10,
      6,
      2,
      14,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6887921653971708,
      "boolq": 0.4559633027522936,
      "openbookqa": 0.224,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.4431818181818182,
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.3712407886875124
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      14,
      4,
      14,
      14,
      2,
      14,
      10,
      4,
      16,
      16,
      8,
      14,
      4,
      10,
      12,
      2,
      14,
      8,
      16,
      12,
      4,
      2,
      8,
      12,
      12,
      8,
      10,
      14,
      2,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5877675840978593,
      "arc_easy": 0.4831649831649832,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.228,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.360884285998805,
      "piqa": 0.6681175190424374
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      10,
      12,
      12,
      6,
      2,
      8,
      12,
      6,
      4,
      2,
      12,
      6,
      8,
      16,
      6,
      16,
      2,
      4,
      6,
      6,
      12,
      8,
      10,
      2,
      14,
      8,
      16,
      14,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "openbookqa": 0.222,
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.3692491535550687,
      "boolq": 0.4730886850152905,
      "arc_challenge": 0.25853242320819114,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      8,
      6,
      4,
      4,
      2,
      12,
      4,
      6,
      14,
      2,
      10,
      8,
      10,
      12,
      2,
      12,
      10,
      16,
      4,
      6,
      16,
      8,
      6,
      2,
      12,
      2,
      2,
      16,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4802188552188552,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.36058554072893845,
      "openbookqa": 0.222,
      "piqa": 0.6702937976060935,
      "boolq": 0.5972477064220183,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      4,
      14,
      14,
      6,
      6,
      2,
      16,
      14,
      10,
      12,
      2,
      10,
      6,
      2,
      16,
      14,
      4,
      4,
      8,
      2,
      2,
      6,
      14,
      14,
      6,
      6,
      6,
      14,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3717386974706234,
      "arc_easy": 0.45075757575757575,
      "piqa": 0.6871599564744287,
      "boolq": 0.46299694189602447,
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.212
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      6,
      4,
      4,
      2,
      6,
      16,
      12,
      6,
      10,
      16,
      6,
      10,
      4,
      10,
      8,
      16,
      4,
      4,
      16,
      16,
      14,
      14,
      16,
      8,
      16,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24829351535836178,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.234,
      "winogrande": 0.5082872928176796,
      "boolq": 0.5847094801223242,
      "piqa": 0.676822633297062,
      "hellaswag": 0.36078470424218284
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      6,
      4,
      2,
      14,
      10,
      12,
      12,
      10,
      12,
      16,
      16,
      8,
      10,
      2,
      8,
      14,
      4,
      10,
      14,
      16,
      14,
      12,
      4,
      14,
      10,
      14,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5153906866614049,
      "openbookqa": 0.234,
      "hellaswag": 0.35929097789285,
      "boolq": 0.5798165137614679,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24744027303754265,
      "arc_easy": 0.47895622895622897
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      8,
      16,
      6,
      10,
      4,
      4,
      2,
      4,
      2,
      16,
      6,
      4,
      14,
      8,
      4,
      8,
      4,
      8,
      8,
      16,
      4,
      8,
      12,
      4,
      10,
      6,
      16,
      12,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.25853242320819114,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.3707428799044015,
      "piqa": 0.6942328618063112,
      "boolq": 0.4886850152905199,
      "openbookqa": 0.224
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      12,
      16,
      12,
      2,
      14,
      6,
      8,
      6,
      4,
      8,
      4,
      6,
      12,
      12,
      12,
      8,
      2,
      14,
      6,
      6,
      12,
      14,
      10,
      14,
      4,
      6,
      12,
      8,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.691512513601741,
      "hellaswag": 0.3690499900418243,
      "boolq": 0.4743119266055046,
      "openbookqa": 0.218,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5232833464877664,
      "arc_easy": 0.4452861952861953
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      2,
      16,
      16,
      12,
      6,
      4,
      2,
      8,
      8,
      2,
      8,
      4,
      4,
      4,
      10,
      6,
      10,
      4,
      14,
      4,
      2,
      10,
      4,
      6,
      6,
      8,
      6,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5837920489296636,
      "arc_easy": 0.47853535353535354,
      "openbookqa": 0.234,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.3594901414060944,
      "piqa": 0.6686615886833515,
      "arc_challenge": 0.23890784982935154
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      6,
      14,
      2,
      6,
      14,
      8,
      8,
      2,
      14,
      10,
      14,
      10,
      2,
      4,
      12,
      8,
      2,
      14,
      12,
      6,
      14,
      2,
      16,
      12,
      10,
      8,
      6,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24573378839590443,
      "piqa": 0.6735582154515778,
      "hellaswag": 0.3594901414060944,
      "openbookqa": 0.226,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.4911616161616162,
      "boolq": 0.5969418960244648
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      16,
      6,
      8,
      4,
      6,
      16,
      4,
      16,
      4,
      6,
      4,
      14,
      8,
      4,
      2,
      6,
      8,
      6,
      14,
      6,
      10,
      6,
      12,
      12,
      8,
      2,
      14,
      2,
      8,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.222,
      "arc_easy": 0.45580808080808083,
      "boolq": 0.4831804281345566,
      "piqa": 0.691512513601741,
      "hellaswag": 0.3695478988249353,
      "arc_challenge": 0.25170648464163825,
      "winogrande": 0.5169692186266772
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      16,
      2,
      16,
      14,
      14,
      10,
      12,
      2,
      16,
      8,
      8,
      2,
      4,
      4,
      4,
      8,
      4,
      14,
      16,
      16,
      4,
      6,
      14,
      4,
      12,
      8,
      4,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3694483170683131,
      "arc_challenge": 0.25597269624573377,
      "openbookqa": 0.214,
      "arc_easy": 0.4436026936026936,
      "piqa": 0.6931447225244831,
      "winogrande": 0.5146014206787688,
      "boolq": 0.4840978593272171
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      2,
      6,
      2,
      14,
      4,
      12,
      16,
      8,
      2,
      16,
      8,
      12,
      2,
      4,
      14,
      16,
      14,
      6,
      2,
      14,
      14,
      6,
      16,
      8,
      6,
      4,
      8,
      12,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25597269624573377,
      "winogrande": 0.5224940805051302,
      "arc_easy": 0.4503367003367003,
      "hellaswag": 0.37273451503684524,
      "piqa": 0.6871599564744287,
      "openbookqa": 0.222,
      "boolq": 0.4636085626911315
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      4,
      2,
      16,
      2,
      2,
      6,
      12,
      8,
      10,
      6,
      2,
      14,
      14,
      10,
      10,
      10,
      8,
      8,
      14,
      8,
      14,
      10,
      8,
      8,
      6,
      2,
      16,
      14,
      16,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44107744107744107,
      "boolq": 0.41804281345565747,
      "winogrande": 0.5209155485398579,
      "piqa": 0.6871599564744287,
      "openbookqa": 0.222,
      "hellaswag": 0.37094204341764586,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      2,
      2,
      12,
      4,
      14,
      2,
      10,
      14,
      6,
      16,
      8,
      12,
      6,
      10,
      8,
      10,
      10,
      8,
      2,
      2,
      2,
      16,
      6,
      10,
      12,
      10,
      14,
      2,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "hellaswag": 0.359788886675961,
      "piqa": 0.6730141458106638,
      "boolq": 0.5840978593272171,
      "openbookqa": 0.228,
      "arc_easy": 0.48358585858585856,
      "arc_challenge": 0.25
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      4,
      16,
      16,
      16,
      8,
      6,
      8,
      10,
      8,
      14,
      10,
      16,
      16,
      8,
      16,
      14,
      14,
      14,
      8,
      14,
      2,
      10,
      16,
      10,
      12,
      2,
      12,
      8,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6055045871559633,
      "arc_easy": 0.4831649831649832,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24488054607508533,
      "hellaswag": 0.359788886675961,
      "winogrande": 0.5138121546961326,
      "openbookqa": 0.24
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      6,
      6,
      6,
      12,
      12,
      6,
      16,
      16,
      6,
      12,
      10,
      6,
      12,
      6,
      4,
      6,
      8,
      6,
      8,
      14,
      12,
      8,
      4,
      10,
      4,
      6,
      14,
      10,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25,
      "piqa": 0.6882480957562568,
      "hellaswag": 0.3686516630153356,
      "openbookqa": 0.218,
      "winogrande": 0.5209155485398579,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.46116207951070337
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      6,
      10,
      10,
      16,
      14,
      8,
      6,
      4,
      8,
      2,
      8,
      6,
      14,
      16,
      8,
      14,
      4,
      4,
      16,
      8,
      4,
      2,
      10,
      12,
      16,
      2,
      6,
      8,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3694483170683131,
      "boolq": 0.47889908256880737,
      "openbookqa": 0.218,
      "winogrande": 0.516179952644041,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4574915824915825,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      10,
      2,
      12,
      4,
      6,
      12,
      2,
      8,
      12,
      16,
      8,
      8,
      10,
      14,
      14,
      16,
      16,
      4,
      16,
      6,
      12,
      6,
      8,
      2,
      8,
      14,
      2,
      14,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.23,
      "arc_easy": 0.48737373737373735,
      "piqa": 0.6730141458106638,
      "boolq": 0.5749235474006116,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.3588926508663613,
      "arc_challenge": 0.24488054607508533
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      6,
      16,
      4,
      12,
      12,
      14,
      8,
      12,
      16,
      2,
      4,
      10,
      16,
      8,
      10,
      10,
      16,
      12,
      8,
      2,
      8,
      4,
      6,
      8,
      16,
      10,
      2,
      4,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "boolq": 0.46452599388379207,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.44191919191919193,
      "hellaswag": 0.3677554272057359,
      "arc_challenge": 0.25853242320819114,
      "winogrande": 0.5232833464877664
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      8,
      14,
      4,
      4,
      6,
      6,
      2,
      16,
      8,
      12,
      10,
      4,
      12,
      8,
      2,
      4,
      12,
      2,
      8,
      4,
      14,
      10,
      16,
      2,
      12,
      8,
      4,
      12,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35899223262298346,
      "arc_easy": 0.49158249158249157,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.232,
      "boolq": 0.5669724770642202,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      14,
      12,
      16,
      16,
      2,
      6,
      4,
      10,
      2,
      6,
      8,
      16,
      16,
      6,
      16,
      10,
      16,
      2,
      6,
      16,
      12,
      2,
      4,
      2,
      10,
      6,
      2,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.544954128440367,
      "winogrande": 0.5082872928176796,
      "arc_challenge": 0.24488054607508533,
      "openbookqa": 0.236,
      "hellaswag": 0.3604859589723163,
      "arc_easy": 0.4797979797979798,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      4,
      12,
      12,
      16,
      12,
      12,
      2,
      2,
      4,
      4,
      4,
      14,
      16,
      10,
      14,
      14,
      10,
      10,
      2,
      10,
      6,
      12,
      10,
      4,
      8,
      14,
      6,
      6,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5889908256880734,
      "hellaswag": 0.35899223262298346,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.2568259385665529,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6713819368879217,
      "openbookqa": 0.23
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      10,
      14,
      10,
      8,
      14,
      2,
      6,
      4,
      12,
      6,
      10,
      16,
      14,
      8,
      12,
      10,
      10,
      12,
      8,
      8,
      14,
      14,
      12,
      8,
      8,
      16,
      6,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "hellaswag": 0.3593905596494722,
      "boolq": 0.5678899082568807,
      "openbookqa": 0.238,
      "arc_easy": 0.48148148148148145,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.25
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      16,
      6,
      4,
      12,
      8,
      14,
      10,
      8,
      4,
      4,
      6,
      4,
      8,
      16,
      14,
      14,
      10,
      8,
      2,
      2,
      14,
      12,
      16,
      16,
      2,
      6,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "boolq": 0.46238532110091746,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.3694483170683131,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.44907407407407407,
      "piqa": 0.6936887921653971
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      14,
      10,
      8,
      6,
      8,
      2,
      2,
      6,
      12,
      12,
      6,
      14,
      8,
      6,
      8,
      12,
      14,
      2,
      2,
      8,
      8,
      2,
      12,
      16,
      8,
      16,
      14,
      8,
      2,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3707428799044015,
      "winogrande": 0.5090765588003157,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.44865319865319864,
      "openbookqa": 0.214,
      "boolq": 0.46452599388379207,
      "arc_challenge": 0.2568259385665529
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      2,
      2,
      8,
      16,
      14,
      10,
      10,
      8,
      4,
      10,
      16,
      16,
      4,
      2,
      12,
      16,
      6,
      12,
      8,
      10,
      14,
      8,
      12,
      2,
      2,
      10,
      10,
      16,
      14,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "piqa": 0.6719260065288357,
      "hellaswag": 0.3601872137024497,
      "boolq": 0.5966360856269113,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.49074074074074076,
      "arc_challenge": 0.24914675767918087
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      12,
      4,
      8,
      12,
      4,
      14,
      12,
      6,
      2,
      14,
      6,
      4,
      12,
      10,
      4,
      12,
      16,
      12,
      14,
      10,
      16,
      4,
      8,
      14,
      12,
      12,
      6,
      6,
      4,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "openbookqa": 0.23,
      "arc_easy": 0.4802188552188552,
      "boolq": 0.5902140672782875,
      "piqa": 0.6719260065288357,
      "hellaswag": 0.35919139613622786,
      "arc_challenge": 0.2431740614334471
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      4,
      12,
      4,
      6,
      10,
      14,
      10,
      4,
      2,
      4,
      14,
      12,
      10,
      6,
      10,
      4,
      16,
      2,
      8,
      16,
      12,
      8,
      4,
      2,
      12,
      8,
      2,
      4,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6103975535168196,
      "piqa": 0.6708378672470077,
      "arc_easy": 0.4797979797979798,
      "hellaswag": 0.3593905596494722,
      "openbookqa": 0.236,
      "arc_challenge": 0.24488054607508533,
      "winogrande": 0.5090765588003157
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      10,
      12,
      4,
      4,
      6,
      16,
      12,
      12,
      14,
      8,
      12,
      10,
      12,
      14,
      16,
      16,
      2,
      12,
      4,
      10,
      8,
      6,
      2,
      6,
      8,
      10,
      16,
      4,
      2,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6730141458106638,
      "arc_easy": 0.47769360269360267,
      "boolq": 0.5758409785932722,
      "openbookqa": 0.234,
      "arc_challenge": 0.25597269624573377,
      "hellaswag": 0.35839474208325034,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      10,
      14,
      8,
      4,
      6,
      8,
      12,
      10,
      6,
      12,
      4,
      12,
      4,
      4,
      12,
      4,
      16,
      16,
      12,
      6,
      10,
      16,
      8,
      14,
      4,
      8,
      8,
      6,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5440366972477064,
      "openbookqa": 0.238,
      "hellaswag": 0.3586934873531169,
      "arc_challenge": 0.2440273037542662,
      "arc_easy": 0.4852693602693603,
      "piqa": 0.6746463547334058,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      16,
      12,
      2,
      12,
      2,
      8,
      2,
      14,
      6,
      10,
      16,
      12,
      12,
      16,
      6,
      6,
      16,
      6,
      4,
      2,
      4,
      8,
      10,
      8,
      14,
      8,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "piqa": 0.676822633297062,
      "arc_easy": 0.48863636363636365,
      "hellaswag": 0.3580959968133838,
      "boolq": 0.5388379204892967,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5248618784530387
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      4,
      6,
      14,
      8,
      4,
      14,
      4,
      10,
      4,
      14,
      2,
      14,
      14,
      6,
      6,
      16,
      10,
      12,
      12,
      2,
      8,
      4,
      10,
      12,
      12,
      2,
      16,
      8,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24829351535836178,
      "winogrande": 0.5248618784530387,
      "openbookqa": 0.22,
      "piqa": 0.6926006528835691,
      "hellaswag": 0.37024497112129057,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.46605504587155966
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      4,
      14,
      14,
      2,
      10,
      14,
      6,
      4,
      10,
      14,
      6,
      6,
      14,
      2,
      16,
      4,
      10,
      16,
      6,
      10,
      2,
      10,
      10,
      16,
      10,
      8,
      2,
      12,
      6,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35859390559649473,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.2508532423208191,
      "arc_easy": 0.4890572390572391,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.228,
      "boolq": 0.5758409785932722
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      4,
      4,
      10,
      2,
      14,
      14,
      16,
      2,
      12,
      12,
      10,
      4,
      12,
      10,
      6,
      14,
      10,
      6,
      14,
      16,
      2,
      6,
      10,
      12,
      16,
      2,
      10,
      8,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3710416251742681,
      "boolq": 0.4437308868501529,
      "piqa": 0.6877040261153428,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.21,
      "arc_challenge": 0.2525597269624573,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      8,
      14,
      12,
      12,
      12,
      2,
      6,
      10,
      16,
      6,
      2,
      14,
      16,
      12,
      10,
      4,
      16,
      16,
      14,
      14,
      16,
      16,
      8,
      4,
      16,
      8,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.3714399522007568,
      "arc_challenge": 0.25170648464163825,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4444444444444444,
      "openbookqa": 0.214,
      "boolq": 0.47553516819571867
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      16,
      6,
      8,
      2,
      10,
      12,
      10,
      8,
      8,
      4,
      16,
      8,
      2,
      14,
      16,
      10,
      14,
      2,
      12,
      10,
      12,
      16,
      12,
      16,
      8,
      14,
      4,
      2,
      8,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5984709480122324,
      "piqa": 0.676822633297062,
      "arc_challenge": 0.24573378839590443,
      "hellaswag": 0.35769766978689504,
      "arc_easy": 0.48148148148148145,
      "openbookqa": 0.224,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      12,
      16,
      16,
      14,
      6,
      4,
      2,
      6,
      10,
      8,
      6,
      14,
      14,
      12,
      10,
      12,
      6,
      2,
      4,
      14,
      16,
      10,
      16,
      4,
      4,
      6,
      4,
      14,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "piqa": 0.6719260065288357,
      "arc_challenge": 0.26023890784982934,
      "arc_easy": 0.4852693602693603,
      "hellaswag": 0.3615813582951603,
      "openbookqa": 0.23,
      "boolq": 0.6067278287461774
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      2,
      10,
      6,
      4,
      16,
      10,
      12,
      12,
      8,
      16,
      12,
      14,
      16,
      4,
      14,
      10,
      14,
      10,
      4,
      12,
      2,
      14,
      10,
      16,
      4,
      4,
      10,
      16,
      10,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3579964150567616,
      "arc_easy": 0.48695286195286197,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.25,
      "piqa": 0.6741022850924918,
      "boolq": 0.5865443425076453,
      "openbookqa": 0.24
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      12,
      16,
      10,
      14,
      4,
      2,
      12,
      4,
      16,
      12,
      14,
      12,
      16,
      8,
      16,
      2,
      4,
      4,
      8,
      2,
      12,
      16,
      16,
      8,
      4,
      10,
      4,
      2,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.25,
      "boolq": 0.47339449541284406,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.216,
      "hellaswag": 0.3717386974706234,
      "arc_easy": 0.4398148148148148
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      4,
      4,
      12,
      6,
      16,
      12,
      6,
      14,
      4,
      12,
      2,
      10,
      8,
      16,
      14,
      10,
      6,
      6,
      4,
      2,
      8,
      2,
      10,
      10,
      4,
      4,
      10,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6882480957562568,
      "hellaswag": 0.37004580760804623,
      "openbookqa": 0.216,
      "arc_challenge": 0.2551194539249147,
      "arc_easy": 0.45202020202020204,
      "boolq": 0.5244648318042814,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      16,
      4,
      10,
      16,
      14,
      12,
      14,
      4,
      4,
      16,
      12,
      10,
      14,
      14,
      2,
      4,
      16,
      14,
      10,
      10,
      6,
      16,
      8,
      8,
      16,
      14,
      16,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4793771043771044,
      "hellaswag": 0.3593905596494722,
      "openbookqa": 0.232,
      "winogrande": 0.516179952644041,
      "piqa": 0.6735582154515778,
      "arc_challenge": 0.24744027303754265,
      "boolq": 0.5801223241590214
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      14,
      14,
      8,
      12,
      8,
      4,
      14,
      2,
      6,
      10,
      10,
      12,
      10,
      16,
      8,
      8,
      4,
      8,
      6,
      4,
      8,
      4,
      8,
      4,
      10,
      12,
      12,
      2,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24488054607508533,
      "piqa": 0.6741022850924918,
      "openbookqa": 0.236,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5932721712538226,
      "hellaswag": 0.3575980880302729
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      12,
      4,
      14,
      16,
      12,
      4,
      12,
      14,
      4,
      14,
      16,
      4,
      10,
      14,
      12,
      6,
      12,
      12,
      12,
      10,
      8,
      4,
      12,
      14,
      6,
      14,
      2,
      4,
      14,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3586934873531169,
      "boolq": 0.6110091743119266,
      "openbookqa": 0.234,
      "arc_challenge": 0.2440273037542662,
      "piqa": 0.6746463547334058,
      "arc_easy": 0.4793771043771044,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      6,
      4,
      6,
      2,
      2,
      6,
      6,
      8,
      10,
      8,
      10,
      16,
      16,
      8,
      8,
      4,
      16,
      8,
      6,
      6,
      8,
      2,
      2,
      10,
      16,
      2,
      6,
      14,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5248618784530387,
      "arc_easy": 0.44276094276094274,
      "hellaswag": 0.3701453893646684,
      "piqa": 0.6866158868335147,
      "boolq": 0.4577981651376147,
      "openbookqa": 0.216,
      "arc_challenge": 0.2525597269624573
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      16,
      14,
      16,
      14,
      8,
      4,
      14,
      14,
      6,
      8,
      14,
      6,
      16,
      12,
      8,
      12,
      14,
      10,
      2,
      2,
      4,
      12,
      4,
      10,
      16,
      2,
      2,
      12,
      16,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6697497279651795,
      "arc_easy": 0.48063973063973064,
      "hellaswag": 0.3579964150567616,
      "arc_challenge": 0.24829351535836178,
      "boolq": 0.6085626911314985,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.234
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      4,
      10,
      10,
      4,
      10,
      8,
      12,
      8,
      8,
      2,
      4,
      14,
      6,
      16,
      4,
      4,
      14,
      16,
      16,
      10,
      8,
      4,
      8,
      10,
      10,
      8,
      8,
      8,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6702937976060935,
      "boolq": 0.5844036697247706,
      "arc_challenge": 0.2508532423208191,
      "hellaswag": 0.3577972515435172,
      "openbookqa": 0.236,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      4,
      10,
      6,
      8,
      16,
      4,
      2,
      6,
      16,
      4,
      6,
      2,
      4,
      8,
      16,
      4,
      6,
      8,
      16,
      2,
      16,
      14,
      14,
      8,
      10,
      6,
      12,
      4,
      4,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "boolq": 0.4672782874617737,
      "winogrande": 0.5232833464877664,
      "piqa": 0.690424374319913,
      "openbookqa": 0.218,
      "hellaswag": 0.3692491535550687,
      "arc_challenge": 0.24232081911262798
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      10,
      2,
      6,
      10,
      14,
      12,
      10,
      4,
      8,
      6,
      8,
      10,
      14,
      14,
      16,
      8,
      14,
      10,
      10,
      2,
      2,
      14,
      12,
      2,
      16,
      14,
      16,
      8,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4776758409785933,
      "arc_easy": 0.44191919191919193,
      "hellaswag": 0.3695478988249353,
      "winogrande": 0.5098658247829518,
      "arc_challenge": 0.24829351535836178,
      "piqa": 0.690424374319913,
      "openbookqa": 0.228
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      14,
      12,
      4,
      2,
      10,
      8,
      6,
      6,
      2,
      10,
      2,
      16,
      10,
      14,
      14,
      4,
      2,
      8,
      8,
      6,
      14,
      10,
      12,
      2,
      6,
      2,
      14,
      4,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48695286195286197,
      "winogrande": 0.516179952644041,
      "piqa": 0.6719260065288357,
      "openbookqa": 0.234,
      "boolq": 0.5941896024464832,
      "arc_challenge": 0.24744027303754265,
      "hellaswag": 0.3603863772156941
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      10,
      10,
      16,
      2,
      14,
      14,
      8,
      12,
      6,
      4,
      12,
      16,
      12,
      10,
      6,
      12,
      4,
      12,
      16,
      14,
      16,
      12,
      4,
      14,
      8,
      6,
      4,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5944954128440367,
      "openbookqa": 0.236,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6686615886833515,
      "arc_easy": 0.48358585858585856,
      "hellaswag": 0.3577972515435172,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      2,
      10,
      14,
      14,
      6,
      8,
      10,
      10,
      16,
      8,
      2,
      2,
      12,
      10,
      6,
      10,
      16,
      12,
      10,
      2,
      12,
      16,
      2,
      12,
      4,
      2,
      6,
      2,
      10,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4457070707070707,
      "arc_challenge": 0.24829351535836178,
      "piqa": 0.6936887921653971,
      "openbookqa": 0.22,
      "hellaswag": 0.3701453893646684,
      "boolq": 0.42844036697247706,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      4,
      2,
      12,
      6,
      8,
      16,
      16,
      8,
      4,
      12,
      10,
      16,
      8,
      6,
      2,
      10,
      16,
      16,
      14,
      8,
      14,
      10,
      4,
      14,
      14,
      14,
      2,
      2,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.222,
      "arc_challenge": 0.25341296928327645,
      "arc_easy": 0.4444444444444444,
      "hellaswag": 0.37004580760804623,
      "boolq": 0.4415902140672783,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      4,
      6,
      2,
      6,
      14,
      10,
      12,
      2,
      14,
      12,
      6,
      6,
      6,
      8,
      8,
      10,
      16,
      4,
      10,
      12,
      8,
      8,
      10,
      8,
      10,
      10,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37024497112129057,
      "arc_challenge": 0.2525597269624573,
      "piqa": 0.6898803046789989,
      "boolq": 0.44464831804281346,
      "openbookqa": 0.218,
      "winogrande": 0.5288082083662194,
      "arc_easy": 0.4457070707070707
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      12,
      10,
      6,
      16,
      6,
      14,
      14,
      6,
      2,
      12,
      6,
      10,
      2,
      14,
      6,
      12,
      14,
      16,
      10,
      8,
      6,
      14,
      10,
      12,
      10,
      4,
      6,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4823232323232323,
      "boolq": 0.5804281345565749,
      "arc_challenge": 0.2525597269624573,
      "hellaswag": 0.35909181437960563,
      "openbookqa": 0.224,
      "piqa": 0.6719260065288357,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      2,
      16,
      6,
      14,
      10,
      12,
      8,
      4,
      4,
      6,
      6,
      10,
      4,
      8,
      14,
      14,
      10,
      8,
      4,
      14,
      8,
      6,
      6,
      4,
      2,
      8,
      6,
      14,
      6,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.3610834495120494,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5908256880733945,
      "openbookqa": 0.226,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5098658247829518
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      4,
      2,
      4,
      16,
      12,
      10,
      10,
      2,
      6,
      14,
      12,
      14,
      4,
      4,
      12,
      16,
      2,
      6,
      2,
      16,
      12,
      16,
      12,
      16,
      8,
      8,
      4,
      12,
      6,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3601872137024497,
      "arc_easy": 0.48863636363636365,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6730141458106638,
      "boolq": 0.5951070336391437,
      "openbookqa": 0.234
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      12,
      2,
      2,
      2,
      10,
      8,
      10,
      2,
      8,
      14,
      16,
      6,
      6,
      8,
      12,
      8,
      10,
      16,
      12,
      10,
      4,
      6,
      4,
      16,
      12,
      10,
      2,
      10,
      12,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6942328618063112,
      "arc_challenge": 0.26023890784982934,
      "openbookqa": 0.212,
      "hellaswag": 0.3707428799044015,
      "boolq": 0.45535168195718656,
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      16,
      6,
      16,
      10,
      4,
      10,
      4,
      8,
      14,
      2,
      8,
      10,
      2,
      16,
      4,
      12,
      16,
      16,
      8,
      6,
      4,
      10,
      16,
      2,
      2,
      2,
      12,
      8,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2568259385665529,
      "boolq": 0.42110091743119266,
      "arc_easy": 0.43897306397306396,
      "piqa": 0.6942328618063112,
      "openbookqa": 0.224,
      "hellaswag": 0.371539533957379,
      "winogrande": 0.5185477505919495
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      6,
      4,
      14,
      14,
      16,
      12,
      8,
      6,
      2,
      6,
      10,
      4,
      6,
      6,
      2,
      14,
      8,
      14,
      6,
      4,
      10,
      6,
      12,
      14,
      16,
      14,
      4,
      10,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "winogrande": 0.5177584846093133,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6686615886833515,
      "hellaswag": 0.36058554072893845,
      "boolq": 0.5767584097859327,
      "arc_challenge": 0.25341296928327645
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      8,
      16,
      12,
      12,
      4,
      16,
      6,
      4,
      6,
      16,
      16,
      4,
      14,
      12,
      4,
      4,
      4,
      8,
      14,
      4,
      6,
      6,
      6,
      4,
      14,
      2,
      12,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35839474208325034,
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6730141458106638,
      "arc_challenge": 0.24829351535836178,
      "openbookqa": 0.23,
      "winogrande": 0.5217048145224941,
      "boolq": 0.5880733944954128
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      4,
      4,
      10,
      2,
      14,
      6,
      6,
      4,
      10,
      2,
      4,
      10,
      10,
      8,
      8,
      14,
      12,
      8,
      4,
      12,
      8,
      12,
      12,
      10,
      2,
      12,
      6,
      6,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.236,
      "boolq": 0.581039755351682,
      "hellaswag": 0.35968930491933876,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.48148148148148145
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      4,
      14,
      8,
      12,
      2,
      4,
      2,
      14,
      10,
      14,
      6,
      8,
      12,
      8,
      12,
      8,
      14,
      14,
      10,
      10,
      14,
      10,
      10,
      12,
      10,
      4,
      2,
      12,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5862385321100917,
      "hellaswag": 0.3588926508663613,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.236,
      "arc_easy": 0.4890572390572391
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      2,
      10,
      14,
      12,
      12,
      8,
      8,
      4,
      14,
      16,
      8,
      16,
      4,
      2,
      12,
      14,
      12,
      12,
      10,
      6,
      2,
      8,
      8,
      8,
      6,
      16,
      10,
      10,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6708378672470077,
      "hellaswag": 0.35909181437960563,
      "arc_easy": 0.4852693602693603,
      "openbookqa": 0.238,
      "winogrande": 0.5201262825572218,
      "boolq": 0.590519877675841,
      "arc_challenge": 0.25597269624573377
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      8,
      12,
      6,
      12,
      2,
      14,
      4,
      10,
      6,
      8,
      10,
      14,
      6,
      8,
      8,
      2,
      10,
      4,
      14,
      12,
      16,
      12,
      10,
      16,
      4,
      14,
      10,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6920565832426551,
      "winogrande": 0.5201262825572218,
      "arc_easy": 0.4473905723905724,
      "arc_challenge": 0.25426621160409557,
      "boolq": 0.47553516819571867,
      "openbookqa": 0.22,
      "hellaswag": 0.36974706233817967
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      4,
      14,
      10,
      16,
      4,
      8,
      14,
      6,
      10,
      14,
      2,
      16,
      14,
      2,
      2,
      6,
      6,
      8,
      16,
      4,
      12,
      8,
      10,
      6,
      8,
      4,
      14,
      14,
      6,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5009174311926605,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6866158868335147,
      "hellaswag": 0.3707428799044015,
      "arc_challenge": 0.2551194539249147,
      "arc_easy": 0.4478114478114478,
      "openbookqa": 0.222
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      2,
      16,
      6,
      4,
      16,
      8,
      6,
      6,
      6,
      6,
      2,
      10,
      12,
      16,
      8,
      4,
      8,
      12,
      2,
      16,
      16,
      6,
      6,
      14,
      2,
      4,
      4,
      14,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6860718171926007,
      "winogrande": 0.5146014206787688,
      "boolq": 0.445565749235474,
      "arc_challenge": 0.2593856655290102,
      "hellaswag": 0.3717386974706234,
      "openbookqa": 0.22,
      "arc_easy": 0.4524410774410774
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      12,
      10,
      4,
      12,
      8,
      14,
      4,
      8,
      2,
      12,
      12,
      10,
      14,
      2,
      2,
      8,
      10,
      12,
      6,
      12,
      10,
      6,
      6,
      6,
      6,
      8,
      16,
      8,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.37183827922724555,
      "openbookqa": 0.218,
      "piqa": 0.690968443960827,
      "arc_challenge": 0.25170648464163825,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.41987767584097857,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      2,
      16,
      12,
      8,
      6,
      16,
      14,
      6,
      16,
      8,
      12,
      14,
      8,
      16,
      8,
      6,
      8,
      16,
      4,
      10,
      10,
      6,
      8,
      16,
      4,
      16,
      16,
      12,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5694189602446483,
      "arc_challenge": 0.24744027303754265,
      "hellaswag": 0.35859390559649473,
      "winogrande": 0.5074980268350434,
      "openbookqa": 0.23,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.49452861952861954
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      8,
      8,
      8,
      6,
      4,
      6,
      10,
      6,
      12,
      8,
      14,
      2,
      6,
      6,
      2,
      6,
      14,
      6,
      8,
      6,
      16,
      6,
      8,
      14,
      2,
      4,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24658703071672355,
      "hellaswag": 0.3579964150567616,
      "openbookqa": 0.234,
      "boolq": 0.5874617737003058,
      "piqa": 0.675734494015234,
      "arc_easy": 0.49242424242424243,
      "winogrande": 0.5217048145224941
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      16,
      2,
      6,
      12,
      14,
      12,
      12,
      14,
      6,
      16,
      10,
      16,
      16,
      2,
      2,
      10,
      2,
      8,
      4,
      6,
      12,
      4,
      6,
      10,
      16,
      12,
      12,
      16,
      12,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35909181437960563,
      "openbookqa": 0.228,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.5844036697247706,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6719260065288357,
      "arc_easy": 0.48863636363636365
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      8,
      2,
      6,
      12,
      10,
      14,
      12,
      10,
      12,
      16,
      12,
      8,
      12,
      2,
      2,
      10,
      2,
      16,
      6,
      2,
      12,
      10,
      4,
      2,
      16,
      12,
      14,
      14,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24914675767918087,
      "piqa": 0.6855277475516867,
      "openbookqa": 0.224,
      "arc_easy": 0.44234006734006737,
      "boolq": 0.4706422018348624,
      "winogrande": 0.5224940805051302,
      "hellaswag": 0.3694483170683131
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      6,
      4,
      16,
      10,
      4,
      12,
      8,
      4,
      2,
      16,
      12,
      2,
      16,
      10,
      6,
      12,
      14,
      2,
      6,
      8,
      8,
      6,
      8,
      14,
      2,
      10,
      16,
      4,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.45749235474006117,
      "hellaswag": 0.3701453893646684,
      "arc_challenge": 0.25341296928327645,
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.526440410418311,
      "openbookqa": 0.214
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      16,
      6,
      6,
      14,
      14,
      12,
      8,
      16,
      12,
      14,
      8,
      4,
      2,
      8,
      10,
      14,
      2,
      6,
      10,
      12,
      4,
      4,
      6,
      4,
      16,
      16,
      8,
      16,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4861111111111111,
      "openbookqa": 0.228,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6773667029379761,
      "boolq": 0.5792048929663609,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3571001792471619
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      12,
      12,
      12,
      2,
      16,
      6,
      2,
      12,
      16,
      2,
      12,
      2,
      14,
      12,
      6,
      14,
      4,
      8,
      4,
      4,
      6,
      6,
      16,
      4,
      4,
      6,
      10,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "piqa": 0.6877040261153428,
      "arc_easy": 0.4515993265993266,
      "hellaswag": 0.37044413463453496,
      "boolq": 0.42201834862385323,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      14,
      12,
      16,
      16,
      6,
      16,
      8,
      14,
      16,
      4,
      6,
      10,
      16,
      14,
      8,
      12,
      6,
      14,
      4,
      4,
      12,
      14,
      16,
      6,
      2,
      12,
      2,
      2,
      14,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3694483170683131,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44276094276094274,
      "openbookqa": 0.214,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.4541284403669725
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      14,
      2,
      16,
      16,
      2,
      10,
      8,
      2,
      12,
      12,
      16,
      2,
      16,
      12,
      14,
      4,
      16,
      6,
      16,
      8,
      2,
      6,
      10,
      12,
      4,
      2,
      4,
      4,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.44036697247706424,
      "arc_easy": 0.44402356902356904,
      "openbookqa": 0.23,
      "winogrande": 0.5256511444356748,
      "hellaswag": 0.3701453893646684,
      "arc_challenge": 0.25597269624573377,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      10,
      6,
      16,
      14,
      8,
      10,
      4,
      6,
      6,
      16,
      4,
      6,
      2,
      6,
      12,
      2,
      4,
      12,
      6,
      4,
      12,
      14,
      14,
      14,
      10,
      12,
      16,
      12,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.2431740614334471,
      "openbookqa": 0.216,
      "arc_easy": 0.4452861952861953,
      "boolq": 0.4669724770642202,
      "hellaswag": 0.37064329814777935,
      "piqa": 0.690968443960827
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      12,
      6,
      14,
      6,
      6,
      10,
      14,
      16,
      8,
      6,
      6,
      12,
      2,
      6,
      10,
      6,
      6,
      6,
      6,
      14,
      8,
      6,
      6,
      2,
      10,
      10,
      4,
      6,
      14,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.4504587155963303,
      "piqa": 0.6860718171926007,
      "arc_challenge": 0.2551194539249147,
      "arc_easy": 0.44234006734006737,
      "hellaswag": 0.3694483170683131,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.22
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      4,
      12,
      10,
      2,
      14,
      4,
      16,
      6,
      6,
      8,
      8,
      10,
      6,
      4,
      10,
      4,
      4,
      10,
      2,
      14,
      16,
      2,
      14,
      10,
      4,
      12,
      6,
      6,
      8,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "boolq": 0.4504587155963303,
      "winogrande": 0.526440410418311,
      "arc_easy": 0.44991582491582494,
      "hellaswag": 0.37004580760804623,
      "arc_challenge": 0.257679180887372,
      "openbookqa": 0.222
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      12,
      6,
      2,
      8,
      8,
      16,
      6,
      16,
      12,
      8,
      12,
      16,
      8,
      12,
      10,
      16,
      14,
      4,
      12,
      10,
      14,
      14,
      6,
      12,
      12,
      8,
      12,
      14,
      4,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.6,
      "hellaswag": 0.35789683330013944,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6697497279651795,
      "arc_challenge": 0.2380546075085324,
      "openbookqa": 0.23,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      12,
      2,
      10,
      4,
      12,
      8,
      10,
      4,
      2,
      8,
      10,
      16,
      16,
      4,
      4,
      2,
      8,
      4,
      2,
      4,
      10,
      8,
      2,
      8,
      10,
      4,
      14,
      12,
      4,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2525597269624573,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.218,
      "boolq": 0.44403669724770645,
      "arc_easy": 0.4562289562289562,
      "hellaswag": 0.37203744274048994,
      "piqa": 0.690424374319913
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      14,
      8,
      10,
      16,
      8,
      6,
      2,
      4,
      12,
      16,
      12,
      4,
      10,
      4,
      10,
      12,
      6,
      2,
      14,
      10,
      8,
      8,
      12,
      12,
      16,
      8,
      4,
      12,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3584943238398725,
      "winogrande": 0.5067087608524072,
      "openbookqa": 0.224,
      "arc_challenge": 0.2525597269624573,
      "arc_easy": 0.48695286195286197,
      "piqa": 0.6741022850924918,
      "boolq": 0.5581039755351682
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      6,
      16,
      4,
      12,
      10,
      6,
      6,
      6,
      4,
      16,
      4,
      2,
      8,
      6,
      6,
      16,
      8,
      16,
      16,
      14,
      2,
      10,
      8,
      8,
      2,
      14,
      14,
      8,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.44865319865319864,
      "hellaswag": 0.3694483170683131,
      "arc_challenge": 0.25170648464163825,
      "boolq": 0.46299694189602447,
      "piqa": 0.690968443960827,
      "openbookqa": 0.22
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      8,
      2,
      2,
      2,
      10,
      4,
      4,
      2,
      2,
      12,
      10,
      10,
      2,
      12,
      2,
      6,
      8,
      2,
      8,
      4,
      12,
      6,
      12,
      12,
      14,
      2,
      12,
      8,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4473905723905724,
      "winogrande": 0.5138121546961326,
      "piqa": 0.6860718171926007,
      "arc_challenge": 0.25597269624573377,
      "openbookqa": 0.218,
      "boolq": 0.4669724770642202,
      "hellaswag": 0.3707428799044015
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      8,
      8,
      6,
      16,
      6,
      16,
      6,
      2,
      16,
      16,
      12,
      14,
      14,
      10,
      10,
      10,
      6,
      4,
      14,
      10,
      2,
      14,
      16,
      16,
      10,
      14,
      4,
      10,
      16,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "winogrande": 0.5169692186266772,
      "openbookqa": 0.222,
      "piqa": 0.6871599564744287,
      "boolq": 0.43363914373088686,
      "arc_easy": 0.45580808080808083,
      "hellaswag": 0.3708424616610237
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      4,
      16,
      14,
      8,
      4,
      16,
      2,
      10,
      8,
      4,
      10,
      6,
      14,
      2,
      12,
      6,
      12,
      16,
      16,
      12,
      8,
      4,
      16,
      4,
      8,
      14,
      4,
      10,
      12,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.257679180887372,
      "openbookqa": 0.22,
      "piqa": 0.6936887921653971,
      "hellaswag": 0.37004580760804623,
      "boolq": 0.4620795107033639,
      "arc_easy": 0.45075757575757575,
      "winogrande": 0.5201262825572218
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      10,
      4,
      10,
      14,
      16,
      6,
      16,
      12,
      14,
      6,
      2,
      14,
      2,
      2,
      10,
      10,
      8,
      12,
      16,
      2,
      10,
      4,
      12,
      6,
      10,
      12,
      4,
      16,
      8,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25341296928327645,
      "hellaswag": 0.3708424616610237,
      "boolq": 0.44036697247706424,
      "winogrande": 0.5303867403314917,
      "openbookqa": 0.216,
      "arc_easy": 0.45496632996632996,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      6,
      16,
      2,
      16,
      6,
      10,
      10,
      2,
      4,
      2,
      4,
      14,
      2,
      16,
      12,
      14,
      12,
      12,
      4,
      10,
      2,
      14,
      8,
      14,
      8,
      16,
      4,
      6,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.236,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.359788886675961,
      "arc_challenge": 0.24829351535836178,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.47895622895622897,
      "boolq": 0.5785932721712538
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      2,
      16,
      16,
      12,
      12,
      10,
      6,
      6,
      14,
      10,
      4,
      14,
      8,
      16,
      10,
      4,
      10,
      2,
      14,
      16,
      8,
      2,
      12,
      10,
      12,
      4,
      8,
      12,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.212,
      "arc_easy": 0.4414983164983165,
      "boolq": 0.47553516819571867,
      "arc_challenge": 0.25426621160409557,
      "winogrande": 0.5098658247829518,
      "hellaswag": 0.37024497112129057,
      "piqa": 0.6893362350380848
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      16,
      4,
      10,
      8,
      8,
      14,
      16,
      2,
      16,
      4,
      6,
      12,
      10,
      12,
      4,
      6,
      2,
      4,
      12,
      16,
      2,
      12,
      6,
      8,
      8,
      6,
      12,
      10,
      12,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.212,
      "arc_easy": 0.43602693602693604,
      "arc_challenge": 0.2431740614334471,
      "winogrande": 0.5240726124704025,
      "boolq": 0.43180428134556575,
      "hellaswag": 0.3703445528779128,
      "piqa": 0.6931447225244831
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      2,
      12,
      4,
      10,
      2,
      16,
      16,
      10,
      10,
      4,
      6,
      14,
      10,
      14,
      8,
      4,
      6,
      16,
      2,
      8,
      10,
      6,
      2,
      8,
      8,
      4,
      2,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24914675767918087,
      "arc_easy": 0.4511784511784512,
      "openbookqa": 0.218,
      "winogrande": 0.5209155485398579,
      "boolq": 0.42782874617737005,
      "hellaswag": 0.37054371639115713,
      "piqa": 0.6844396082698585
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      16,
      12,
      2,
      14,
      4,
      10,
      6,
      8,
      8,
      8,
      6,
      4,
      12,
      2,
      14,
      16,
      14,
      6,
      10,
      6,
      10,
      6,
      6,
      4,
      10,
      10,
      2,
      14,
      8,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3703445528779128,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.22,
      "piqa": 0.6898803046789989,
      "arc_challenge": 0.24573378839590443,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4917431192660551
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      10,
      12,
      14,
      12,
      14,
      2,
      14,
      2,
      14,
      8,
      6,
      12,
      4,
      6,
      6,
      10,
      16,
      16,
      14,
      12,
      10,
      6,
      12,
      4,
      6,
      6,
      2,
      12,
      4,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3701453893646684,
      "openbookqa": 0.222,
      "arc_challenge": 0.2508532423208191,
      "arc_easy": 0.4444444444444444,
      "piqa": 0.6898803046789989,
      "winogrande": 0.5209155485398579,
      "boolq": 0.4801223241590214
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      14,
      4,
      16,
      8,
      4,
      8,
      14,
      12,
      16,
      12,
      8,
      14,
      10,
      2,
      12,
      2,
      4,
      8,
      8,
      4,
      14,
      16,
      2,
      6,
      2,
      2,
      16,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4831649831649832,
      "boolq": 0.5617737003058104,
      "piqa": 0.6741022850924918,
      "hellaswag": 0.35879306910973907,
      "openbookqa": 0.238,
      "winogrande": 0.5224940805051302,
      "arc_challenge": 0.2431740614334471
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      16,
      4,
      14,
      6,
      6,
      12,
      10,
      16,
      12,
      2,
      6,
      2,
      14,
      4,
      4,
      10,
      12,
      2,
      14,
      4,
      10,
      12,
      6,
      14,
      4,
      10,
      8,
      4,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "arc_challenge": 0.24232081911262798,
      "boolq": 0.6137614678899083,
      "winogrande": 0.5146014206787688,
      "hellaswag": 0.3584943238398725,
      "arc_easy": 0.4802188552188552,
      "piqa": 0.6746463547334058
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      14,
      16,
      6,
      8,
      10,
      16,
      12,
      6,
      12,
      6,
      6,
      10,
      16,
      16,
      16,
      6,
      6,
      10,
      10,
      14,
      16,
      12,
      6,
      8,
      10,
      2,
      10,
      16,
      8,
      6,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.427217125382263,
      "arc_challenge": 0.2525597269624573,
      "hellaswag": 0.36914957179844654,
      "winogrande": 0.5146014206787688,
      "piqa": 0.6936887921653971,
      "openbookqa": 0.224,
      "arc_easy": 0.44612794612794615
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      10,
      14,
      16,
      6,
      8,
      14,
      14,
      2,
      2,
      2,
      4,
      14,
      12,
      12,
      12,
      6,
      6,
      4,
      4,
      10,
      12,
      14,
      4,
      12,
      8,
      16,
      6,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2440273037542662,
      "boolq": 0.42110091743119266,
      "arc_easy": 0.4414983164983165,
      "openbookqa": 0.212,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.37134037044413465,
      "winogrande": 0.5288082083662194
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      2,
      12,
      12,
      6,
      12,
      4,
      4,
      6,
      14,
      2,
      14,
      14,
      16,
      8,
      4,
      14,
      8,
      14,
      14,
      10,
      8,
      14,
      2,
      8,
      6,
      8,
      2,
      4,
      6,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "boolq": 0.5990825688073395,
      "hellaswag": 0.3584943238398725,
      "openbookqa": 0.226,
      "arc_challenge": 0.24146757679180889,
      "arc_easy": 0.4852693602693603,
      "piqa": 0.675734494015234
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      8,
      4,
      10,
      2,
      8,
      2,
      16,
      2,
      2,
      6,
      14,
      4,
      6,
      10,
      6,
      14,
      6,
      10,
      16,
      2,
      2,
      2,
      2,
      12,
      2,
      10,
      16,
      12,
      2,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.24744027303754265,
      "arc_easy": 0.4797979797979798,
      "openbookqa": 0.236,
      "piqa": 0.6686615886833515,
      "boolq": 0.5844036697247706,
      "winogrande": 0.5272296764009471,
      "hellaswag": 0.3586934873531169
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      14,
      4,
      2,
      12,
      2,
      2,
      4,
      4,
      4,
      16,
      14,
      6,
      2,
      2,
      16,
      6,
      4,
      16,
      2,
      12,
      12,
      8,
      16,
      6,
      6,
      4,
      2,
      4,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5593272171253822,
      "openbookqa": 0.232,
      "winogrande": 0.5153906866614049,
      "arc_easy": 0.492003367003367,
      "piqa": 0.6746463547334058,
      "hellaswag": 0.3586934873531169,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      10,
      6,
      4,
      12,
      8,
      8,
      10,
      2,
      6,
      4,
      10,
      8,
      14,
      2,
      16,
      4,
      4,
      2,
      4,
      4,
      12,
      10,
      4,
      4,
      4,
      4,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6692056583242655,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.4861111111111111,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5785932721712538,
      "hellaswag": 0.3601872137024497,
      "openbookqa": 0.226
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      2,
      12,
      8,
      10,
      4,
      14,
      14,
      10,
      6,
      4,
      16,
      8,
      2,
      14,
      12,
      16,
      6,
      12,
      10,
      10,
      16,
      2,
      16,
      16,
      12,
      4,
      14,
      16,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.3707428799044015,
      "boolq": 0.4837920489296636,
      "openbookqa": 0.216,
      "piqa": 0.691512513601741,
      "arc_easy": 0.4532828282828283,
      "winogrande": 0.5248618784530387
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      8,
      14,
      2,
      14,
      10,
      2,
      8,
      8,
      6,
      2,
      6,
      10,
      6,
      6,
      4,
      6,
      2,
      8,
      10,
      2,
      16,
      8,
      12,
      14,
      10,
      6,
      4,
      10,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.2525597269624573,
      "hellaswag": 0.35919139613622786,
      "piqa": 0.6741022850924918,
      "boolq": 0.5883792048929664,
      "openbookqa": 0.226,
      "winogrande": 0.5114443567482242
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      16,
      6,
      6,
      16,
      6,
      6,
      6,
      2,
      10,
      16,
      10,
      16,
      8,
      2,
      6,
      16,
      16,
      14,
      2,
      14,
      6,
      6,
      4,
      2,
      2,
      8,
      8,
      6,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5764525993883792,
      "piqa": 0.6708378672470077,
      "openbookqa": 0.228,
      "hellaswag": 0.35789683330013944,
      "arc_challenge": 0.24061433447098976,
      "winogrande": 0.5130228887134964,
      "arc_easy": 0.4831649831649832
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      8,
      6,
      14,
      14,
      8,
      14,
      14,
      16,
      4,
      6,
      14,
      16,
      16,
      16,
      6,
      12,
      10,
      10,
      16,
      6,
      6,
      12,
      10,
      12,
      10,
      14,
      4,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.214,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6871599564744287,
      "hellaswag": 0.3692491535550687,
      "boolq": 0.5051987767584097,
      "arc_easy": 0.4385521885521885
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      10,
      6,
      4,
      14,
      8,
      8,
      8,
      16,
      12,
      12,
      12,
      10,
      8,
      4,
      6,
      12,
      6,
      2,
      10,
      14,
      16,
      8,
      4,
      16,
      4,
      16,
      14,
      10,
      14,
      2,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.43486238532110094,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.4473905723905724,
      "hellaswag": 0.3703445528779128,
      "winogrande": 0.5153906866614049
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      6,
      16,
      2,
      12,
      8,
      6,
      4,
      4,
      16,
      10,
      10,
      2,
      8,
      8,
      12,
      2,
      10,
      2,
      4,
      12,
      4,
      4,
      4,
      14,
      6,
      14,
      4,
      10,
      6,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.214,
      "arc_easy": 0.44654882154882153,
      "hellaswag": 0.3719378609838678,
      "arc_challenge": 0.24829351535836178,
      "boolq": 0.4724770642201835,
      "winogrande": 0.526440410418311,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      6,
      8,
      16,
      6,
      2,
      12,
      4,
      4,
      4,
      8,
      16,
      14,
      2,
      12,
      8,
      8,
      8,
      16,
      2,
      14,
      14,
      6,
      12,
      8,
      12,
      2,
      10,
      6,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35929097789285,
      "arc_challenge": 0.24573378839590443,
      "arc_easy": 0.48653198653198654,
      "boolq": 0.5749235474006116,
      "openbookqa": 0.238,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6741022850924918
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      6,
      14,
      8,
      16,
      16,
      10,
      12,
      10,
      4,
      14,
      16,
      6,
      8,
      8,
      8,
      4,
      4,
      14,
      6,
      16,
      10,
      10,
      8,
      12,
      2,
      6,
      10,
      4,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.48256880733944957,
      "arc_easy": 0.4377104377104377,
      "piqa": 0.6855277475516867,
      "winogrande": 0.5201262825572218,
      "hellaswag": 0.3701453893646684,
      "arc_challenge": 0.2440273037542662,
      "openbookqa": 0.216
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      4,
      16,
      12,
      10,
      2,
      2,
      8,
      6,
      4,
      6,
      14,
      4,
      12,
      16,
      4,
      10,
      12,
      14,
      6,
      4,
      14,
      12,
      14,
      4,
      2,
      2,
      4,
      10,
      2,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.47853535353535354,
      "hellaswag": 0.35769766978689504,
      "arc_challenge": 0.25170648464163825,
      "openbookqa": 0.232,
      "winogrande": 0.5153906866614049,
      "piqa": 0.6692056583242655,
      "boolq": 0.5844036697247706
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      6,
      10,
      12,
      10,
      2,
      16,
      10,
      2,
      2,
      12,
      14,
      10,
      2,
      16,
      14,
      8,
      2,
      16,
      14,
      16,
      6,
      14,
      6,
      16,
      2,
      2,
      12,
      8,
      16,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.676822633297062,
      "boolq": 0.518960244648318,
      "openbookqa": 0.234,
      "arc_challenge": 0.24744027303754265,
      "hellaswag": 0.35879306910973907,
      "arc_easy": 0.48148148148148145,
      "winogrande": 0.5090765588003157
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      6,
      8,
      12,
      8,
      10,
      10,
      14,
      12,
      10,
      6,
      12,
      6,
      4,
      2,
      6,
      2,
      4,
      14,
      14,
      10,
      12,
      2,
      10,
      6,
      4,
      2,
      6,
      6,
      14,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4398148148148148,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.228,
      "hellaswag": 0.3719378609838678,
      "boolq": 0.42752293577981654,
      "piqa": 0.6871599564744287,
      "arc_challenge": 0.2593856655290102
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      6,
      2,
      8,
      16,
      10,
      14,
      10,
      6,
      16,
      8,
      8,
      2,
      4,
      2,
      6,
      6,
      14,
      12,
      8,
      8,
      6,
      12,
      8,
      8,
      2,
      12,
      4,
      2,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.234,
      "arc_challenge": 0.24061433447098976,
      "hellaswag": 0.35919139613622786,
      "arc_easy": 0.48442760942760943,
      "piqa": 0.675734494015234,
      "boolq": 0.5923547400611621
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      10,
      2,
      16,
      4,
      14,
      2,
      2,
      16,
      10,
      4,
      16,
      8,
      14,
      4,
      14,
      2,
      16,
      8,
      10,
      16,
      8,
      12,
      14,
      16,
      6,
      8,
      14,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.226,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.2431740614334471,
      "arc_easy": 0.4877946127946128,
      "boolq": 0.5899082568807339,
      "piqa": 0.6730141458106638,
      "hellaswag": 0.35829516032662817
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      10,
      10,
      4,
      2,
      12,
      12,
      6,
      16,
      10,
      16,
      12,
      12,
      16,
      10,
      16,
      14,
      2,
      12,
      6,
      12,
      8,
      16,
      8,
      8,
      14,
      4,
      16,
      8,
      8,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "arc_challenge": 0.2525597269624573,
      "arc_easy": 0.4473905723905724,
      "piqa": 0.6877040261153428,
      "hellaswag": 0.3690499900418243,
      "boolq": 0.4773700305810398,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      2,
      10,
      6,
      14,
      12,
      8,
      4,
      8,
      6,
      10,
      8,
      16,
      2,
      16,
      10,
      2,
      10,
      16,
      8,
      2,
      16,
      10,
      16,
      10,
      8,
      10,
      8,
      8,
      10,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.24,
      "boolq": 0.5599388379204893,
      "hellaswag": 0.3599880501892053,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5138121546961326,
      "arc_challenge": 0.2525597269624573,
      "arc_easy": 0.4877946127946128
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      10,
      4,
      10,
      8,
      10,
      8,
      16,
      12,
      8,
      12,
      14,
      10,
      14,
      10,
      10,
      2,
      8,
      8,
      14,
      4,
      6,
      12,
      14,
      6,
      6,
      14,
      16,
      8,
      14,
      6,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5177584846093133,
      "piqa": 0.6702937976060935,
      "boolq": 0.5981651376146789,
      "hellaswag": 0.35789683330013944,
      "openbookqa": 0.226,
      "arc_easy": 0.48442760942760943,
      "arc_challenge": 0.24914675767918087
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      12,
      16,
      8,
      8,
      4,
      12,
      2,
      16,
      12,
      4,
      16,
      8,
      8,
      12,
      8,
      10,
      4,
      4,
      14,
      2,
      4,
      6,
      12,
      2,
      2,
      12,
      8,
      2,
      14,
      16,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "openbookqa": 0.228,
      "boolq": 0.5920489296636086,
      "arc_easy": 0.48569023569023567,
      "hellaswag": 0.3595897231627166,
      "arc_challenge": 0.24573378839590443,
      "winogrande": 0.5209155485398579
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      12,
      16,
      2,
      16,
      2,
      8,
      10,
      14,
      16,
      12,
      10,
      16,
      12,
      12,
      2,
      6,
      16,
      8,
      2,
      10,
      12,
      8,
      2,
      4,
      2,
      6,
      14,
      12,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "piqa": 0.691512513601741,
      "arc_easy": 0.45286195286195285,
      "winogrande": 0.5217048145224941,
      "boolq": 0.40581039755351683,
      "arc_challenge": 0.2525597269624573,
      "hellaswag": 0.37024497112129057
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      8,
      4,
      14,
      4,
      6,
      12,
      8,
      8,
      4,
      2,
      14,
      14,
      14,
      16,
      16,
      12,
      16,
      6,
      16,
      12,
      6,
      16,
      14,
      8,
      12,
      8,
      10,
      8,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.36875124477195775,
      "openbookqa": 0.212,
      "arc_easy": 0.44696969696969696,
      "piqa": 0.6887921653971708,
      "boolq": 0.4547400611620795,
      "arc_challenge": 0.2525597269624573
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      16,
      16,
      4,
      2,
      8,
      4,
      14,
      10,
      6,
      4,
      4,
      12,
      6,
      4,
      16,
      14,
      2,
      4,
      16,
      8,
      2,
      8,
      14,
      12,
      12,
      16,
      16,
      2,
      12,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25853242320819114,
      "winogrande": 0.516179952644041,
      "openbookqa": 0.214,
      "arc_easy": 0.44402356902356904,
      "boolq": 0.4672782874617737,
      "piqa": 0.690424374319913,
      "hellaswag": 0.3703445528779128
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      14,
      12,
      12,
      10,
      6,
      6,
      14,
      16,
      16,
      12,
      6,
      16,
      2,
      12,
      6,
      16,
      10,
      16,
      4,
      4,
      2,
      8,
      4,
      4,
      14,
      2,
      16,
      12,
      16,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "openbookqa": 0.214,
      "winogrande": 0.5138121546961326,
      "hellaswag": 0.37114120693089026,
      "piqa": 0.6849836779107725,
      "arc_easy": 0.4511784511784512,
      "boolq": 0.41376146788990825
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      10,
      4,
      4,
      4,
      2,
      14,
      10,
      10,
      10,
      6,
      16,
      16,
      10,
      14,
      8,
      10,
      8,
      8,
      16,
      4,
      14,
      14,
      12,
      4,
      16,
      6,
      2,
      14,
      10,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.226,
      "arc_easy": 0.4861111111111111,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.35829516032662817,
      "boolq": 0.590519877675841,
      "piqa": 0.6697497279651795
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      10,
      6,
      12,
      14,
      14,
      10,
      14,
      16,
      10,
      8,
      8,
      10,
      8,
      12,
      6,
      8,
      16,
      8,
      14,
      2,
      10,
      4,
      2,
      10,
      10,
      16,
      2,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4444444444444444,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.226,
      "boolq": 0.4565749235474006,
      "hellaswag": 0.3707428799044015,
      "piqa": 0.6920565832426551,
      "arc_challenge": 0.25170648464163825
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      4,
      12,
      8,
      2,
      10,
      8,
      14,
      2,
      14,
      12,
      12,
      4,
      10,
      8,
      10,
      6,
      14,
      14,
      14,
      2,
      2,
      12,
      10,
      12,
      10,
      2,
      16,
      12,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3693487353116909,
      "arc_easy": 0.44234006734006737,
      "arc_challenge": 0.25170648464163825,
      "boolq": 0.42813455657492355,
      "winogrande": 0.5256511444356748,
      "openbookqa": 0.214,
      "piqa": 0.6860718171926007
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      2,
      10,
      2,
      6,
      14,
      14,
      2,
      10,
      8,
      10,
      12,
      8,
      4,
      12,
      6,
      6,
      16,
      6,
      10,
      6,
      10,
      10,
      16,
      4,
      12,
      16,
      16,
      12,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3595897231627166,
      "arc_easy": 0.4772727272727273,
      "arc_challenge": 0.25426621160409557,
      "openbookqa": 0.226,
      "winogrande": 0.5114443567482242,
      "piqa": 0.6779107725788901,
      "boolq": 0.5740061162079511
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      12,
      8,
      4,
      2,
      16,
      4,
      6,
      12,
      6,
      10,
      8,
      6,
      16,
      4,
      10,
      14,
      6,
      10,
      2,
      8,
      12,
      14,
      2,
      4,
      16,
      12,
      10,
      12,
      6,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.234,
      "winogrande": 0.5240726124704025,
      "arc_challenge": 0.2551194539249147,
      "arc_easy": 0.49284511784511786,
      "piqa": 0.6730141458106638,
      "boolq": 0.5804281345565749,
      "hellaswag": 0.3593905596494722
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      14,
      8,
      12,
      16,
      10,
      16,
      2,
      12,
      4,
      12,
      10,
      10,
      8,
      6,
      12,
      4,
      12,
      8,
      6,
      14,
      12,
      8,
      4,
      10,
      6,
      14,
      14,
      12,
      4,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.216,
      "piqa": 0.6887921653971708,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.24573378839590443,
      "hellaswag": 0.3695478988249353,
      "boolq": 0.4902140672782875,
      "arc_easy": 0.44486531986531985
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      2,
      14,
      4,
      6,
      6,
      16,
      10,
      14,
      4,
      6,
      2,
      8,
      16,
      2,
      10,
      6,
      8,
      16,
      16,
      2,
      4,
      12,
      12,
      14,
      16,
      14,
      2,
      14,
      2,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5232833464877664,
      "openbookqa": 0.216,
      "arc_easy": 0.4431818181818182,
      "arc_challenge": 0.25170648464163825,
      "hellaswag": 0.37024497112129057,
      "piqa": 0.6871599564744287,
      "boolq": 0.4596330275229358
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      16,
      10,
      12,
      12,
      2,
      6,
      12,
      10,
      2,
      14,
      8,
      4,
      6,
      8,
      8,
      10,
      2,
      6,
      4,
      14,
      6,
      12,
      14,
      14,
      16,
      10,
      6,
      10,
      12,
      10,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25341296928327645,
      "hellaswag": 0.37064329814777935,
      "openbookqa": 0.22,
      "piqa": 0.6898803046789989,
      "boolq": 0.42018348623853213,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.44612794612794615
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      4,
      14,
      12,
      4,
      8,
      2,
      10,
      12,
      16,
      10,
      6,
      2,
      2,
      14,
      14,
      16,
      2,
      8,
      8,
      16,
      16,
      14,
      2,
      16,
      6,
      10,
      12,
      16,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4819023569023569,
      "piqa": 0.6746463547334058,
      "arc_challenge": 0.2440273037542662,
      "hellaswag": 0.359788886675961,
      "winogrande": 0.5177584846093133,
      "boolq": 0.6076452599388379,
      "openbookqa": 0.23
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      12,
      4,
      16,
      2,
      6,
      12,
      12,
      10,
      4,
      12,
      8,
      8,
      8,
      16,
      2,
      8,
      12,
      12,
      10,
      4,
      14,
      12,
      6,
      2,
      4,
      14,
      10,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35899223262298346,
      "boolq": 0.5874617737003058,
      "openbookqa": 0.23,
      "arc_challenge": 0.24744027303754265,
      "piqa": 0.6653971708378672,
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.48358585858585856
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      4,
      10,
      6,
      16,
      16,
      16,
      12,
      14,
      16,
      16,
      4,
      14,
      10,
      10,
      8,
      8,
      14,
      16,
      4,
      4,
      8,
      12,
      2,
      12,
      14,
      4,
      16,
      8,
      2,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.236,
      "boolq": 0.6030581039755352,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6708378672470077,
      "hellaswag": 0.3610834495120494,
      "arc_challenge": 0.2431740614334471
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      16,
      14,
      6,
      14,
      2,
      16,
      16,
      10,
      4,
      2,
      14,
      8,
      4,
      2,
      10,
      4,
      10,
      10,
      14,
      8,
      2,
      8,
      16,
      10,
      10,
      6,
      6,
      12,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5201262825572218,
      "boolq": 0.43027522935779816,
      "piqa": 0.6855277475516867,
      "arc_easy": 0.4457070707070707,
      "hellaswag": 0.3693487353116909,
      "openbookqa": 0.21,
      "arc_challenge": 0.25
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      10,
      16,
      8,
      6,
      2,
      6,
      6,
      8,
      6,
      6,
      14,
      6,
      2,
      14,
      10,
      2,
      16,
      4,
      2,
      10,
      2,
      14,
      16,
      10,
      10,
      4,
      10,
      16,
      6,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.690424374319913,
      "winogrande": 0.5272296764009471,
      "boolq": 0.4666666666666667,
      "arc_easy": 0.44612794612794615,
      "arc_challenge": 0.2525597269624573,
      "hellaswag": 0.37134037044413465,
      "openbookqa": 0.212
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      12,
      14,
      10,
      16,
      14,
      14,
      6,
      14,
      2,
      16,
      8,
      12,
      16,
      16,
      12,
      10,
      16,
      16,
      12,
      4,
      16,
      4,
      6,
      8,
      16,
      2,
      10,
      2,
      8,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "boolq": 0.4504587155963303,
      "winogrande": 0.516179952644041,
      "arc_easy": 0.4444444444444444,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3716391157140012,
      "piqa": 0.6887921653971708
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      6,
      4,
      8,
      8,
      4,
      6,
      2,
      4,
      10,
      4,
      6,
      2,
      14,
      8,
      10,
      8,
      4,
      6,
      14,
      8,
      16,
      8,
      8,
      8,
      6,
      16,
      10,
      6,
      2,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25597269624573377,
      "boolq": 0.5669724770642202,
      "winogrande": 0.5153906866614049,
      "hellaswag": 0.3575980880302729,
      "piqa": 0.6670293797606094,
      "arc_easy": 0.484006734006734,
      "openbookqa": 0.234
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      12,
      4,
      6,
      10,
      2,
      14,
      4,
      2,
      8,
      6,
      12,
      16,
      6,
      2,
      10,
      6,
      14,
      4,
      14,
      12,
      8,
      14,
      4,
      14,
      12,
      8,
      4,
      8,
      16,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35829516032662817,
      "arc_easy": 0.4764309764309764,
      "openbookqa": 0.234,
      "winogrande": 0.5193370165745856,
      "boolq": 0.5663608562691131,
      "arc_challenge": 0.2551194539249147,
      "piqa": 0.6730141458106638
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      8,
      4,
      2,
      10,
      16,
      14,
      6,
      12,
      10,
      10,
      14,
      16,
      10,
      8,
      10,
      8,
      8,
      6,
      6,
      14,
      10,
      2,
      14,
      4,
      8,
      16,
      4,
      4,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.358195578570006,
      "boolq": 0.5507645259938838,
      "winogrande": 0.5169692186266772,
      "arc_challenge": 0.24061433447098976,
      "arc_easy": 0.4936868686868687,
      "openbookqa": 0.23,
      "piqa": 0.6735582154515778
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      10,
      16,
      14,
      14,
      2,
      16,
      2,
      8,
      6,
      2,
      10,
      12,
      10,
      12,
      2,
      2,
      4,
      10,
      14,
      2,
      6,
      6,
      14,
      8,
      16,
      6,
      14,
      14,
      16,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25426621160409557,
      "arc_easy": 0.48442760942760943,
      "boolq": 0.5929663608562691,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.3588926508663613,
      "openbookqa": 0.232,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      14,
      6,
      12,
      2,
      8,
      16,
      4,
      10,
      12,
      10,
      6,
      4,
      4,
      8,
      2,
      2,
      10,
      2,
      8,
      8,
      12,
      12,
      2,
      8,
      14,
      6,
      4,
      10,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4436026936026936,
      "openbookqa": 0.216,
      "boolq": 0.45137614678899085,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5067087608524072,
      "hellaswag": 0.37054371639115713,
      "arc_challenge": 0.24829351535836178
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      2,
      8,
      6,
      2,
      10,
      12,
      8,
      10,
      2,
      4,
      6,
      4,
      10,
      6,
      16,
      4,
      16,
      4,
      6,
      12,
      14,
      16,
      8,
      2,
      12,
      16,
      10,
      6,
      8,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.46452599388379207,
      "openbookqa": 0.218,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.24829351535836178,
      "hellaswag": 0.3690499900418243,
      "piqa": 0.6926006528835691,
      "arc_easy": 0.4452861952861953
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      10,
      6,
      16,
      12,
      14,
      2,
      12,
      4,
      14,
      6,
      2,
      8,
      2,
      8,
      6,
      2,
      16,
      10,
      10,
      8,
      6,
      16,
      2,
      2,
      12,
      16,
      8,
      16,
      16,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48063973063973064,
      "openbookqa": 0.232,
      "boolq": 0.5862385321100917,
      "hellaswag": 0.358195578570006,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6675734494015234
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      10,
      10,
      2,
      2,
      10,
      14,
      14,
      6,
      8,
      10,
      14,
      8,
      16,
      6,
      8,
      4,
      16,
      14,
      8,
      8,
      10,
      6,
      12,
      16,
      14,
      16,
      4,
      16,
      8,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5185477505919495,
      "piqa": 0.6882480957562568,
      "arc_easy": 0.45454545454545453,
      "boolq": 0.44128440366972477,
      "openbookqa": 0.22,
      "hellaswag": 0.3721370244971121,
      "arc_challenge": 0.2551194539249147
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      16,
      6,
      10,
      14,
      4,
      4,
      6,
      8,
      16,
      4,
      16,
      6,
      2,
      6,
      10,
      16,
      6,
      6,
      12,
      10,
      12,
      2,
      14,
      2,
      2,
      2,
      12,
      4,
      2,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.214,
      "arc_challenge": 0.24573378839590443,
      "hellaswag": 0.3707428799044015,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.4363914373088685,
      "winogrande": 0.5240726124704025,
      "piqa": 0.6871599564744287
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      6,
      14,
      10,
      14,
      14,
      16,
      2,
      12,
      12,
      6,
      10,
      10,
      14,
      12,
      6,
      10,
      6,
      4,
      4,
      6,
      12,
      10,
      10,
      12,
      12,
      16,
      6,
      8,
      12,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4850152905198777,
      "hellaswag": 0.36964748058155744,
      "winogrande": 0.5090765588003157,
      "piqa": 0.690424374319913,
      "arc_challenge": 0.26023890784982934
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      4,
      6,
      14,
      12,
      8,
      10,
      8,
      14,
      16,
      16,
      6,
      16,
      2,
      14,
      2,
      14,
      4,
      2,
      10,
      16,
      6,
      16,
      16,
      14,
      2,
      4,
      6,
      12,
      10,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48863636363636365,
      "piqa": 0.676278563656148,
      "boolq": 0.5614678899082569,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.234,
      "hellaswag": 0.35909181437960563
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      14,
      14,
      14,
      10,
      2,
      2,
      12,
      10,
      10,
      10,
      2,
      12,
      8,
      12,
      14,
      10,
      10,
      10,
      12,
      14,
      4,
      12,
      4,
      6,
      6,
      8,
      8,
      6,
      4,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.48653198653198654,
      "piqa": 0.6751904243743199,
      "hellaswag": 0.36068512248556067,
      "winogrande": 0.5138121546961326,
      "arc_challenge": 0.2525597269624573,
      "boolq": 0.591743119266055,
      "openbookqa": 0.224
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      16,
      2,
      2,
      4,
      4,
      6,
      14,
      4,
      2,
      4,
      14,
      16,
      12,
      12,
      4,
      4,
      6,
      8,
      6,
      2,
      16,
      2,
      2,
      16,
      2,
      14,
      2,
      14,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5240726124704025,
      "piqa": 0.6860718171926007,
      "hellaswag": 0.37054371639115713,
      "arc_easy": 0.45075757575757575,
      "boolq": 0.42660550458715596,
      "openbookqa": 0.21,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      12,
      2,
      10,
      12,
      8,
      14,
      14,
      12,
      4,
      10,
      2,
      8,
      16,
      16,
      10,
      8,
      10,
      16,
      10,
      4,
      4,
      10,
      4,
      10,
      14,
      8,
      2,
      16,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "winogrande": 0.5090765588003157,
      "arc_easy": 0.4898989898989899,
      "openbookqa": 0.232,
      "boolq": 0.5883792048929664,
      "piqa": 0.6653971708378672,
      "hellaswag": 0.35919139613622786
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      12,
      16,
      10,
      2,
      16,
      16,
      16,
      4,
      8,
      14,
      2,
      8,
      16,
      10,
      6,
      10,
      6,
      8,
      6,
      10,
      4,
      12,
      8,
      14,
      4,
      10,
      12,
      10,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.242,
      "arc_easy": 0.4852693602693603,
      "boolq": 0.5709480122324159,
      "arc_challenge": 0.24488054607508533,
      "winogrande": 0.5232833464877664,
      "hellaswag": 0.35879306910973907,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      10,
      2,
      10,
      12,
      14,
      16,
      12,
      16,
      12,
      12,
      12,
      8,
      6,
      8,
      8,
      16,
      14,
      4,
      4,
      6,
      2,
      14,
      2,
      12,
      16,
      2,
      8,
      8,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3571997610037841,
      "piqa": 0.6751904243743199,
      "openbookqa": 0.222,
      "arc_challenge": 0.2431740614334471,
      "boolq": 0.5516819571865443,
      "arc_easy": 0.4819023569023569,
      "winogrande": 0.510655090765588
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      16,
      2,
      12,
      8,
      2,
      4,
      4,
      14,
      10,
      14,
      6,
      2,
      4,
      8,
      6,
      2,
      4,
      6,
      14,
      14,
      10,
      10,
      6,
      16,
      12,
      10,
      8,
      6,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6860718171926007,
      "arc_easy": 0.4541245791245791,
      "hellaswag": 0.36984664409480184,
      "openbookqa": 0.21,
      "boolq": 0.4327217125382263
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      12,
      2,
      6,
      6,
      14,
      14,
      14,
      12,
      12,
      2,
      12,
      16,
      4,
      8,
      8,
      10,
      10,
      12,
      16,
      14,
      4,
      14,
      4,
      12,
      4,
      16,
      14,
      12,
      12,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.222,
      "arc_easy": 0.4457070707070707,
      "arc_challenge": 0.24744027303754265,
      "winogrande": 0.5240726124704025,
      "boolq": 0.4767584097859327,
      "hellaswag": 0.36984664409480184,
      "piqa": 0.6898803046789989
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      14,
      2,
      6,
      6,
      14,
      14,
      10,
      16,
      6,
      2,
      4,
      12,
      2,
      4,
      16,
      8,
      10,
      14,
      10,
      16,
      6,
      6,
      14,
      16,
      16,
      10,
      12,
      6,
      16,
      16,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.222,
      "arc_easy": 0.44907407407407407,
      "hellaswag": 0.37044413463453496,
      "boolq": 0.4510703363914373,
      "arc_challenge": 0.25170648464163825,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6844396082698585
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      14,
      16,
      2,
      6,
      6,
      8,
      8,
      6,
      14,
      8,
      14,
      4,
      2,
      2,
      14,
      6,
      8,
      8,
      6,
      10,
      14,
      12,
      6,
      10,
      12,
      16,
      4,
      14,
      6,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3588926508663613,
      "arc_challenge": 0.24232081911262798,
      "winogrande": 0.5146014206787688,
      "arc_easy": 0.4823232323232323,
      "openbookqa": 0.232,
      "piqa": 0.6713819368879217,
      "boolq": 0.5944954128440367
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      4,
      2,
      8,
      10,
      16,
      2,
      4,
      4,
      8,
      10,
      16,
      6,
      12,
      16,
      4,
      2,
      2,
      4,
      14,
      16,
      12,
      4,
      12,
      14,
      16,
      4,
      14,
      8,
      8,
      4,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.369946225851424,
      "piqa": 0.690424374319913,
      "openbookqa": 0.222,
      "arc_easy": 0.45454545454545453,
      "arc_challenge": 0.25,
      "boolq": 0.45718654434250766,
      "winogrande": 0.516179952644041
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      8,
      8,
      6,
      6,
      6,
      2,
      8,
      2,
      14,
      12,
      6,
      12,
      4,
      6,
      10,
      14,
      4,
      16,
      12,
      2,
      14,
      14,
      12,
      8,
      14,
      6,
      6,
      4,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "arc_easy": 0.48484848484848486,
      "hellaswag": 0.35899223262298346,
      "arc_challenge": 0.25,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6730141458106638,
      "boolq": 0.5675840978593272
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      4,
      6,
      2,
      2,
      14,
      12,
      8,
      10,
      6,
      14,
      8,
      6,
      10,
      6,
      4,
      14,
      4,
      16,
      2,
      16,
      2,
      6,
      8,
      10,
      12,
      12,
      6,
      4,
      16,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3712407886875124,
      "arc_easy": 0.4431818181818182,
      "piqa": 0.6882480957562568,
      "boolq": 0.46972477064220186,
      "openbookqa": 0.21,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.24232081911262798
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      2,
      10,
      2,
      8,
      8,
      10,
      2,
      10,
      6,
      14,
      6,
      6,
      16,
      8,
      8,
      4,
      8,
      4,
      16,
      16,
      8,
      2,
      10,
      8,
      10,
      4,
      10,
      2,
      2,
      8,
      16,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3595897231627166,
      "winogrande": 0.5193370165745856,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.48274410774410775,
      "piqa": 0.6724700761697497,
      "openbookqa": 0.228,
      "boolq": 0.5837920489296636
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      6,
      12,
      16,
      4,
      4,
      4,
      10,
      6,
      4,
      12,
      12,
      16,
      2,
      6,
      16,
      8,
      6,
      4,
      6,
      12,
      8,
      4,
      6,
      10,
      14,
      10,
      10,
      14,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3593905596494722,
      "arc_challenge": 0.2551194539249147,
      "boolq": 0.5724770642201835,
      "openbookqa": 0.24,
      "piqa": 0.6724700761697497,
      "arc_easy": 0.48569023569023567,
      "winogrande": 0.5122336227308603
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      6,
      4,
      14,
      10,
      8,
      16,
      6,
      14,
      10,
      8,
      14,
      8,
      14,
      6,
      2,
      12,
      2,
      6,
      2,
      2,
      8,
      14,
      4,
      2,
      12,
      14,
      4,
      4,
      16,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.6,
      "hellaswag": 0.35968930491933876,
      "piqa": 0.676278563656148,
      "openbookqa": 0.226,
      "arc_easy": 0.48569023569023567,
      "winogrande": 0.5177584846093133
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      2,
      2,
      8,
      10,
      2,
      2,
      6,
      10,
      14,
      16,
      14,
      12,
      8,
      6,
      12,
      8,
      10,
      12,
      10,
      2,
      12,
      10,
      16,
      16,
      12,
      16,
      4,
      16,
      8,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.572782874617737,
      "openbookqa": 0.226,
      "hellaswag": 0.35859390559649473,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5146014206787688,
      "arc_challenge": 0.2354948805460751,
      "arc_easy": 0.48148148148148145
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      4,
      8,
      6,
      4,
      6,
      14,
      16,
      4,
      14,
      10,
      8,
      8,
      4,
      4,
      10,
      12,
      2,
      16,
      16,
      6,
      8,
      10,
      14,
      8,
      8,
      4,
      12,
      16,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36964748058155744,
      "openbookqa": 0.218,
      "winogrande": 0.5201262825572218,
      "piqa": 0.6877040261153428,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4648318042813456
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      4,
      10,
      14,
      4,
      12,
      12,
      6,
      2,
      6,
      10,
      16,
      14,
      2,
      12,
      4,
      16,
      4,
      4,
      10,
      8,
      14,
      8,
      4,
      4,
      2,
      4,
      2,
      6,
      10,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4902140672782875,
      "winogrande": 0.5240726124704025,
      "openbookqa": 0.214,
      "piqa": 0.690968443960827,
      "arc_challenge": 0.2568259385665529,
      "hellaswag": 0.3694483170683131
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      4,
      8,
      6,
      16,
      12,
      14,
      14,
      10,
      12,
      10,
      14,
      8,
      4,
      14,
      12,
      14,
      4,
      2,
      2,
      4,
      8,
      2,
      6,
      12,
      2,
      8,
      12,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25170648464163825,
      "piqa": 0.6751904243743199,
      "arc_easy": 0.48063973063973064,
      "boolq": 0.6039755351681957,
      "winogrande": 0.5146014206787688,
      "openbookqa": 0.236,
      "hellaswag": 0.35919139613622786
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      6,
      8,
      8,
      10,
      14,
      2,
      12,
      10,
      2,
      4,
      6,
      14,
      16,
      2,
      10,
      6,
      10,
      10,
      16,
      16,
      12,
      2,
      6,
      2,
      12,
      2,
      10,
      6,
      14,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.36895040828520215,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.24744027303754265,
      "openbookqa": 0.218,
      "arc_easy": 0.45454545454545453,
      "piqa": 0.6893362350380848,
      "boolq": 0.42079510703363915
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      12,
      14,
      2,
      14,
      10,
      2,
      14,
      8,
      16,
      10,
      4,
      16,
      12,
      8,
      4,
      6,
      10,
      8,
      14,
      8,
      8,
      12,
      8,
      14,
      8,
      2,
      4,
      8,
      2,
      12,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5209155485398579,
      "piqa": 0.676278563656148,
      "boolq": 0.5960244648318043,
      "openbookqa": 0.232,
      "arc_easy": 0.47853535353535354,
      "hellaswag": 0.35839474208325034,
      "arc_challenge": 0.24573378839590443
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      2,
      4,
      14,
      16,
      10,
      2,
      14,
      8,
      2,
      8,
      12,
      6,
      10,
      12,
      6,
      10,
      8,
      10,
      12,
      6,
      8,
      4,
      10,
      16,
      4,
      12,
      12,
      12,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "boolq": 0.5834862385321101,
      "hellaswag": 0.3575980880302729,
      "arc_challenge": 0.24061433447098976,
      "arc_easy": 0.48442760942760943,
      "winogrande": 0.5114443567482242,
      "openbookqa": 0.23
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      2,
      8,
      16,
      4,
      2,
      6,
      4,
      6,
      6,
      2,
      6,
      6,
      16,
      12,
      10,
      14,
      8,
      8,
      16,
      12,
      4,
      12,
      6,
      6,
      6,
      10,
      14,
      12,
      12,
      10,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.3615813582951603,
      "boolq": 0.5834862385321101,
      "openbookqa": 0.23,
      "arc_challenge": 0.24146757679180889,
      "piqa": 0.6735582154515778,
      "winogrande": 0.5090765588003157,
      "arc_easy": 0.4810606060606061
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      6,
      12,
      8,
      6,
      2,
      16,
      10,
      16,
      16,
      4,
      8,
      4,
      8,
      2,
      10,
      8,
      4,
      8,
      16,
      8,
      16,
      4,
      4,
      8,
      4,
      2,
      12,
      10,
      4,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6784548422198041,
      "openbookqa": 0.238,
      "winogrande": 0.5177584846093133,
      "boolq": 0.5825688073394495,
      "arc_challenge": 0.24658703071672355,
      "arc_easy": 0.4819023569023569,
      "hellaswag": 0.3604859589723163
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      16,
      12,
      10,
      10,
      6,
      2,
      14,
      12,
      14,
      8,
      4,
      12,
      2,
      6,
      10,
      16,
      2,
      12,
      4,
      4,
      4,
      14,
      10,
      12,
      4,
      4,
      8,
      2,
      8,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.563914373088685,
      "arc_easy": 0.4802188552188552,
      "openbookqa": 0.23,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.35769766978689504,
      "arc_challenge": 0.23890784982935154,
      "piqa": 0.6659412404787813
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      16,
      2,
      6,
      12,
      2,
      10,
      12,
      16,
      2,
      6,
      16,
      10,
      6,
      6,
      8,
      2,
      12,
      8,
      2,
      8,
      12,
      6,
      8,
      12,
      8,
      14,
      14,
      12,
      14,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.23,
      "hellaswag": 0.3584943238398725,
      "arc_easy": 0.48569023569023567,
      "arc_challenge": 0.2508532423208191,
      "boolq": 0.6015290519877676,
      "winogrande": 0.5169692186266772,
      "piqa": 0.6702937976060935
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      12,
      16,
      10,
      14,
      12,
      16,
      16,
      2,
      12,
      2,
      10,
      12,
      16,
      8,
      16,
      12,
      6,
      6,
      2,
      4,
      8,
      16,
      6,
      8,
      14,
      16,
      6,
      6,
      2,
      2,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35859390559649473,
      "arc_challenge": 0.24573378839590443,
      "openbookqa": 0.228,
      "piqa": 0.6719260065288357,
      "boolq": 0.5920489296636086,
      "winogrande": 0.5232833464877664,
      "arc_easy": 0.4819023569023569
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      4,
      12,
      14,
      14,
      10,
      14,
      12,
      12,
      6,
      8,
      4,
      4,
      4,
      8,
      12,
      14,
      2,
      4,
      10,
      4,
      2,
      12,
      10,
      4,
      14,
      14,
      8,
      2,
      14,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4524410774410774,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.25341296928327645,
      "boolq": 0.4562691131498471,
      "hellaswag": 0.36964748058155744,
      "openbookqa": 0.222
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      14,
      14,
      8,
      12,
      2,
      12,
      12,
      4,
      16,
      14,
      14,
      4,
      2,
      8,
      2,
      4,
      14,
      10,
      12,
      2,
      2,
      12,
      4,
      2,
      8,
      12,
      12,
      10,
      2,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6893362350380848,
      "openbookqa": 0.218,
      "winogrande": 0.5122336227308603,
      "arc_easy": 0.4478114478114478,
      "boolq": 0.4773700305810398,
      "arc_challenge": 0.2551194539249147,
      "hellaswag": 0.369946225851424
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      14,
      16,
      12,
      16,
      8,
      16,
      14,
      12,
      6,
      6,
      10,
      10,
      2,
      16,
      6,
      4,
      8,
      16,
      6,
      16,
      8,
      14,
      2,
      14,
      12,
      12,
      12,
      10,
      2,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.675734494015234,
      "hellaswag": 0.35789683330013944,
      "boolq": 0.5648318042813456,
      "arc_challenge": 0.24914675767918087,
      "winogrande": 0.5098658247829518,
      "arc_easy": 0.4751683501683502,
      "openbookqa": 0.236
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      14,
      12,
      14,
      14,
      10,
      12,
      2,
      12,
      12,
      2,
      10,
      4,
      2,
      2,
      2,
      14,
      14,
      16,
      12,
      16,
      8,
      10,
      6,
      14,
      2,
      12,
      12,
      12,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6860718171926007,
      "hellaswag": 0.3703445528779128,
      "arc_easy": 0.44696969696969696,
      "winogrande": 0.5217048145224941,
      "openbookqa": 0.22,
      "arc_challenge": 0.26023890784982934,
      "boolq": 0.41437308868501527
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      12,
      4,
      12,
      6,
      14,
      2,
      12,
      6,
      8,
      14,
      10,
      4,
      4,
      8,
      10,
      16,
      16,
      6,
      10,
      14,
      14,
      4,
      12,
      16,
      6,
      4,
      8,
      14,
      10,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6692056583242655,
      "openbookqa": 0.232,
      "boolq": 0.5737003058103975,
      "arc_challenge": 0.24658703071672355,
      "winogrande": 0.5185477505919495,
      "arc_easy": 0.49284511784511786,
      "hellaswag": 0.3604859589723163
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      14,
      14,
      8,
      4,
      6,
      14,
      10,
      12,
      8,
      12,
      16,
      2,
      10,
      4,
      10,
      12,
      4,
      10,
      4,
      6,
      10,
      4,
      14,
      16,
      8,
      8,
      4,
      8,
      4,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4936868686868687,
      "openbookqa": 0.232,
      "hellaswag": 0.3593905596494722,
      "boolq": 0.5746177370030581,
      "piqa": 0.6719260065288357,
      "winogrande": 0.5209155485398579,
      "arc_challenge": 0.24146757679180889
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      16,
      14,
      6,
      16,
      2,
      14,
      6,
      8,
      2,
      8,
      8,
      12,
      4,
      4,
      4,
      2,
      12,
      10,
      8,
      12,
      6,
      14,
      6,
      8,
      12,
      10,
      8,
      12,
      12,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4781144781144781,
      "piqa": 0.6697497279651795,
      "winogrande": 0.5209155485398579,
      "boolq": 0.5519877675840978,
      "openbookqa": 0.232,
      "hellaswag": 0.35829516032662817,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      16,
      12,
      12,
      2,
      6,
      16,
      4,
      10,
      6,
      4,
      6,
      14,
      10,
      12,
      2,
      12,
      2,
      10,
      4,
      6,
      2,
      6,
      10,
      14,
      2,
      16,
      4,
      4,
      2,
      12,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25341296928327645,
      "piqa": 0.6833514689880305,
      "winogrande": 0.5185477505919495,
      "hellaswag": 0.3710416251742681,
      "arc_easy": 0.44823232323232326,
      "boolq": 0.47706422018348627,
      "openbookqa": 0.22
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      12,
      14,
      8,
      10,
      14,
      6,
      16,
      16,
      6,
      2,
      8,
      12,
      14,
      6,
      12,
      8,
      6,
      10,
      6,
      8,
      4,
      14,
      4,
      16,
      4,
      12,
      2,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.22,
      "winogrande": 0.5122336227308603,
      "piqa": 0.6898803046789989,
      "arc_easy": 0.4414983164983165,
      "arc_challenge": 0.24658703071672355,
      "hellaswag": 0.3692491535550687,
      "boolq": 0.4666666666666667
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      14,
      6,
      2,
      10,
      10,
      16,
      14,
      16,
      14,
      14,
      8,
      8,
      10,
      12,
      4,
      16,
      10,
      14,
      4,
      2,
      16,
      16,
      4,
      2,
      8,
      10,
      12,
      10,
      14,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.218,
      "hellaswag": 0.3695478988249353,
      "boolq": 0.44954128440366975,
      "arc_challenge": 0.2627986348122867,
      "piqa": 0.6893362350380848,
      "arc_easy": 0.44276094276094274,
      "winogrande": 0.5280189423835833
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      12,
      2,
      16,
      2,
      12,
      12,
      2,
      16,
      12,
      16,
      14,
      12,
      14,
      2,
      16,
      16,
      12,
      8,
      6,
      6,
      8,
      16,
      6,
      16,
      16,
      12,
      16,
      2,
      4,
      12,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4515993265993266,
      "winogrande": 0.5082872928176796,
      "openbookqa": 0.216,
      "arc_challenge": 0.2525597269624573,
      "boolq": 0.44464831804281346,
      "hellaswag": 0.3707428799044015,
      "piqa": 0.6871599564744287
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      12,
      2,
      8,
      4,
      2,
      6,
      4,
      4,
      2,
      10,
      8,
      12,
      10,
      12,
      4,
      2,
      14,
      10,
      16,
      10,
      10,
      8,
      4,
      4,
      14,
      14,
      16,
      2,
      4,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.44823232323232326,
      "winogrande": 0.5130228887134964,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.25341296928327645,
      "boolq": 0.44036697247706424,
      "openbookqa": 0.218,
      "hellaswag": 0.3694483170683131
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      8,
      8,
      6,
      8,
      8,
      2,
      8,
      10,
      6,
      8,
      10,
      14,
      12,
      8,
      16,
      4,
      2,
      14,
      16,
      14,
      12,
      2,
      6,
      4,
      4,
      10,
      10,
      8,
      12,
      10,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.358195578570006,
      "piqa": 0.6724700761697497,
      "winogrande": 0.5209155485398579,
      "boolq": 0.6021406727828746,
      "arc_easy": 0.4831649831649832,
      "arc_challenge": 0.2525597269624573,
      "openbookqa": 0.244
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      14,
      14,
      4,
      16,
      16,
      16,
      14,
      10,
      10,
      10,
      8,
      2,
      8,
      8,
      12,
      14,
      2,
      2,
      12,
      6,
      16,
      8,
      8,
      12,
      12,
      8,
      8,
      2,
      12,
      12,
      8,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "piqa": 0.6784548422198041,
      "boolq": 0.5501529051987768,
      "arc_challenge": 0.24914675767918087,
      "openbookqa": 0.228,
      "hellaswag": 0.360884285998805,
      "arc_easy": 0.4793771043771044
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      16,
      10,
      2,
      14,
      6,
      8,
      14,
      8,
      4,
      12,
      6,
      10,
      4,
      8,
      16,
      6,
      10,
      2,
      2,
      6,
      16,
      2,
      10,
      8,
      2,
      4,
      12,
      8,
      10,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25597269624573377,
      "winogrande": 0.5130228887134964,
      "boolq": 0.47217125382263,
      "arc_easy": 0.4457070707070707,
      "hellaswag": 0.3692491535550687,
      "openbookqa": 0.216,
      "piqa": 0.6855277475516867
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      2,
      12,
      12,
      8,
      2,
      6,
      10,
      14,
      2,
      12,
      10,
      12,
      8,
      4,
      6,
      10,
      6,
      12,
      4,
      10,
      4,
      12,
      12,
      2,
      10,
      2,
      6,
      8,
      10,
      16,
      12,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5146014206787688,
      "boolq": 0.44128440366972477,
      "openbookqa": 0.222,
      "arc_easy": 0.4503367003367003,
      "arc_challenge": 0.24573378839590443,
      "piqa": 0.6849836779107725,
      "hellaswag": 0.36984664409480184
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      8,
      10,
      16,
      14,
      12,
      10,
      8,
      12,
      6,
      16,
      6,
      16,
      2,
      12,
      12,
      4,
      2,
      12,
      14,
      12,
      14,
      14,
      4,
      14,
      12,
      14,
      12,
      10,
      8,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6931447225244831,
      "arc_challenge": 0.25426621160409557,
      "arc_easy": 0.4478114478114478,
      "hellaswag": 0.3703445528779128,
      "boolq": 0.517125382262997,
      "winogrande": 0.526440410418311,
      "openbookqa": 0.218
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      12,
      10,
      14,
      2,
      10,
      4,
      12,
      12,
      4,
      8,
      2,
      8,
      10,
      10,
      10,
      16,
      4,
      8,
      8,
      8,
      12,
      8,
      6,
      8,
      12,
      12,
      16,
      2,
      16,
      14,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35968930491933876,
      "arc_easy": 0.48358585858585856,
      "winogrande": 0.5209155485398579,
      "openbookqa": 0.224,
      "boolq": 0.5828746177370031,
      "piqa": 0.6708378672470077,
      "arc_challenge": 0.24488054607508533
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      14,
      6,
      8,
      2,
      8,
      10,
      8,
      16,
      6,
      8,
      4,
      8,
      12,
      2,
      16,
      12,
      8,
      14,
      16,
      14,
      12,
      8,
      6,
      8,
      10,
      8,
      6,
      6,
      8,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "boolq": 0.5850152905198777,
      "arc_easy": 0.4877946127946128,
      "hellaswag": 0.35919139613622786,
      "winogrande": 0.5114443567482242,
      "arc_challenge": 0.24658703071672355,
      "openbookqa": 0.236
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      12,
      2,
      8,
      8,
      4,
      4,
      14,
      2,
      16,
      2,
      8,
      2,
      4,
      2,
      8,
      6,
      10,
      6,
      8,
      4,
      2,
      14,
      16,
      10,
      12,
      12,
      12,
      16,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4890572390572391,
      "winogrande": 0.5201262825572218,
      "openbookqa": 0.24,
      "boolq": 0.6027522935779817,
      "arc_challenge": 0.24914675767918087,
      "hellaswag": 0.36068512248556067,
      "piqa": 0.6686615886833515
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      6,
      16,
      14,
      12,
      4,
      14,
      6,
      12,
      12,
      2,
      16,
      16,
      6,
      8,
      4,
      14,
      6,
      4,
      2,
      12,
      4,
      16,
      6,
      12,
      10,
      4,
      12,
      12,
      6,
      6,
      14,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6741022850924918,
      "hellaswag": 0.35929097789285,
      "boolq": 0.5944954128440367,
      "winogrande": 0.5122336227308603,
      "arc_challenge": 0.24146757679180889,
      "arc_easy": 0.48274410774410775,
      "openbookqa": 0.232
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      10,
      2,
      6,
      2,
      16,
      14,
      2,
      6,
      8,
      16,
      4,
      2,
      12,
      2,
      10,
      8,
      16,
      8,
      10,
      12,
      4,
      10,
      16,
      12,
      12,
      10,
      12,
      12,
      4,
      14,
      2
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.25,
      "arc_easy": 0.47769360269360267,
      "openbookqa": 0.222,
      "winogrande": 0.5193370165745856,
      "piqa": 0.6670293797606094,
      "hellaswag": 0.3602867954590719,
      "boolq": 0.5813455657492355
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      8,
      14,
      6,
      10,
      16,
      6,
      6,
      6,
      2,
      8,
      12,
      4,
      6,
      10,
      10,
      8,
      14,
      8,
      14,
      2,
      6,
      10,
      16,
      6,
      10,
      2,
      6,
      12,
      10,
      6,
      6,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6735582154515778,
      "winogrande": 0.5169692186266772,
      "hellaswag": 0.35859390559649473,
      "openbookqa": 0.24,
      "boolq": 0.5709480122324159,
      "arc_challenge": 0.24829351535836178,
      "arc_easy": 0.47769360269360267
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      8,
      4,
      16,
      10,
      8,
      8,
      14,
      2,
      16,
      14,
      12,
      10,
      16,
      10,
      14,
      16,
      10,
      16,
      6,
      8,
      8,
      6,
      10,
      12,
      16,
      12,
      4,
      2,
      6,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5169692186266772,
      "arc_easy": 0.44991582491582494,
      "arc_challenge": 0.25,
      "piqa": 0.690968443960827,
      "openbookqa": 0.208,
      "hellaswag": 0.3694483170683131,
      "boolq": 0.4235474006116208
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      6,
      6,
      16,
      12,
      16,
      8,
      6,
      14,
      8,
      10,
      2,
      16,
      4,
      6,
      16,
      6,
      16,
      4,
      10,
      12,
      14,
      6,
      6,
      6,
      10,
      16,
      14,
      10,
      16,
      4,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.482262996941896,
      "arc_challenge": 0.257679180887372,
      "piqa": 0.6860718171926007,
      "openbookqa": 0.22,
      "arc_easy": 0.44612794612794615,
      "hellaswag": 0.3694483170683131,
      "winogrande": 0.5130228887134964
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      14,
      14,
      12,
      6,
      2,
      12,
      2,
      16,
      10,
      16,
      14,
      4,
      4,
      14,
      10,
      14,
      12,
      12,
      16,
      16,
      10,
      4,
      6,
      2,
      16,
      16,
      10,
      8,
      14,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.226,
      "boolq": 0.5773700305810398,
      "arc_challenge": 0.24488054607508533,
      "arc_easy": 0.484006734006734,
      "piqa": 0.6702937976060935,
      "hellaswag": 0.35829516032662817
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      16,
      16,
      16,
      16,
      4,
      10,
      14,
      14,
      10,
      16,
      8,
      8,
      8,
      8,
      10,
      14,
      14,
      10,
      6,
      6,
      8,
      8,
      2,
      8,
      14,
      14,
      10,
      16,
      12,
      2,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.228,
      "piqa": 0.6675734494015234,
      "arc_easy": 0.48484848484848486,
      "arc_challenge": 0.2431740614334471,
      "hellaswag": 0.35879306910973907,
      "winogrande": 0.5122336227308603,
      "boolq": 0.5996941896024465
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      16,
      12,
      10,
      8,
      16,
      16,
      4,
      10,
      10,
      8,
      8,
      16,
      2,
      2,
      6,
      14,
      10,
      10,
      10,
      12,
      4,
      14,
      16,
      4,
      6,
      12,
      12,
      12,
      6,
      6,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "winogrande": 0.510655090765588,
      "hellaswag": 0.3593905596494722,
      "arc_easy": 0.48148148148148145,
      "boolq": 0.6048929663608563,
      "piqa": 0.6741022850924918,
      "openbookqa": 0.23,
      "arc_challenge": 0.24232081911262798
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      2,
      12,
      6,
      4,
      10,
      8,
      14,
      6,
      6,
      8,
      8,
      4,
      6,
      8,
      10,
      8,
      8,
      8,
      10,
      16,
      14,
      16,
      6,
      2,
      10,
      14,
      6,
      4,
      10,
      8,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.228,
      "hellaswag": 0.3575980880302729,
      "winogrande": 0.526440410418311,
      "piqa": 0.6659412404787813,
      "arc_challenge": 0.24232081911262798,
      "boolq": 0.6036697247706422,
      "arc_easy": 0.48863636363636365
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      10,
      6,
      14,
      16,
      12,
      2,
      16,
      6,
      8,
      8,
      14,
      12,
      2,
      4,
      6,
      6,
      2,
      16,
      12,
      4,
      12,
      2,
      2,
      16,
      6,
      4,
      12,
      8,
      16,
      8,
      8,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.232,
      "hellaswag": 0.35839474208325034,
      "boolq": 0.5629969418960244,
      "arc_easy": 0.4802188552188552,
      "winogrande": 0.5185477505919495,
      "arc_challenge": 0.24146757679180889,
      "piqa": 0.6719260065288357
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      10,
      6,
      8,
      6,
      6,
      10,
      16,
      8,
      4,
      2,
      12,
      14,
      2,
      6,
      14,
      12,
      12,
      16,
      2,
      16,
      6,
      4,
      16,
      10,
      12,
      6,
      12,
      2,
      14,
      12,
      14,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.257679180887372,
      "openbookqa": 0.212,
      "arc_easy": 0.4511784511784512,
      "piqa": 0.6860718171926007,
      "winogrande": 0.5090765588003157,
      "hellaswag": 0.3708424616610237,
      "boolq": 0.4055045871559633
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      16,
      6,
      4,
      12,
      10,
      6,
      6,
      2,
      10,
      2,
      10,
      12,
      2,
      4,
      10,
      4,
      4,
      2,
      2,
      6,
      14,
      6,
      4,
      6,
      16,
      14,
      2,
      4,
      14,
      6,
      4,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.226,
      "boolq": 0.4614678899082569,
      "arc_easy": 0.44486531986531985,
      "winogrande": 0.5232833464877664,
      "piqa": 0.6898803046789989,
      "hellaswag": 0.37094204341764586,
      "arc_challenge": 0.2568259385665529
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      2,
      8,
      6,
      14,
      4,
      14,
      4,
      8,
      14,
      2,
      14,
      16,
      12,
      6,
      2,
      6,
      2,
      14,
      10,
      4,
      2,
      6,
      2,
      6,
      12,
      6,
      8,
      12,
      6,
      8,
      4
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.228,
      "piqa": 0.6866158868335147,
      "winogrande": 0.5217048145224941,
      "boolq": 0.41437308868501527,
      "hellaswag": 0.36895040828520215,
      "arc_challenge": 0.24914675767918087,
      "arc_easy": 0.44023569023569026
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      8,
      10,
      2,
      14,
      14,
      16,
      10,
      16,
      8,
      4,
      14,
      8,
      12,
      6,
      12,
      14,
      10,
      2,
      4,
      10,
      2,
      4,
      16,
      2,
      2,
      2,
      16,
      12,
      4,
      4,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "hellaswag": 0.35879306910973907,
      "openbookqa": 0.222,
      "winogrande": 0.5082872928176796,
      "boolq": 0.5697247706422018,
      "arc_challenge": 0.24914675767918087,
      "arc_easy": 0.48484848484848486,
      "piqa": 0.6779107725788901
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      8,
      12,
      6,
      4,
      10,
      12,
      8,
      6,
      14,
      6,
      16,
      10,
      14,
      2,
      16,
      6,
      6,
      10,
      12,
      14,
      12,
      6,
      2,
      6,
      8,
      10,
      2,
      8,
      16,
      8,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2619453924914676,
      "arc_easy": 0.4452861952861953,
      "winogrande": 0.5193370165745856,
      "hellaswag": 0.37044413463453496,
      "openbookqa": 0.218,
      "piqa": 0.6931447225244831,
      "boolq": 0.4792048929663609
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      4,
      6,
      16,
      10,
      10,
      8,
      2,
      12,
      8,
      2,
      4,
      14,
      12,
      16,
      6,
      10,
      10,
      6,
      16,
      4,
      16,
      14,
      12,
      2,
      14,
      6,
      10,
      2,
      6,
      16,
      14,
      6
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6713819368879217,
      "arc_challenge": 0.24744027303754265,
      "arc_easy": 0.48737373737373735,
      "openbookqa": 0.232,
      "boolq": 0.5880733944954128,
      "winogrande": 0.510655090765588,
      "hellaswag": 0.359788886675961
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      6,
      10,
      12,
      10,
      10,
      2,
      16,
      12,
      12,
      6,
      12,
      14,
      8,
      4,
      2,
      8,
      16,
      8,
      2,
      10,
      16,
      16,
      16,
      8,
      16,
      10,
      2,
      2,
      10,
      2,
      16,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2568259385665529,
      "boolq": 0.45015290519877676,
      "piqa": 0.6882480957562568,
      "winogrande": 0.5240726124704025,
      "hellaswag": 0.37044413463453496,
      "openbookqa": 0.216,
      "arc_easy": 0.44234006734006737
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      2,
      12,
      10,
      12,
      16,
      10,
      8,
      14,
      8,
      10,
      10,
      6,
      12,
      8,
      16,
      4,
      4,
      6,
      2,
      4,
      2,
      10,
      10,
      10,
      16,
      6,
      12,
      8,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "piqa": 0.6866158868335147,
      "arc_challenge": 0.2508532423208191,
      "openbookqa": 0.222,
      "arc_easy": 0.44023569023569026,
      "hellaswag": 0.37054371639115713,
      "winogrande": 0.5138121546961326,
      "boolq": 0.42385321100917434
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      8,
      2,
      10,
      4,
      12,
      16,
      10,
      14,
      8,
      16,
      10,
      12,
      14,
      4,
      4,
      16,
      10,
      4,
      16,
      10,
      6,
      4,
      2,
      4,
      2,
      8,
      6,
      4,
      16,
      14,
      12
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.463914373088685,
      "arc_easy": 0.44823232323232326,
      "hellaswag": 0.37004580760804623,
      "openbookqa": 0.222,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6882480957562568,
      "arc_challenge": 0.25
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      2,
      12,
      6,
      8,
      4,
      16,
      14,
      16,
      8,
      8,
      16,
      6,
      4,
      6,
      14,
      4,
      2,
      16,
      4,
      2,
      12,
      12,
      14,
      6,
      2,
      4,
      12,
      6,
      4,
      4,
      10
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "openbookqa": 0.222,
      "arc_challenge": 0.25597269624573377,
      "piqa": 0.6855277475516867,
      "hellaswag": 0.3690499900418243,
      "arc_easy": 0.4494949494949495,
      "boolq": 0.5100917431192661,
      "winogrande": 0.5224940805051302
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      4,
      2,
      14,
      6,
      10,
      14,
      16,
      12,
      4,
      14,
      12,
      6,
      10,
      2,
      2,
      6,
      10,
      2,
      14,
      12,
      12,
      2,
      14,
      8,
      12,
      2,
      2,
      2,
      6,
      8,
      8,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4494949494949495,
      "hellaswag": 0.37044413463453496,
      "winogrande": 0.5177584846093133,
      "piqa": 0.6866158868335147,
      "boolq": 0.4599388379204893,
      "arc_challenge": 0.25597269624573377,
      "openbookqa": 0.224
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      12,
      4,
      12,
      12,
      4,
      2,
      10,
      14,
      14,
      14,
      8,
      6,
      8,
      10,
      2,
      6,
      2,
      12,
      16,
      12,
      4,
      2,
      2,
      4,
      14,
      10,
      14,
      16,
      16,
      10,
      10,
      8
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.55565749235474,
      "arc_easy": 0.4819023569023569,
      "arc_challenge": 0.24914675767918087,
      "piqa": 0.6735582154515778,
      "openbookqa": 0.212,
      "winogrande": 0.5217048145224941,
      "hellaswag": 0.3580959968133838
    }
  },
  {
    "name": "vicuna-7b_0.50",
    "rank_list": [
      16,
      12,
      16,
      10,
      8,
      8,
      12,
      16,
      14,
      4,
      4,
      14,
      12,
      14,
      2,
      6,
      14,
      16,
      8,
      6,
      4,
      2,
      14,
      6,
      16,
      8,
      8,
      12,
      12,
      4,
      16,
      14
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "boolq": 0.5935779816513761,
      "arc_easy": 0.476010101010101,
      "piqa": 0.6702937976060935,
      "hellaswag": 0.3594901414060944,
      "winogrande": 0.5177584846093133,
      "openbookqa": 0.228,
      "arc_challenge": 0.2508532423208191
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      12,
      10,
      16,
      4,
      4,
      12,
      14,
      6,
      14,
      10,
      6,
      4,
      6,
      10,
      14,
      8,
      14,
      4,
      14,
      8,
      14,
      6,
      4,
      10,
      8,
      12,
      2,
      12,
      14,
      8,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_easy": 0.4452861952861953,
      "openbookqa": 0.216,
      "boolq": 0.4437308868501529,
      "hellaswag": 0.36875124477195775,
      "piqa": 0.690968443960827,
      "winogrande": 0.5201262825572218,
      "arc_challenge": 0.2551194539249147
    }
  },
  {
    "name": "llama-7b_0.50",
    "rank_list": [
      14,
      8,
      14,
      4,
      10,
      12,
      2,
      12,
      12,
      12,
      16,
      2,
      2,
      10,
      12,
      12,
      16,
      12,
      4,
      6,
      12,
      6,
      6,
      6,
      10,
      14,
      16,
      2,
      4,
      2,
      6,
      16
    ],
    "pruning_rate_list": [
      0,
      0,
      0,
      0,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0.635,
      0,
      0
    ],
    "performance": {
      "arc_challenge": 0.2551194539249147,
      "arc_easy": 0.4372895622895623,
      "piqa": 0.6887921653971708,
      "hellaswag": 0.37004580760804623,
      "openbookqa": 0.218,
      "winogrande": 0.5185477505919495,
      "boolq": 0.43516819571865445
    }
  }
]
