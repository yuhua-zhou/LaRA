[
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      4,
      4,
      12,
      2,
      4,
      4,
      6,
      8,
      6,
      4,
      8,
      8,
      8,
      4,
      10,
      8,
      2,
      2,
      2,
      6,
      8,
      12,
      4,
      2,
      12,
      12,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32
    ],
    "performance": {
      "BoolQ": 0.6385321100917432,
      "PIQA": 0.7595212187159956,
      "HellaSwag": 0.659928301135232,
      "WinoGrande": 0.6377269139700079,
      "ARC-e": 0.6157407407407407,
      "ARC-c": 0.3498293515358361,
      "OBQA": 0.394
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      8,
      2,
      8,
      2,
      12,
      8,
      6,
      2,
      8,
      12,
      4,
      10,
      8,
      8,
      10,
      12,
      8,
      2,
      4,
      10,
      6,
      8,
      4,
      8,
      4,
      12,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6697247706422018,
      "PIQA": 0.7687704026115343,
      "HellaSwag": 0.6869149571798446,
      "WinoGrande": 0.6337805840568271,
      "ARC-e": 0.627104377104377,
      "ARC-c": 0.3651877133105802,
      "OBQA": 0.406
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      2,
      6,
      2,
      8,
      4,
      2,
      6,
      8,
      8,
      12,
      12,
      4,
      6,
      8,
      8,
      8,
      12,
      8,
      12,
      6,
      10,
      4,
      4,
      8,
      6,
      2,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5975535168195719,
      "PIQA": 0.6926006528835691,
      "HellaSwag": 0.4690300736904999,
      "WinoGrande": 0.5303867403314917,
      "ARC-e": 0.4688552188552188,
      "ARC-c": 0.2849829351535836,
      "OBQA": 0.358
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      8,
      2,
      8,
      8,
      10,
      6,
      6,
      6,
      2,
      4,
      2,
      12,
      2,
      4,
      10,
      10,
      12,
      10,
      8,
      8,
      8,
      4,
      6,
      8,
      10,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38
    ],
    "performance": {
      "BoolQ": 0.6324159021406728,
      "PIQA": 0.7464635473340587,
      "HellaSwag": 0.6374228241386178,
      "WinoGrande": 0.6235201262825573,
      "ARC-e": 0.5867003367003367,
      "ARC-c": 0.3353242320819112,
      "OBQA": 0.398
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      4,
      6,
      12,
      10,
      2,
      4,
      6,
      2,
      6,
      8,
      2,
      2,
      2,
      12,
      10,
      6,
      4,
      6,
      2,
      8,
      4,
      8,
      12,
      6,
      12,
      8,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.6009174311926605,
      "PIQA": 0.6789989118607181,
      "HellaSwag": 0.4441346345349532,
      "WinoGrande": 0.494869771112865,
      "ARC-e": 0.5,
      "ARC-c": 0.2798634812286689,
      "OBQA": 0.346
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      12,
      12,
      2,
      10,
      2,
      12,
      8,
      12,
      2,
      4,
      10,
      10,
      10,
      4,
      12,
      12,
      6,
      10,
      12,
      2,
      6,
      6,
      2,
      2,
      12,
      2,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.5636085626911315,
      "PIQA": 0.7704026115342764,
      "HellaSwag": 0.667396932881896,
      "WinoGrande": 0.632991318074191,
      "ARC-e": 0.6830808080808081,
      "ARC-c": 0.3805460750853242,
      "OBQA": 0.402
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      10,
      2,
      2,
      12,
      12,
      6,
      2,
      4,
      10,
      6,
      12,
      8,
      12,
      6,
      2,
      4,
      4,
      2,
      6,
      2,
      6,
      10,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32
    ],
    "performance": {
      "BoolQ": 0.5116207951070336,
      "PIQA": 0.7578890097932536,
      "HellaSwag": 0.6422027484564827,
      "WinoGrande": 0.6037884767166535,
      "ARC-e": 0.63510101010101,
      "ARC-c": 0.3506825938566553,
      "OBQA": 0.406
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      12,
      6,
      8,
      2,
      8,
      12,
      2,
      8,
      6,
      6,
      10,
      8,
      6,
      8,
      4,
      12,
      8,
      6,
      2,
      10,
      6,
      2,
      10,
      8,
      2,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38
    ],
    "performance": {
      "BoolQ": 0.6113149847094801,
      "PIQA": 0.7480957562568009,
      "HellaSwag": 0.6109340768771161,
      "WinoGrande": 0.5990528808208366,
      "ARC-e": 0.5904882154882155,
      "ARC-c": 0.3506825938566553,
      "OBQA": 0.392
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      10,
      10,
      8,
      10,
      10,
      12,
      8,
      12,
      8,
      8,
      12,
      4,
      12,
      8,
      2,
      8,
      6,
      2,
      4,
      2,
      10,
      6,
      6,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6593272171253822,
      "PIQA": 0.7671381936887922,
      "HellaSwag": 0.6851224855606453,
      "WinoGrande": 0.6353591160220995,
      "ARC-e": 0.6325757575757576,
      "ARC-c": 0.3694539249146757,
      "OBQA": 0.398
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      8,
      2,
      6,
      12,
      2,
      12,
      12,
      2,
      8,
      8,
      2,
      4,
      4,
      10,
      4,
      12,
      4,
      12,
      4,
      6,
      12,
      12,
      10,
      10,
      4,
      6,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32
    ],
    "performance": {
      "BoolQ": 0.6403669724770642,
      "PIQA": 0.7578890097932536,
      "HellaSwag": 0.660426209918343,
      "WinoGrande": 0.6353591160220995,
      "ARC-e": 0.6115319865319865,
      "ARC-c": 0.348976109215017,
      "OBQA": 0.4
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      6,
      8,
      2,
      12,
      12,
      2,
      4,
      4,
      12,
      12,
      10,
      8,
      2,
      2,
      12,
      4,
      2,
      12,
      10,
      8,
      8,
      8,
      6,
      10,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38
    ],
    "performance": {
      "BoolQ": 0.6229357798165137,
      "PIQA": 0.7426550598476604,
      "HellaSwag": 0.6344353714399522,
      "WinoGrande": 0.6227308602999211,
      "ARC-e": 0.5913299663299664,
      "ARC-c": 0.3404436860068259,
      "OBQA": 0.394
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      12,
      2,
      4,
      6,
      2,
      2,
      8,
      8,
      2,
      12,
      10,
      2,
      6,
      4,
      12,
      8,
      2,
      6,
      2,
      12,
      6,
      6,
      4,
      2,
      8,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5865443425076453,
      "PIQA": 0.6893362350380848,
      "HellaSwag": 0.4672376020713005,
      "WinoGrande": 0.5288082083662194,
      "ARC-e": 0.4595959595959596,
      "ARC-c": 0.2909556313993174,
      "OBQA": 0.36
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      12,
      6,
      2,
      2,
      4,
      2,
      12,
      2,
      12,
      4,
      4,
      8,
      2,
      10,
      2,
      10,
      8,
      2,
      10,
      8,
      12,
      2,
      4,
      2,
      4,
      2,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.4920489296636086,
      "PIQA": 0.7736670293797606,
      "HellaSwag": 0.6702848038239394,
      "WinoGrande": 0.6377269139700079,
      "ARC-e": 0.6712962962962963,
      "ARC-c": 0.3720136518771331,
      "OBQA": 0.4
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      2,
      8,
      12,
      4,
      6,
      6,
      10,
      8,
      2,
      8,
      2,
      12,
      6,
      4,
      12,
      8,
      2,
      2,
      10,
      10,
      8,
      8,
      6,
      12,
      4,
      8,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.555045871559633,
      "PIQA": 0.7731229597388466,
      "HellaSwag": 0.668990240987851,
      "WinoGrande": 0.6377269139700079,
      "ARC-e": 0.6708754208754208,
      "ARC-c": 0.3720136518771331,
      "OBQA": 0.402
    }
  },
  {
    "name": "Vicuna-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      4,
      4,
      6,
      2,
      2,
      4,
      4,
      2,
      12,
      2,
      2,
      6,
      10,
      2,
      6,
      8,
      2,
      6,
      4,
      10,
      4,
      12,
      6,
      12,
      6,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.5923547400611621,
      "PIQA": 0.7704026115342764,
      "HellaSwag": 0.6679944234216292,
      "WinoGrande": 0.6369376479873717,
      "ARC-e": 0.6670875420875421,
      "ARC-c": 0.378839590443686,
      "OBQA": 0.404
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      8,
      4,
      8,
      12,
      4,
      10,
      10,
      10,
      2,
      2,
      4,
      10,
      8,
      8,
      12,
      8,
      4,
      2,
      12,
      6,
      10,
      4,
      10,
      4,
      8,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.636697247706422,
      "PIQA": 0.7665941240478781,
      "HellaSwag": 0.6861183031268672,
      "WinoGrande": 0.6369376479873717,
      "ARC-e": 0.6342592592592593,
      "ARC-c": 0.3728668941979522,
      "OBQA": 0.4
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      8,
      4,
      12,
      6,
      12,
      10,
      2,
      8,
      8,
      2,
      6,
      2,
      6,
      4,
      6,
      4,
      10,
      4,
      6,
      12,
      2,
      6,
      12,
      6,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6400611620795107,
      "PIQA": 0.7709466811751904,
      "HellaSwag": 0.6883091017725552,
      "WinoGrande": 0.6345698500394633,
      "ARC-e": 0.6355218855218855,
      "ARC-c": 0.3694539249146757,
      "OBQA": 0.404
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      10,
      2,
      10,
      10,
      10,
      12,
      10,
      2,
      4,
      4,
      8,
      12,
      6,
      2,
      8,
      8,
      12,
      2,
      6,
      12,
      6,
      2,
      6,
      12,
      8,
      12,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6385321100917432,
      "PIQA": 0.7752992383025027,
      "HellaSwag": 0.6877116112328221,
      "WinoGrande": 0.6385161799526441,
      "ARC-e": 0.6346801346801347,
      "ARC-c": 0.3813993174061433,
      "OBQA": 0.396
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      12,
      10,
      2,
      8,
      2,
      12,
      12,
      12,
      4,
      8,
      4,
      12,
      6,
      2,
      6,
      10,
      6,
      6,
      6,
      12,
      12,
      6,
      12,
      2,
      12,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6244648318042814,
      "PIQA": 0.7714907508161044,
      "HellaSwag": 0.6880103565026887,
      "WinoGrande": 0.6266771902131019,
      "ARC-e": 0.6355218855218855,
      "ARC-c": 0.3728668941979522,
      "OBQA": 0.406
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      2,
      2,
      2,
      6,
      8,
      8,
      12,
      4,
      2,
      6,
      2,
      2,
      2,
      8,
      2,
      12,
      12,
      8,
      10,
      2,
      12,
      12,
      12,
      12,
      10,
      6,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25,
      0.25
    ],
    "performance": {
      "BoolQ": 0.6614678899082569,
      "PIQA": 0.7709466811751904,
      "HellaSwag": 0.6890061740689106,
      "WinoGrande": 0.6322020520915549,
      "ARC-e": 0.6321548821548821,
      "ARC-c": 0.3703071672354949,
      "OBQA": 0.394
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      8,
      4,
      6,
      4,
      6,
      8,
      6,
      2,
      4,
      12,
      8,
      12,
      4,
      10,
      8,
      12,
      4,
      4,
      4,
      2,
      12,
      4,
      6,
      10,
      8,
      10,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32,
      0.32
    ],
    "performance": {
      "BoolQ": 0.6620795107033639,
      "PIQA": 0.7616974972796517,
      "HellaSwag": 0.6598287193786099,
      "WinoGrande": 0.6298342541436464,
      "ARC-e": 0.6106902356902357,
      "ARC-c": 0.35580204778157,
      "OBQA": 0.396
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      2,
      2,
      10,
      12,
      8,
      10,
      4,
      12,
      8,
      8,
      8,
      12,
      10,
      12,
      6,
      6,
      12,
      6,
      10,
      12,
      12,
      6,
      2,
      8,
      8,
      4,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38,
      0.38
    ],
    "performance": {
      "BoolQ": 0.6330275229357798,
      "PIQA": 0.749727965179543,
      "HellaSwag": 0.635929097789285,
      "WinoGrande": 0.6211523283346487,
      "ARC-e": 0.5913299663299664,
      "ARC-c": 0.3344709897610921,
      "OBQA": 0.398
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      12,
      8,
      6,
      2,
      8,
      8,
      12,
      2,
      10,
      6,
      6,
      4,
      4,
      10,
      8,
      10,
      6,
      8,
      10,
      12,
      6,
      4,
      6,
      12,
      8,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5954128440366973,
      "PIQA": 0.6947769314472253,
      "HellaSwag": 0.466938856801434,
      "WinoGrande": 0.5272296764009471,
      "ARC-e": 0.4566498316498316,
      "ARC-c": 0.2858361774744027,
      "OBQA": 0.356
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      12,
      10,
      8,
      12,
      8,
      10,
      12,
      8,
      10,
      8,
      4,
      12,
      4,
      2,
      2,
      8,
      4,
      2,
      10,
      6,
      10,
      10,
      4,
      2,
      2,
      8,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5785932721712538,
      "PIQA": 0.6974972796517954,
      "HellaSwag": 0.4644493128858793,
      "WinoGrande": 0.5280189423835833,
      "ARC-e": 0.4629629629629629,
      "ARC-c": 0.2866894197952218,
      "OBQA": 0.356
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      6,
      10,
      12,
      8,
      6,
      6,
      2,
      6,
      8,
      8,
      10,
      2,
      6,
      4,
      2,
      8,
      2,
      4,
      6,
      4,
      6,
      12,
      12,
      12,
      2,
      6,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5929663608562691,
      "PIQA": 0.6953210010881393,
      "HellaSwag": 0.4655447122087233,
      "WinoGrande": 0.5224940805051302,
      "ARC-e": 0.4617003367003367,
      "ARC-c": 0.2790102389078498,
      "OBQA": 0.358
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      4,
      4,
      4,
      2,
      12,
      6,
      6,
      12,
      8,
      8,
      6,
      6,
      6,
      8,
      10,
      8,
      2,
      6,
      10,
      10,
      2,
      8,
      2,
      4,
      8,
      8,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.535474006116208,
      "PIQA": 0.6942328618063112,
      "HellaSwag": 0.4642501493726349,
      "WinoGrande": 0.5374901341752171,
      "ARC-e": 0.4772727272727273,
      "ARC-c": 0.2849829351535836,
      "OBQA": 0.354
    }
  },
  {
    "name": "LLaMA-7B",
    "layer_info": [
      8,
      8,
      8,
      8,
      10,
      12,
      2,
      10,
      6,
      6,
      10,
      10,
      10,
      8,
      6,
      2,
      10,
      12,
      6,
      10,
      4,
      10,
      2,
      8,
      12,
      10,
      12,
      12,
      8,
      10,
      8,
      8
    ],
    "rank_list": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "pruning_rate_list": [
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625,
      0.625
    ],
    "performance": {
      "BoolQ": 0.5892966360856269,
      "PIQA": 0.6920565832426551,
      "HellaSwag": 0.4640509858593906,
      "WinoGrande": 0.5201262825572218,
      "ARC-e": 0.4642255892255892,
      "ARC-c": 0.2883959044368601,
      "OBQA": 0.36
    }
  }
]